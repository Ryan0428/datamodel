{"version":3,"sources":["webpack://DataModel/webpack/universalModuleDefinition","webpack://DataModel/webpack/bootstrap","webpack://DataModel/./src/index.js","webpack://DataModel/./src/enums/data-format.js","webpack://DataModel/./src/enums/dimension-subtype.js","webpack://DataModel/./src/enums/measure-subtype.js","webpack://DataModel/./src/enums/field-type.js","webpack://DataModel/./src/enums/filtering-mode.js","webpack://DataModel/./src/utils/date-time-formatter.js","webpack://DataModel/./src/utils/column-major.js","webpack://DataModel/./src/utils/extend2.js","webpack://DataModel/./src/utils/helper.js","webpack://DataModel/./src/field-store.js","webpack://DataModel/./src/value.js","webpack://DataModel/./src/operator/row-diffset-iterator.js","webpack://DataModel/./src/operator/bucket-creator.js","webpack://DataModel/./src/operator/get-common-schema.js","webpack://DataModel/./src/constants/index.js","webpack://DataModel/./src/operator/cross-product.js","webpack://DataModel/./src/operator/merge-sort.js","webpack://DataModel/./src/operator/data-builder.js","webpack://DataModel/./src/operator/difference.js","webpack://DataModel/./src/operator/group-by-function.js","webpack://DataModel/./src/utils/reducer-store.js","webpack://DataModel/./src/operator/group-by.js","webpack://DataModel/./src/operator/natural-join-filter-function.js","webpack://DataModel/./src/operator/union.js","webpack://DataModel/./src/operator/outer-join.js","webpack://DataModel/./src/fields/field/index.js","webpack://DataModel/./src/fields/dimension/index.js","webpack://DataModel/./src/fields/categorical/index.js","webpack://DataModel/./src/fields/temporal/index.js","webpack://DataModel/./src/fields/binned/index.js","webpack://DataModel/./src/fields/measure/index.js","webpack://DataModel/./src/fields/continuous/index.js","webpack://DataModel/./src/fields/parsers/field-parser/index.js","webpack://DataModel/./src/fields/parsers/categorical-parser/index.js","webpack://DataModel/./src/fields/parsers/temporal-parser/index.js","webpack://DataModel/./src/fields/parsers/binned-parser/index.js","webpack://DataModel/./src/fields/parsers/continuous-parser/index.js","webpack://DataModel/./src/fields/partial-field/index.js","webpack://DataModel/./src/field-creator.js","webpack://DataModel/./src/default-config.js","webpack://DataModel/./src/converter/dsv-arr.js","webpack://DataModel/./node_modules/d3-dsv/src/dsv.js","webpack://DataModel/./node_modules/d3-dsv/src/csv.js","webpack://DataModel/./node_modules/d3-dsv/src/tsv.js","webpack://DataModel/./src/converter/dsv-str.js","webpack://DataModel/./src/converter/flat-json.js","webpack://DataModel/./src/converter/auto-resolver.js","webpack://DataModel/./src/helper.js","webpack://DataModel/./src/relation.js","webpack://DataModel/./src/datamodel.js","webpack://DataModel/./src/stats/index.js","webpack://DataModel/./src/export.js","webpack://DataModel/./src/operator/compose.js","webpack://DataModel/./src/operator/pure-operators.js","webpack://DataModel/./src/operator/natural-join.js"],"names":["root","factory","exports","module","define","amd","window","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","DataModel","default","data_format","FLAT_JSON","DSV_STR","DSV_ARR","AUTO","dimension_subtype","CATEGORICAL","TEMPORAL","GEO","BINNED","measure_subtype","CONTINUOUS","field_type","MEASURE","DIMENSION","filtering_mode","NORMAL","INVERSE","ALL","convertToNativeDate","date","Date","pad","DateTimeFormatter","format","this","dtParams","undefined","nativeDate","RegExp","escape","text","replace","TOKEN_PREFIX","DATETIME_PARAM_SEQUENCE","YEAR","MONTH","DAY","HOUR","MINUTE","SECOND","MILLISECOND","defaultNumberParser","defVal","val","parsedVal","isFinite","parseInt","defaultRangeParser","range","nVal","toLowerCase","length","getTokenDefinitions","daysDef","short","long","monthsDef","H","index","extract","parser","formatter","getHours","toString","hours","P","M","getMinutes","S","getSeconds","K","getMilliseconds","a","join","day","getDay","A","e","getDate","b","month","getMonth","B","y","substring","year","getFullYear","Y","getTokenFormalNames","definitions","HOUR_12","AMPM_UPPERCASE","AMPM_LOWERCASE","SHORT_DAY","LONG_DAY","DAY_OF_MONTH","DAY_OF_MONTH_CONSTANT_WIDTH","SHORT_MONTH","LONG_MONTH","MONTH_OF_YEAR","SHORT_YEAR","LONG_YEAR","tokenResolver","defaultResolver","arg","targetParam","arguments","hourFormat24","hourFormat12","ampmLower","ampmUpper","amOrpm","isPM","findTokens","tokenPrefix","tokenLiterals","keys","occurrence","forwardChar","indexOf","push","token","formatAs","nDate","formattedStr","String","formattedVal","parse","dateTimeStamp","options","extractTokenValue","dtParamSeq","noBreak","dtParamArr","args","resolverKey","resolverParams","resolverFn","param","resolvedVal","splice","apply","tokenObj","lastOccurrenceIndex","occObj","occIndex","targetText","regexFormat","tokenArr","map","obj","occurrenceLength","extractValues","match","shift","getNativeDate","unshift","Function","column_major","store","_len","fields","Array","_key","forEach","fieldIndex","from","OBJECTSTRING","objectToStrFn","objectToStr","arrayToStr","checkCyclicRef","parentArr","bIndex","extend2","obj1","obj2","skipUndef","_typeof","merge","tgtArr","srcArr","item","srcVal","tgtVal","str","cRef","isArray","isCallable","getUniqueId","getTime","Math","round","random","isArrEqual","arr1","arr2","formatNumber","field_store","data","createNamespace","fieldArr","dataId","fieldsObj","retObj","field","getMeasure","schema","type","getDimension","src_value","Value","_classCallCheck","configurable","writable","_value","rowDiffsetIterator","rowDiffset","callback","split","diffStr","diffStsArr","start","end","createBinnedFieldData","config","buckets","binCount","binSize","dataStore","binnedData","_field$domain","domain","_field$domain2","_slicedToArray","min","max","oriMax","stops","binEnd","prevEndpoint","mid","partialField","extraBinELm","endPoint","filter","datum","Set","add","concat","bucket_creator_toConsumableArray","sort","getCommonSchema","fs1","fs2","retArr","fs1Arr","DM_DERIVATIVES","JOINS","CROSS","LEFTOUTER","RIGHTOUTER","NATURAL","FULLOUTER","LOGICAL_OPERATORS","defaultFilterFn","crossProduct","dm1","dm2","filterFn","replaceCommonSchema","jointype","applicableFilterFn","dm1FieldStore","getFieldspace","dm2FieldStore","dm1FieldStoreName","dm2FieldStoreName","commonSchemaList","Error","tmpSchema","_rowDiffset","rowAdded","rowPosition","ii","tuple","userArg","dm1Fields","prepareJoinData","dm2Fields","tupleObj","cellVal","iii","len","datamodel","defSortFn","a1","b1","mergeSort","arr","sortFn","merge_sort_sort","lo","hi","floor","mainArr","auxArr","merge_sort_merge","getSortFn","dataType","sortType","retFunc","groupData","hashMap","Map","groupedData","fieldVal","has","set","createSortingFnArg","groupedDatum","targetFields","targetFieldDetails","label","reduce","acc","next","idx","dataBuilder","fieldStore","colIdentifier","sortingDetails","uids","addUid","assign","columnWise","reqSorting","tmpDataArr","colName","insertInd","dataObj","fieldName","sortMeta","fDetails","fieldInSchema","sortingFn","slice","f","data_builder_toConsumableArray","pop","sortData","tmpData","difference_difference","hashTable","schemaNameArr","dm1FieldStoreFieldObj","dm2FieldStoreFieldObj","_colIdentifier","prepareDataHelper","dm","addData","hashData","schemaName","sum","allNulls","isNestedArray","sumVal","carry","x","group_by_function_toConsumableArray","avg","arrSum","fnList","Infinity","every","first","last","count","std","sqrt","mean","num","pow","variance","reducer_store_ReducerStore","ReducerStore","_this","reducer_store_classCallCheck","entries","reducer","_this2","__unregister","delete","reducer_store","group_by_groupBy","dataModel","reducers","existingDataModel","sFieldArr","dimensions","getPartialFieldspace","_ref","group_by_slicedToArray","getFieldArr","reducerObj","pReducers","measures","defaultReducer","_ref3","resolve","defAggFn","getReducerObj","fieldStoreObj","dbName","dimensionArr","measureArr","newDataModel","_ref5","_ref6","rowCount","hash","_","row","__calculateFieldspace","src_export","naturalJoinFilter","commonSchemaArr","retainTuple","union_union","leftOuterJoin","dataModel1","dataModel2","rightOuterJoin","fields_field","Field","field_classCallCheck","subtype","description","displayName","dimension","_cachedDomain","calculateDataDomain","categorical","temporal","_this3","currIdx","prevDatum","minDiff","Number","POSITIVE_INFINITY","binned","binsArr","bins","measure","unit","numberFormat","continuous","NEGATIVE_INFINITY","field_parser","categorical_parser","trim","temporal_parser","TemporalParser","temporal_parser_classCallCheck","temporal_parser_possibleConstructorReturn","__proto__","getPrototypeOf","_dtf","binned_parser","matched","continuous_parser","parseFloat","isNaN","partial_field","PartialField","partial_field_classCallCheck","_sanitize","createFields","dataColumn","headers","headersObj","header","createUnitField","default_config","dataFormat","dsv_arr","firstRowHeader","columns","dsv_arr_toConsumableArray","EOL","EOF","QUOTE","NEWLINE","RETURN","objectConverter","JSON","stringify","src_dsv","delimiter","reFormat","DELIMITER","charCodeAt","parseRows","rows","N","I","eof","eol","j","formatRow","formatValue","test","convert","customConverter","columnSet","column","inferColumns","formatRows","csv","tsv","dsv_str","fieldSeparator","dsv","flat_json","insertionIndex","auto_resolver","converter","isString","isObject","prepareSelectionData","resp","_iteratorNormalCompletion","_didIteratorError","_iteratorError","_step","_iterator","iterator","done","err","return","helper_updateFields","partialFieldspace","fieldStoreName","_ref2","helper_slicedToArray","collID","partialFieldMap","newFields","coll","createUnitFieldFromPartial","helper_persistDerivation","model","operation","_model$_derivation","criteriaFn","derivative","op","meta","criteria","_derivation","helper_toConsumableArray","helper_filterPropagationModel","propModels","filterByMeasure","fns","propModel","getData","fieldsConfig","getFieldsConfig","fieldsSpace","values","v","def","some","propField","valueOf","filteredModel","clone","select","fn","saveChild","helper_cloneWithSelect","sourceDm","selectFn","selectConfig","cloneConfig","cloned","newRowDiffSet","lastInsertedValue","li","checker","helper_selectHelper","calculateFieldsConfig","helper_cloneWithProject","projField","allFields","projectionSet","actualProjField","helper_updateData","relation","converterFn","converter_namespaceObject","_converterFn","_converterFn2","formattedData","nameSpace","_partialFieldspace","applyExistingOperationOnModel","_propModel$","_propModel$2","_getOperationArgument","child","derivation","params","groupByString","helper_getOperationArguments","selectionModel","rejectionModel","propagateIdentifiers","propModelInf","nonTraversingModel","excludeModels","handlePropagation","_children","_applyExistingOperati","_applyExistingOperati2","propagateToAllDataModels","identifiers","rootModels","propagationInf","propagationNameSpace","propagateToSource","propagationSourceId","sourceId","propagateInterpolatedValues","criterias","persistent","actionCriterias","mutableActions","filteredCriteria","entry","action","sourceActionCriterias","actionInf","actionConf","applyOnSource","models","path","getPathToRootModel","_parent","rootModel","propConfig","sourceIdentifiers","rootGroupByModel","groupByModel","inf","propagationModel","getFilteredModel","reverse","src_relation","Relation","relation_classCallCheck","source","_fieldStoreName","updateData","_propagationNameSpace","immutableActions","_fieldspace","joinWith","unionWith","differenceWith","defConfig","oDm","retDataModel","getAllFields","jsonData","rowObj","constructor","fieldConfig","normalizedProjField","relation_toConsumableArray","search","_fieldConfig","fieldDef","removeChild","findIndex","sibling","parent","criteriaQueue","datamodel_classCallCheck","datamodel_possibleConstructorReturn","_onPropagation","_sortingDetails","order","withUid","dataGenerated","fieldNames","fmtFieldIdx","elem","fIdx","fmtFn","datumIdx","fieldsArr","groupBy","rawData","dataInCSVArr","sortedDm","fieldinst","dependency","replaceVar","depVars","retrieveFn","depFieldIndices","fieldSpec","fs","suppliedFields","computedValues","fieldsData","datamodel_toConsumableArray","_createFields","datamodel_slicedToArray","addField","addToNameSpace","isMutableAction","payload","getRootDataModel","getRootGroupByModel","find","sourceNamespace","addToPropNamespace","filterImmutableAction","criteriaModel","propagateImmutableActions","eventName","dimensionName","binFieldName","dataSet","currfield","binField","stats_sum","stats_avg","stats_min","stats_max","stats_first","stats_last","stats_count","sd","Operators","compose","_len5","operations","_key5","currentDM","frstChild","derivations","compose_toConsumableArray","addParent","dispose","bin","_len3","_key3","project","_len2","_key2","_len4","_key4","calculateVariable","difference","naturalJoin","fullOuterJoin","union","Stats","stats_namespaceObject","enums_namespaceObject","DataFormat","FilteringMode","version","package_0","__webpack_exports__"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,IACA,mBAAAG,eAAAC,IACAD,OAAA,eAAAH,GACA,iBAAAC,QACAA,QAAA,UAAAD,IAEAD,EAAA,UAAAC,IARA,CASCK,OAAA,WACD,mBCTA,IAAAC,KAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAP,QAGA,IAAAC,EAAAI,EAAAE,IACAC,EAAAD,EACAE,GAAA,EACAT,YAUA,OANAU,EAAAH,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAQ,GAAA,EAGAR,EAAAD,QA0DA,OArDAM,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAd,EAAAe,EAAAC,GACAV,EAAAW,EAAAjB,EAAAe,IACAG,OAAAC,eAAAnB,EAAAe,GAA0CK,YAAA,EAAAC,IAAAL,KAK1CV,EAAAgB,EAAA,SAAAtB,GACA,oBAAAuB,eAAAC,aACAN,OAAAC,eAAAnB,EAAAuB,OAAAC,aAAwDC,MAAA,WAExDP,OAAAC,eAAAnB,EAAA,cAAiDyB,OAAA,KAQjDnB,EAAAoB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAAnB,EAAAmB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFAxB,EAAAgB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAAnB,EAAAQ,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAvB,EAAA2B,EAAA,SAAAhC,GACA,IAAAe,EAAAf,KAAA2B,WACA,WAA2B,OAAA3B,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAK,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD7B,EAAAgC,EAAA,GAIAhC,IAAAiC,EAAA,25DClFA,IAAMC,EAAYlC,EAAQ,GAE1BL,EAAOD,QAAUwC,EAAUC,QAAUD,EAAUC,QAAUD,ouBCKzD,IAOeE,GANXC,UAAW,WACXC,QAAS,SACTC,QAAS,SACTC,KAAM,QCEKC,GANXC,YAAa,cACbC,SAAU,WACVC,IAAK,MACLC,OAAQ,UCAGC,GAHXC,WAAY,cCKDC,GAJXC,QAAS,UACTC,UAAW,aCGAC,GALXC,OAAQ,SACRC,QAAS,UACTC,IAAK,OCHT,SAASC,EAAqBC,GAC1B,OAAIA,aAAgBC,KACTD,EAGJ,IAAIC,KAAKD,GASpB,SAASE,EAAK/B,GACV,OAAQA,EAAI,GAAL,IAAgBA,EAAOA,EA8BP,SAASgC,EAAmBC,GACnDC,KAAKD,OAASA,EACdC,KAAKC,cAAWC,EAChBF,KAAKG,gBAAaD,EAftBE,OAAOC,OAAS,SAAUC,GACtB,OAAOA,EAAKC,QAAQ,2BAA4B,SAkBpDT,EAAkBU,aAAe,IAIjCV,EAAkBW,yBACdC,KAAM,EACNC,MAAO,EACPC,IAAK,EACLC,KAAM,EACNC,OAAQ,EACRC,OAAQ,EACRC,YAAa,GAUjBlB,EAAkBmB,oBAAsB,SAAUC,GAC9C,OAAO,SAAUC,GACb,IAAIC,EACJ,OAAIC,SAASD,EAAYE,SAASH,EAAK,KAC5BC,EAGJF,IAYfpB,EAAkByB,mBAAqB,SAAUC,EAAON,GACpD,OAAO,SAACC,GACJ,IACI7E,EADAD,SAGJ,IAAK8E,EAAO,OAAOD,EAEnB,IAAMO,EAAON,EAAIO,cAEjB,IAAKrF,EAAI,EAAGC,EAAIkF,EAAMG,OAAQtF,EAAIC,EAAGD,IACjC,GAAImF,EAAMnF,GAAGqF,gBAAkBD,EAC3B,OAAOpF,EAIf,YAAU6D,IAAN7D,EACO6E,EAEJ,OAqBfpB,EAAkB8B,oBAAsB,WACpC,IAAMC,GACFC,OACI,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,MACI,SACA,SACA,UACA,YACA,WACA,SACA,aAGFC,GACFF,OACI,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,MACA,OAEJC,MACI,UACA,WACA,QACA,QACA,MACA,OACA,OACA,SACA,YACA,UACA,WACA,aA6OR,OAxOIE,GAEIrF,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAGP,OAFUzB,EAAoByB,GAErBmB,WAAWC,aAG5BjG,GAEIM,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GACP,IACMqB,EADI9C,EAAoByB,GACdmB,WAAa,GAE7B,OAAkB,IAAVE,EAAc,GAAKA,GAAOD,aAG1CpE,GAEIvB,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCG,GAEI7F,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,WACpBC,OAAQ,SAACjB,GACL,OAAIA,EACOA,EAAIO,cAER,MAEXW,UAAW,SAAClB,GAIR,OAHUzB,EAAoByB,GACdmB,WAEA,GAAK,KAAO,OAGpCI,GAEI9F,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACfwB,gBAKvBC,GAEIhG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACZ0B,gBAK1BC,GAEIlG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACjB4B,kBAEHR,aAGlBS,GAEIpG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQC,MAAMmB,KAAK,KAA9B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQC,OACrDO,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQC,MAAMoB,GAAMX,aAGpCa,GAEIxG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,UAAWN,EAAQE,KAAKkB,KAAK,KAA7B,KACbb,OAAQtC,EAAkByB,mBAAmBM,EAAQE,MACrDM,UAND,SAMYlB,GACP,IACM+B,EADIxD,EAAoByB,GAChBgC,SAEd,OAAQtB,EAAQE,KAAKmB,GAAMX,aAGnCc,GAEIzG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GAChBmC,UAEHf,aAGnB5F,GAEIC,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GAChBmC,aAKtBC,GAEI3G,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUF,MAAMmB,KAAK,KAAhC,KACbb,OAAQtC,EAAkByB,mBAAmBS,EAAUF,OACvDO,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUF,MAAM0B,GAAQjB,aAGxCmB,GAEI9G,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,UAAWH,EAAUD,KAAKkB,KAAK,KAA/B,KACbb,OAAQtC,EAAkBmB,oBAAoBe,EAAUD,MACxDM,UAND,SAMYlB,GACP,IACMqC,EADI9D,EAAoByB,GACdsC,WAEhB,OAAQzB,EAAUD,KAAKyB,GAAQjB,aAGvC9F,GAEIG,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,UACpBC,OALD,SAKSjB,GAAO,OAAOrB,EAAkBmB,qBAAlBnB,CAAwCqB,GAAO,GACrEkB,UAND,SAMYlB,GAIP,OAAOtB,EAHGH,EAAoByB,GACdsC,WAEG,KAG3BE,GAEI/G,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OALD,SAKSjB,GACJ,GAAIA,EAAK,CACL,IAAM7E,EAAI6E,EAAIQ,OACdR,EAAMA,EAAIyC,UAAUtH,EAAI,EAAGA,GAG/B,OAAOwD,EAAkBmB,qBAAlBnB,CAAwCqB,IAEnDkB,UAbD,SAaYlB,GACP,IACI0C,EADMnE,EAAoByB,GACjB2C,cAAcvB,WACvBjG,SAOJ,OALIuH,IACAvH,EAAIuH,EAAKlC,OACTkC,EAAOA,EAAKD,UAAUtH,EAAI,EAAGA,IAG1BuH,IAGfE,GAEInH,KAAM,IACNsF,MAAO,EACPC,QAJD,WAIc,MAAO,YACpBC,OAAQtC,EAAkBmB,sBAC1BoB,UAND,SAMYlB,GAIP,OAHUzB,EAAoByB,GACf2C,cAAcvB,eAgB7CzC,EAAkBkE,oBAAsB,WACpC,IAAMC,EAAcnE,EAAkB8B,sBAEtC,OACIf,KAAMoD,EAAYhC,EAClBiC,QAASD,EAAY3H,EACrB6H,eAAgBF,EAAY9F,EAC5BiG,eAAgBH,EAAYxB,EAC5B3B,OAAQmD,EAAYvB,EACpB3B,OAAQkD,EAAYrB,EACpByB,UAAWJ,EAAYjB,EACvBsB,SAAUL,EAAYb,EACtBmB,aAAcN,EAAYZ,EAC1BmB,4BAA6BP,EAAYtH,EACzC8H,YAAaR,EAAYV,EACzBmB,WAAYT,EAAYP,EACxBiB,cAAeV,EAAYxH,EAC3BmI,WAAYX,EAAYN,EACxBkB,UAAWZ,EAAYF,IAW/BjE,EAAkBgF,cAAgB,WAC9B,IAAMb,EAAcnE,EAAkB8B,sBAChCmD,EAAkB,WAMpB,IALA,IAAI1I,EAAI,EACJ2I,SACAC,SACE3I,EAAI4I,UAAKvD,OAERtF,EAAIC,EAAGD,IACV2I,oBAAW3I,OAAX6D,EAAAgF,UAAW7I,IACX6I,UAAAvD,QAAStF,OAAT6D,EAAAgF,UAAS7I,MACL4I,EAAcD,GAItB,OAAKC,EAEEA,EAAY,GAAG7C,OAAO6C,EAAY,IAFd,MAK/B,OACIvE,MAAOuD,EAAYN,EAAGM,EAAYF,EAC9BgB,GAEJpE,OAAQsD,EAAYV,EAAGU,EAAYP,EAAGO,EAAYxH,EAC9CsI,GAEJnE,KAAMqD,EAAYjB,EAAGiB,EAAYb,EAAGa,EAAYZ,EAAGY,EAAYtH,EAC3DoI,GAEJlE,MAAOoD,EAAYhC,EAAGgC,EAAY3H,EAAG2H,EAAY9F,EAAG8F,EAAYxB,EAC5D,SAAU0C,EAAcC,EAAcC,EAAWC,GAC7C,IAAIL,SACAM,SACAC,SACArE,SAcJ,OAZIiE,IAAiBG,EAAUF,GAAaC,IACJ,OAAhCC,EAAO,GAAGnD,OAAOmD,EAAO,MACxBC,GAAO,GAGXP,EAAcG,GAEdH,EADOG,GAGOD,EAGbF,GAEL9D,EAAM8D,EAAY,GAAG7C,OAAO6C,EAAY,IACpCO,IACArE,GAAO,IAEJA,GANoB,OASnCL,QAASmD,EAAYvB,EACjBqC,GAEJhE,QAASkD,EAAYrB,EACjBmC,KAUZjF,EAAkB2F,WAAa,SAAU1F,GAQrC,IAPA,IAAM2F,EAAc5F,EAAkBU,aAChCyD,EAAcnE,EAAkB8B,sBAChC+D,EAAgB5I,OAAO6I,KAAK3B,GAC5B4B,KACFxJ,SACAyJ,UAEIzJ,EAAI0D,EAAOgG,QAAQL,EAAarJ,EAAI,KAAO,GAC/CyJ,EAAc/F,EAAO1D,EAAI,IACmB,IAAxCsJ,EAAcI,QAAQD,IAE1BD,EAAWG,MACP9D,MAAO7F,EACP4J,MAAOH,IAIf,OAAOD,GASX/F,EAAkBoG,SAAW,SAAUvG,EAAMI,GACzC,IAQIzD,EARE6J,EAAQzG,EAAoBC,GAC5BkG,EAAa/F,EAAkB2F,WAAW1F,GAC1CkE,EAAcnE,EAAkB8B,sBAClCwE,EAAeC,OAAOtG,GACpB2F,EAAc5F,EAAkBU,aAClCyF,SACAK,SACAjK,SAGJ,IAAKA,EAAI,EAAGC,EAAIuJ,EAAWlE,OAAQtF,EAAIC,EAAGD,IAEtCiK,EAAerC,EADfgC,EAAQJ,EAAWxJ,GAAG4J,OACY5D,UAAU8D,GAC5CC,EAAeA,EAAa7F,QAAQ,IAAIH,OAAOsF,EAAcO,EAAO,KAAMK,GAG9E,OAAOF,GAQXtG,EAAkB7B,UAAUsI,MAAQ,SAAUC,EAAeC,GACzD,IAAM3B,EAAgBhF,EAAkBgF,gBAClC7E,EAAWD,KAAK0G,kBAAkBF,GAClCG,EAAa7G,EAAkBW,wBAC/BmG,EAAUH,GAAWA,EAAQG,QAC7BC,KACAC,KACFC,SACAC,SACAC,SACA9F,SACA9E,SACA6K,SACAC,SACA7K,SAEJ,IAAKyK,KAAejC,EAChB,MAAQ5G,eAAe1B,KAAKsI,EAAeiC,GAA3C,CAMA,IAJAD,EAAKnF,OAAS,EAEdsF,GADAD,EAAiBlC,EAAciC,IACHK,OAAOJ,EAAerF,OAAS,EAAG,GAAG,GAE5DtF,EAAI,EAAGC,EAAI0K,EAAerF,OAAQtF,EAAIC,EAAGD,SAI9B6D,KAFZiB,EAAMlB,GADNiH,EAAQF,EAAe3K,IACFO,OAGjBkK,EAAKd,KAAK,MAEVc,EAAKd,MAAMkB,EAAO/F,IAM1B,SAAqBjB,KAFrBiH,EAAcF,EAAWI,MAAMrH,KAAM8G,KAEa,OAAhBK,KAA0BP,EACxD,MAGJC,EAAWF,EAAWI,IAAgBI,EAG1C,OAAON,GAQX/G,EAAkB7B,UAAUyI,kBAAoB,SAAUF,GACtD,IAYIlK,EAZEyD,EAASC,KAAKD,OACdkE,EAAcnE,EAAkB8B,sBAChC8D,EAAc5F,EAAkBU,aAChCqF,EAAa/F,EAAkB2F,WAAW1F,GAC1CuH,KAEFC,SACAC,SACAC,SACAC,SACAC,SAGAtL,SAEJsL,EAActB,OAAOtG,GAErB,IAAM6H,EAAW/B,EAAWgC,IAAI,SAAAC,GAAA,OAAOA,EAAI7B,QACrC8B,EAAmBlC,EAAWlE,OACpC,IAAKtF,EAAI0L,EAAmB,EAAG1L,GAAK,EAAGA,KACnCoL,EAAW5B,EAAWxJ,GAAG6F,OAEV,IAAMyF,EAAYhG,OAAS,QAKdzB,IAAxBqH,IACAA,EAAsBI,EAAYhG,QAGtC+F,EAAaC,EAAY/D,UAAU6D,EAAW,EAAGF,GACjDI,EAAcA,EAAY/D,UAAU,EAAG6D,EAAW,GAC9CrH,OAAOC,OAAOqH,GACdC,EAAY/D,UAAU2D,EAAqBI,EAAYhG,QAE3D4F,EAAsBE,GAblBF,EAAsBE,EAgB9B,IAAKpL,EAAI,EAAGA,EAAI0L,EAAkB1L,IAC9BmL,EAAS3B,EAAWxJ,GACpBsL,EAAcA,EAAYpH,QAAQmF,EAAc8B,EAAOvB,MAAOhC,EAAYuD,EAAOvB,OAAO9D,WAG5F,IAAM6F,EAAgBxB,EAAcyB,MAAM,IAAI7H,OAAOuH,QAGrD,IAFAK,EAAcE,QAET7L,EAAI,EAAGC,EAAIsL,EAASjG,OAAQtF,EAAIC,EAAGD,IACpCiL,EAASM,EAASvL,IAAM2L,EAAc3L,GAE1C,OAAOiL,GAQXxH,EAAkB7B,UAAUkK,cAAgB,SAAU3B,GAClD,GAAIA,aAAyB5G,KACzB,OAAO4G,EACJ,GAAInF,SAASmF,IAAoBxG,KAAKD,OACzC,OAAO,IAAIH,KAAK4G,GAGpB,IAAMvG,EAAWD,KAAKC,SAAWD,KAAKuG,MAAMC,GAI5C,OAFAvG,EAASmI,QAAQ,MACjBpI,KAAKG,WAAa,IAAKkI,SAASpK,UAAUJ,KAAKwJ,MAAMzH,KAAMK,IACpDD,KAAKG,YAShBL,EAAkB7B,UAAUiI,SAAW,SAAUnG,EAAQyG,GACrD,IAAIrG,SAQJ,OANIqG,EACArG,EAAaH,KAAKG,WAAaH,KAAKmI,cAAc3B,IACzCrG,EAAaH,KAAKG,cAC3BA,EAAaH,KAAKmI,cAAc3B,IAG7B1G,EAAkBoG,SAAS/F,EAAYJ,IC7sBnC,IAAAuI,EAAA,SAACC,GACZ,IAAIlM,EAAI,EACR,OAAO,WAAe,QAAAmM,EAAAtD,UAAAvD,OAAX8G,EAAWC,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAXF,EAAWE,GAAAzD,UAAAyD,GAClBF,EAAOG,QAAQ,SAACzH,EAAK0H,GACXN,EAAMM,aAAuBH,QAC/BH,EAAMM,GAAcH,MAAMI,MAAOnH,OAAQtF,KAE7CkM,EAAMM,GAAY7C,KAAK7E,KAE3B9E,kNCdF0M,EAAe,SACfC,EAAgBjM,OAAOkB,UAAUsE,SACjC0G,EAAc,kBACdC,EAAa,iBAEnB,SAASC,EAAerB,EAAKsB,GAIzB,IAHA,IAAI/M,EAAI+M,EAAUzH,OACd0H,GAAU,EAEPhN,GAAG,CACN,GAAIyL,IAAQsB,EAAU/M,GAElB,OADAgN,EAAShN,EAGbA,GAAK,EAGT,OAAOgN,EA2GX,SAASC,EAASC,EAAMC,EAAMC,GAE1B,YAAI,IAAOF,EAAP,YAAAG,EAAOH,MAASR,SAAgB,IAAOS,EAAP,YAAAE,EAAOF,MAAST,EACzC,WAGP,IAAOS,EAAP,YAAAE,EAAOF,MAAST,GAAyB,OAATS,EACzBD,SAGP,IAAOA,EAAP,YAAAG,EAAOH,MAASR,IAChBQ,EAAOC,aAAgBd,aAnH/B,SAASiB,EAAMJ,EAAMC,EAAMC,EAAWG,EAAQC,GAC1C,IAAIC,EACAC,EACAC,EACAC,EACAC,EAcJ,GATKL,GAKDD,EAAO5D,KAAKuD,GACZM,EAAO7D,KAAKwD,KALZI,GAAUL,GACVM,GAAUL,IAOVA,aAAgBd,MAChB,IAAKoB,EAAO,EAAGA,EAAON,EAAK7H,OAAQmI,GAAQ,EAAG,CAC1C,IACIC,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOzG,GACH,eAGA,IAAO2G,EAAP,YAAAN,EAAOM,MAAWjB,EACZU,QAAwBvJ,IAAX8J,IACfT,EAAKO,GAAQE,IAIF,OAAXD,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,GAAQE,aAAkBtB,cAG9B,KADdwB,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,SAMrD,IAAKC,KAAQN,EAAM,CACf,IACIO,EAASR,EAAKO,GACdE,EAASR,EAAKM,GAElB,MAAOzG,GACH,SAGJ,GAAe,OAAX2G,SAAmB,IAAOA,EAAP,YAAAN,EAAOM,MAAWjB,GAKrCkB,EAAMjB,EAAcxM,KAAKwN,MACbf,GACO,OAAXc,SAAmB,IAAOA,EAAP,YAAAL,EAAOK,MAAWhB,IACrCgB,EAASR,EAAKO,QAGJ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAGxCI,IAAQf,GACE,OAAXa,GAAqBA,aAAkBrB,QACvCqB,EAASR,EAAKO,QAGJ,KADdI,EAAOf,EAAea,EAAQH,IAE1BE,EAASR,EAAKO,GAAQF,EAAOM,GAG7BP,EAAMI,EAAQC,EAAQP,EAAWG,EAAQC,IAI7CN,EAAKO,GAAQE,MAGhB,CACD,GAAIP,QAAwBvJ,IAAX8J,EACb,SAEJT,EAAKO,GAAQE,GAIzB,OAAOT,EAiBPI,CAAMJ,EAAMC,EAAMC,GACXF,GCrIJ,SAASY,EAAShJ,GACrB,OAAOuH,MAAMyB,QAAQhJ,GA6BlB,SAASiJ,EAAYjJ,GACxB,MAAsB,mBAARA,EAaX,IAAMkJ,EAAc,wBAAY,IAAIzK,MAAO0K,UAAYC,KAAKC,MAAsB,IAAhBD,KAAKE,WAqCvE,SAASC,EAAWC,EAAMC,GAC7B,IAAKT,EAAQQ,KAAUR,EAAQS,GAC3B,OAAOD,IAASC,EAGpB,GAAID,EAAKhJ,SAAWiJ,EAAKjJ,OACrB,OAAO,EAGX,IAAK,IAAItF,EAAI,EAAGA,EAAIsO,EAAKhJ,OAAQtF,IAC7B,GAAIsO,EAAKtO,KAAOuO,EAAKvO,GACjB,OAAO,EAIf,OAAO,EAUJ,SAASwO,EAAa1J,GACzB,OAAOA,EC9GX,IAsCe2J,GArCXC,QAEAC,gBAHe,SAGEC,EAAUrO,GACvB,IAAMsO,EAAStO,GAAQyN,IA8BvB,OA7BArK,KAAK+K,KAAKG,IACNtO,KAAMsO,EACNzC,OAAQwC,EACRE,UAHgB,WAIZ,IAAMC,KAIN,OAHApL,KAAKyI,OAAOG,QAAQ,SAACyC,GACjBD,EAAOC,EAAMzO,QAAUyO,IAEpBD,GAEXE,WAVgB,WAWZ,IAAMF,KAMN,OALApL,KAAKyI,OAAOG,QAAQ,SAACyC,GACbA,EAAME,SAASC,OAASrM,EAAUC,UAClCgM,EAAOC,EAAMzO,QAAUyO,KAGxBD,GAEXK,aAnBgB,WAoBZ,IAAML,KAMN,OALApL,KAAKyI,OAAOG,QAAQ,SAACyC,GACbA,EAAME,SAASC,OAASrM,EAAUE,YAClC+L,EAAOC,EAAMzO,QAAUyO,KAGxBD,IAGRpL,KAAK+K,KAAKG,8PCmBVQ,aA1CX,SAAAC,EAAaxK,EAAKkK,gGAAOO,CAAA5L,KAAA2L,GACrB5O,OAAOC,eAAegD,KAAM,UACxB/C,YAAY,EACZ4O,cAAc,EACdC,UAAU,EACVxO,MAAO6D,IAGXnB,KAAKqL,MAAQA,+CAoBb,OAAOhF,OAAOrG,KAAK1C,yCAUnB,OAAO0C,KAAK1C,oCArBZ,OAAO0C,KAAK+L,gBCxBb,SAASC,EAAoBC,EAAYC,GACxCD,EAAWtK,OAAS,GACDsK,EAAWE,MAAM,KACzBvD,QAAQ,SAACwD,GAChB,IAAMC,EAAaD,EAAQD,MAAM,KAC3BG,GAAUD,EAAW,GACrBE,IAAQF,EAAW,IAAMA,EAAW,IAC1C,GAAIE,GAAOD,EACP,IAAK,IAAIjQ,EAAIiQ,EAAOjQ,GAAKkQ,EAAKlQ,GAAK,EAC/B6P,EAAS7P,4aCLtB,SAASmQ,EAAuBnB,EAAOY,EAAYQ,GAAQ,IACxDC,EAAsCD,EAAtCC,QAASC,EAA6BF,EAA7BE,SAAUC,EAAmBH,EAAnBG,QAASN,EAAUG,EAAVH,MAC9BO,KACAC,KAH0DC,EAI7C1B,EAAM2B,SAJuCC,EAAAC,EAAAH,EAAA,GAIzDI,EAJyDF,EAAA,GAIpDG,EAJoDH,EAAA,GAK1DI,EAASD,EACTE,KACAC,SACAC,SACAC,SACAjM,SAWJ,GARAwK,EAAmBC,EAAY,SAAC5P,GAC5BwQ,EAAU7G,MACN+E,KAAMM,EAAMqC,aAAa3C,KAAK1O,GAC9B6F,MAAO7F,OAKVqQ,EAAS,CAIV,IAAMiB,IAHNP,GAAO,GAGoBD,IAF3BP,EAAUA,IAAYQ,EAAMD,GAAOR,GAOnC,IAJKA,GAA4B,IAAhBgB,IACbP,EAAMA,EAAMR,EAAUe,GAE1BJ,EAASJ,EAAMP,EACRW,GAAUH,GACbE,EAAMtH,KAAKuH,GACXA,GAAUX,EAGdF,GAAYJ,MADZA,EAAQA,GAASa,EACEG,SAIvBE,EAAiC,IAAlBd,EAAQJ,MAAc,EAAII,EAAQJ,OAASa,EAG1DT,EAAQY,MAAM1E,QAAQ,SAACgF,GACHf,EAAUgB,OAAO,SAAAC,GAAA,OAASA,EAAM/C,MAAQyC,GAAgBM,EAAM/C,KAAO6C,IAC3EhF,QAAQ,SAACkF,GAAYhB,EAAWgB,EAAM5L,OAAYsL,EAA7B,IAA6CI,IAC5EJ,EAAeI,IAInBf,EAAUgB,OAAO,SAAAC,GAAA,OAASA,EAAM/C,KAAO2B,EAAQJ,QAC9B1D,QAAQ,SAACkF,GAAYhB,EAAWgB,EAAM5L,OAAYiL,EAA7B,IAAoCT,EAAQJ,QAGlFO,EAAUgB,OAAO,SAAAC,GAAA,OAASA,EAAM/C,MAAQ2B,EAAQY,MAAMZ,EAAQY,MAAM3L,OAAS,KAC5DiH,QAAQ,SAACkF,GACRhB,EAAWgB,EAAM5L,OAAYwK,EAAQY,MAAMZ,EAAQY,MAAM3L,OAAS,GAAlE,IAAwE0L,IAI1FX,EAAQY,MAAMlF,QAAQsE,EAAQJ,OAC9B9K,EAAQ,IAAIuM,IAAIrB,EAAQY,OAGpBH,EAAMT,EAAQJ,OAAS9K,EAAMwM,IAAIb,GACjCE,EAASX,EAAQY,MAAMZ,EAAQY,MAAM3L,OAAS,IAAMH,EAAMwM,IAAIX,GAElE7L,KAAQyM,6HAAAC,CAAI1M,IAAO2M,KAAK,SAACnL,EAAGO,GAAJ,OAAUP,EAAIO,IACtCkK,KAEA,IAAK,IAAIpR,EAAI,EAAGA,EAAImF,EAAMG,OAAQtF,IAC9BoR,EAAIzH,MAAMxE,EAAMnF,EAAI,GAAKmF,EAAMnF,IAAM,GAEzC,OAAS0O,KAAM+B,EAAYW,MAAKjM,SC3E7B,SAAS4M,EAAiBC,EAAKC,GAClC,IAAMC,KACAC,KASN,OARAH,EAAI5F,OAAOG,QAAQ,SAACyC,GAChBmD,EAAOxI,KAAKqF,EAAME,SAAS3O,QAE/B0R,EAAI7F,OAAOG,QAAQ,SAACyC,IAC6B,IAAzCmD,EAAOzI,QAAQsF,EAAME,SAAS3O,OAC9B2R,EAAOvI,KAAKqF,EAAME,SAAS3O,QAG5B2R,ECfJ,IAUME,EACD,SADCA,EAEA,UAFAA,EAGA,QAHAA,EAIA,UAJAA,EAKA,qBALAA,EAMJ,MAGIC,GACTC,MAAO,QACPC,UAAW,YACXC,WAAY,aACZC,QAAS,UACTC,UAAW,aAGFC,EACJ,MCrBT,SAASC,IAAoB,OAAO,EAY7B,SAASC,EAAcC,EAAKC,EAAKC,GAA+D,IAArDC,EAAqDpK,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,IAAAA,UAAA,GAAxBqK,EAAwBrK,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,GAAbwJ,EAAMC,MACtFpD,KACAR,KACAyE,EAAqBH,GAAYJ,EACjCQ,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpBE,EAAoBH,EAAc7S,KAClCiT,EAAoBF,EAAc/S,KAClCA,EAAU6S,EAAc7S,KAAxB,IAAgC+S,EAAc/S,KAC9CkT,EAAmB1B,EAAgBqB,EAAeE,GAExD,GAAIC,IAAsBC,EACtB,MAAM,IAAIE,MAAM,8CA2EpB,OAxEAN,EAAchH,OAAOG,QAAQ,SAACyC,GAC1B,IAAM2E,EAAY1G,KAAY+B,EAAME,WACc,IAA9CuE,EAAiB/J,QAAQiK,EAAUpT,OAAiB0S,IACpDU,EAAUpT,KAAU6S,EAAc7S,KAAlC,IAA0CoT,EAAUpT,MAExD2O,EAAOvF,KAAKgK,KAEhBL,EAAclH,OAAOG,QAAQ,SAACyC,GAC1B,IAAM2E,EAAY1G,KAAY+B,EAAME,WACc,IAA9CuE,EAAiB/J,QAAQiK,EAAUpT,MAC9B0S,IACDU,EAAUpT,KAAU+S,EAAc/S,KAAlC,IAA0CoT,EAAUpT,KACpD2O,EAAOvF,KAAKgK,IAGhBzE,EAAOvF,KAAKgK,KAKpBhE,EAAmBmD,EAAIc,YAAa,SAAC5T,GACjC,IAAI6T,GAAW,EACXC,SACJnE,EAAmBoD,EAAIa,YAAa,SAACG,GACjC,IAAMC,KACAC,KACNA,EAAQV,MACRU,EAAQT,MACRJ,EAAchH,OAAOG,QAAQ,SAACyC,GAC1BgF,EAAMrK,KAAKqF,EAAMqC,aAAa3C,KAAK1O,IACnCiU,EAAQV,GAAmBvE,EAAMzO,QAAUyO,EAAMqC,aAAa3C,KAAK1O,KAEvEsT,EAAclH,OAAOG,QAAQ,SAACyC,IAC+B,IAAnDyE,EAAiB/J,QAAQsF,EAAME,SAAS3O,OAAgB0S,GAC1De,EAAMrK,KAAKqF,EAAMqC,aAAa3C,KAAKqF,IAEvCE,EAAQT,GAAmBxE,EAAMzO,QAAUyO,EAAMqC,aAAa3C,KAAKqF,KAEvE,IAAMG,EAAYC,GAAgBF,EAAQV,IACpCa,EAAYD,GAAgBF,EAAQT,IAC1C,GAAIL,EAAmBe,EAAWE,GAAY,CAC1C,IAAMC,KACNL,EAAMzH,QAAQ,SAAC+H,EAASC,GACpBF,EAASnF,EAAOqF,GAAKhU,MAAQ+T,IAE7BT,GAAYxB,EAAMC,QAAUY,EAC5BxE,EAAKoF,GAAeO,GAGpB3F,EAAK/E,KAAK0K,GACVR,GAAW,EACXC,EAAc9T,QAGjB,IAAKkT,IAAab,EAAME,WAAaW,IAAab,EAAMG,cAAgBqB,EAAU,CACnF,IAAMQ,KACFG,EAAMpB,EAAchH,OAAO9G,OAAS,EACxC0O,EAAMzH,QAAQ,SAAC+H,EAASC,GAEhBF,EAASnF,EAAOqF,GAAKhU,MADrBgU,GAAOC,EACsBF,EAGA,OAGrCT,GAAW,EACXC,EAAc9T,EACd0O,EAAK/E,KAAK0K,QAKf,IAAII,GAAU/F,EAAMQ,GAAU3O,SCvGzC,SAASmU,EAAW/N,EAAGO,GACnB,IAAMyN,KAAQhO,EACRiO,KAAQ1N,EACd,OAAIyN,EAAKC,GACG,EAERD,EAAKC,EACE,EAEJ,EAqEJ,SAASC,EAAWC,GAAyB,IAApBC,EAAoBlM,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,GAAX6L,EAIrC,OAHII,EAAIxP,OAAS,GArBrB,SAAS0P,EAAMF,EAAKG,EAAIC,EAAIH,GACxB,GAAIG,IAAOD,EAAM,OAAOH,EAExB,IAAM1D,EAAM6D,EAAK/G,KAAKiH,OAAOD,EAAKD,GAAM,GAKxC,OAJAD,EAAKF,EAAKG,EAAI7D,EAAK2D,GACnBC,EAAKF,EAAK1D,EAAM,EAAG8D,EAAIH,GAzC3B,SAAgBD,EAAKG,EAAI7D,EAAK8D,EAAIH,GAG9B,IAFA,IAAMK,EAAUN,EACVO,KACGrV,EAAIiV,EAAIjV,GAAKkV,EAAIlV,GAAK,EAC3BqV,EAAOrV,GAAKoV,EAAQpV,GAKxB,IAHA,IAAI2G,EAAIsO,EACJ/N,EAAIkK,EAAM,EAELpR,EAAIiV,EAAIjV,GAAKkV,EAAIlV,GAAK,EACvB2G,EAAIyK,GACJgE,EAAQpV,GAAKqV,EAAOnO,GACpBA,GAAK,GACEA,EAAIgO,GACXE,EAAQpV,GAAKqV,EAAO1O,GACpBA,GAAK,GACEoO,EAAOM,EAAO1O,GAAI0O,EAAOnO,KAAO,GACvCkO,EAAQpV,GAAKqV,EAAO1O,GACpBA,GAAK,IAELyO,EAAQpV,GAAKqV,EAAOnO,GACpBA,GAAK,GAqBboO,CAAMR,EAAKG,EAAI7D,EAAK8D,EAAIH,GAEjBD,EAcHE,CAAKF,EAAK,EAAGA,EAAIxP,OAAS,EAAGyP,GAE1BD,0HC3EX,SAASS,EAAWC,EAAUC,EAAU5P,GACpC,IAAI6P,SACJ,OAAQF,GACR,KAAK1S,EAAUC,QACf,KAAKR,EAAiBE,SAEdiT,EADa,SAAbD,EACU,SAAC9O,EAAGO,GAAJ,OAAUA,EAAErB,GAASc,EAAEd,IAEvB,SAACc,EAAGO,GAAJ,OAAUP,EAAEd,GAASqB,EAAErB,IAErC,MACJ,QACI6P,EAAU,SAAC/O,EAAGO,GACV,IAAMyN,KAAQhO,EAAEd,GACV+O,KAAQ1N,EAAErB,GAChB,OAAI8O,EAAKC,EACe,SAAba,EAAsB,GAAK,EAElCd,EAAKC,EACe,SAAba,GAAuB,EAAI,EAE/B,GAGf,OAAOC,EAUX,SAASC,EAAUjH,EAAMlC,GACrB,IAAMoJ,EAAU,IAAIC,IACdC,KAYN,OAVApH,EAAKnC,QAAQ,SAACkF,GACV,IAAMsE,EAAWtE,EAAMjF,GACnBoJ,EAAQI,IAAID,GACZD,EAAYF,EAAQ/U,IAAIkV,IAAW,GAAGpM,KAAK8H,IAE3CqE,EAAYnM,MAAMoM,GAAWtE,KAC7BmE,EAAQK,IAAIF,EAAUD,EAAYxQ,OAAS,MAI5CwQ,EAYX,SAASI,EAAmBC,EAAcC,EAAcC,GACpD,IAAM1N,GACF2N,MAAOH,EAAa,IAQxB,OALAC,EAAaG,OAAO,SAACC,EAAKC,EAAMC,GAE5B,OADAF,EAAIC,GAAQN,EAAa,GAAG3K,IAAI,SAAAiG,GAAA,OAASA,EAAM4E,EAAmBK,GAAK7Q,SAChE2Q,GACR7N,GAEIA,EA0EJ,SAASgO,EAAaC,EAAYhH,EAAYiH,EAAeC,EAAgB1M,GAChF,IAMM2E,GACFG,UACAR,QACAqI,SAEEC,GAPN5M,EAAU1J,OAAOuW,WAHbD,QAAQ,EACRE,YAAY,GAEwB9M,IAOjB4M,OACjBG,EAAaL,GAAkBA,EAAexR,OAAS,EAEvD8R,KAiDN,GA/CgBP,EAAc/G,MAAM,KAE5BvD,QAAQ,SAAC8K,GACb,IAAK,IAAIrX,EAAI,EAAGA,EAAI4W,EAAWtR,OAAQtF,GAAK,EACxC,GAAI4W,EAAW5W,GAAGO,SAAW8W,EAAS,CAClCD,EAAWzN,KAAKiN,EAAW5W,IAC3B,SAMZoX,EAAW7K,QAAQ,SAACyC,GAEhBD,EAAOG,OAAOvF,KAAKqF,EAAME,YAGzB8H,GACAjI,EAAOG,OAAOvF,MACVpJ,KAAM,MACN4O,KAAM,eAIdQ,EAAmBC,EAAY,SAAC5P,GAC5B+O,EAAOL,KAAK/E,SACZ,IAAM2N,EAAYvI,EAAOL,KAAKpJ,OAAS,EAEvC8R,EAAW7K,QAAQ,SAACyC,EAAO+E,GACvBhF,EAAOL,KAAK4I,GAAWvD,EAFf,GAE6B/E,EAAMqC,aAAa3C,KAAK1O,KAE7DgX,IACAjI,EAAOL,KAAK4I,GAAWF,EAAW9R,QAAUtF,GAGhD+O,EAAOgI,KAAKpN,KAAK3J,GAIbmX,GAAcpI,EAAOL,KAAK4I,GAAW3N,KAAK3J,KAI9CmX,GA7HR,SAAkBI,EAAST,GAOvB,IAPuC,IAC/BpI,EAAiB6I,EAAjB7I,KAAMQ,EAAWqI,EAAXrI,OACVsI,SACAC,SACAC,SACA1X,EAAI8W,EAAexR,OAAS,EAEzBtF,GAAK,EAAGA,IACXwX,EAAYV,EAAe9W,GAAG,GAC9ByX,EAAWX,EAAe9W,GAAG,IAC7B0X,EAAWC,GAAczI,EAAQsI,MAO7BzJ,EAAW0J,GAEX5C,EAAUnG,EAAM,SAAC/H,EAAGO,GAAJ,OAAUuQ,EAAS9Q,EAAE+Q,EAAS7R,OAAQqB,EAAEwQ,EAAS7R,UAC1DiI,EAAQ2J,GAAW,WAC1B,IAAM3B,EAAcH,EAAUjH,EAAMgJ,EAAS7R,OACvC+R,EAAYH,EAASA,EAASnS,OAAS,GACvC8Q,EAAeqB,EAASI,MAAM,EAAGJ,EAASnS,OAAS,GACnD+Q,EAAqBD,EAAa5K,IAAI,SAAAsM,GAAA,OAAKH,GAAczI,EAAQ4I,KAEvEhC,EAAYvJ,QAAQ,SAAC4J,GACjBA,EAAaxM,KAAKuM,EAAmBC,EAAcC,EAAcC,MAGrExB,EAAUiB,EAAa,SAACnP,EAAGO,GACvB,IAAM9G,EAAIuG,EAAE,GACNlF,EAAIyF,EAAE,GACZ,OAAO0Q,EAAUxX,EAAGqB,KAIxBiN,EAAKpJ,OAAS,EACdwQ,EAAYvJ,QAAQ,SAACkF,GACjB/C,EAAK/E,KAALqB,MAAA0D,EAAAqJ,EAAatG,EAAM,OAnBG,IAsB1BgG,EAA8C,SAAnCzN,OAAOyN,GAAUpS,cAA2B,OAAS,MAChEwP,EAAUnG,EAAM6G,EAAUmC,EAASvI,KAAMsI,EAAUC,EAAS7R,UAIpE0R,EAAQR,QACRrI,EAAKnC,QAAQ,SAACtL,GACVsW,EAAQR,KAAKpN,KAAK1I,EAAM+W,SA6ExBC,CAASlJ,EAAQ+H,GAGjB1M,EAAQ8M,WAAY,CACpB,IAAMgB,EAAU7L,mBAAA0L,EAAS1L,MAAM0C,EAAOG,OAAO5J,UAASkG,IAAI,sBAC1DuD,EAAOL,KAAKnC,QAAQ,SAACyH,GACjBA,EAAMzH,QAAQ,SAACmC,EAAM1O,GACjBkY,EAAQlY,GAAG2J,KAAK+E,OAGxBK,EAAOL,KAAOwJ,EAGlB,OAAOnJ,EC1NJ,SAASoJ,EAAYrF,EAAKC,GAC7B,IAAMqF,KACAlJ,KACAmJ,KACA3J,KACA0E,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpBiF,EAAwBlF,EAActE,YACtCyJ,EAAwBjF,EAAcxE,YACtCvO,EAAU6S,EAAc7S,KAAxB,UAAsC+S,EAAc/S,KAG1D,IAAK8N,EAAWyE,EAAI0F,eAAe1I,MAAM,KAAKgC,OAAQiB,EAAIyF,eAAe1I,MAAM,KAAKgC,QAChF,OAAO,KAiBX,SAAS2G,EAAkBC,EAAI5J,EAAW6J,GACtChJ,EAAmB+I,EAAG9E,YAAa,SAAC5T,GAChC,IAAMgU,KACF4E,EAAW,GACfP,EAAc9L,QAAQ,SAACsM,GACnB,IAAM5X,EAAQ6N,EAAU+J,GAAYxH,aAAa3C,KAAK1O,GACtD4Y,OAAgB3X,EAChB+S,EAAM6E,GAAc5X,IAEnBmX,EAAUQ,KACPD,GAAWjK,EAAK/E,KAAKqK,GACzBoE,EAAUQ,IAAY,KASlC,OAjCC9F,EAAI0F,eAAe1I,MAAM,KAAMvD,QAAQ,SAACiL,GACrC,IAAMxI,EAAQsJ,EAAsBd,GACpCtI,EAAOvF,KAAKsD,KAAY+B,EAAME,WAC9BmJ,EAAc1O,KAAKqF,EAAME,SAAS3O,QA2BtCkY,EAAkB1F,EAAKwF,GAAuB,GAC9CE,EAAkB3F,EAAKwF,GAAuB,GAEvC,IAAI7D,GAAU/F,EAAMQ,GAAU3O,iIC3DzC,SAASuY,EAAKhE,GACV,IAAIiE,GAAW,EACTC,EAAgBlE,EAAI,aAAczI,MAClC4M,EAASnE,EAAIyB,OAAO,SAAC2C,EAAOvS,GAC9B,OAAIqS,EACOE,EAAM1N,IAAI,SAAC2N,EAAGnZ,GAAJ,OAAUmZ,EAAIxS,EAAE3G,MAErC+Y,EAAWA,GAAmB,OAANpS,EACjBuS,EAAQvS,IAChBqS,EAAgB3M,mBAAA+M,EAAS/M,MAAMyI,EAAI,GAAGxP,UAASkG,IAAI,kBAAM,IAAK,GACjE,OAAOuN,EAAW,KAAOE,EAQ7B,SAASI,GAAKvE,GACV,IAAMkE,EAAgBlE,EAAI,aAAczI,MAClCmI,EAAMM,EAAIxP,QAAU,EACpBgU,EAASR,EAAIhE,GACnB,OAAIkE,EACOM,EAAO9N,IAAI,SAAA2N,GAAA,OAAKA,EAAI3E,IAEb,OAAX8E,EAAkB,KAAOA,EAAS9E,EAqF7C,IAAM+E,IACFT,MACAO,OACAvI,IAhFJ,SAAcgE,GAEV,OADsBA,EAAI,aAAczI,MAE7ByI,EAAIyB,OAAO,SAAC2C,EAAOvS,GAAR,OAAcuS,EAAM1N,IAAI,SAAC2N,EAAGnZ,GAAJ,OAAUkO,KAAK4C,IAAIqI,EAAGxS,EAAE3G,OAClEqM,mBAAA+M,EAAS/M,MAAMyI,EAAI,GAAGxP,UAASkG,IAAI,kBAAMgO,OAEtC1E,EAAI2E,MAAM,SAAAnZ,GAAA,OAAW,OAANA,IAAc,KAAO4N,KAAK4C,IAAL9F,MAAAkD,KAAAkL,EAAYtE,KA2EvD/D,IAnEJ,SAAc+D,GAEV,OADsBA,EAAI,aAAczI,MAE7ByI,EAAIyB,OAAO,SAAC2C,EAAOvS,GAAR,OAAcuS,EAAM1N,IAAI,SAAC2N,EAAGnZ,GAAJ,OAAUkO,KAAK6C,IAAIoI,EAAGxS,EAAE3G,OAClEqM,mBAAA+M,EAAS/M,MAAMyI,EAAI,GAAGxP,UAASkG,IAAI,kBAAM,OAEtCsJ,EAAI2E,MAAM,SAAAnZ,GAAA,OAAW,OAANA,IAAc,KAAO4N,KAAK6C,IAAL/F,MAAAkD,KAAAkL,EAAYtE,KA8DvD4E,MAtDJ,SAAgB5E,GACZ,OAAOA,EAAI,IAsDX6E,KA9CJ,SAAe7E,GACX,OAAOA,EAAIA,EAAIxP,OAAS,IA8CxBsU,MAtCJ,SAAgB9E,GACZ,IAAMkE,EAAgBlE,EAAI,aAAczI,MAClCmI,EAAMM,EAAIxP,OAChB,OAAI0T,EACO3M,mBAAA+M,EAAS/M,MAAMyI,EAAI,GAAGxP,UAASkG,IAAI,kBAAMgJ,IAE7CA,GAiCPqF,IAbJ,SAAc/E,GACV,OAAO5G,KAAK4L,KAZhB,SAAmBhF,GACf,IAAIiF,EAAOV,GAAIvE,GACf,OAAOuE,GAAIvE,EAAItJ,IAAI,SAAAwO,GAAA,OAAA9L,KAAA+L,IAAQD,EAAMD,EAAS,MAUzBG,CAASpF,gQCrGxBqF,cACF,SAAAC,IAAe,IAAAC,EAAA1W,kGAAA2W,CAAA3W,KAAAyW,GACXzW,KAAKuI,MAAQ,IAAI2J,IACjBlS,KAAKuI,MAAM+J,IAAI,aAAc6C,GAE7BpY,OAAO6Z,QAAQhB,IAAQhN,QAAQ,SAAChL,GAC5B8Y,EAAKnO,MAAM+J,IAAI1U,EAAI,GAAIA,EAAI,0DAgB/B,GAAIsH,UAAOvD,OAAQ,CACf,IAAIkV,0CAQJ,MAPuB,mBAAZA,EACP7W,KAAKuI,MAAM+J,IAAI,aAAcuE,GACH,iBAAZA,IACgC,IAA1C9Z,OAAO6I,KAAKgQ,IAAQ7P,QAAQ8Q,IAC5B7W,KAAKuI,MAAM+J,IAAI,aAAcsD,GAAOiB,IAGrC7W,KAGX,OAAOA,KAAKuI,MAAMrL,IAAI,+CAmChBN,EAAMia,GAAS,IAAAC,EAAA9W,KAKrB,MAJoB,iBAATpD,GAAwC,mBAAZia,GACnC7W,KAAKuI,MAAM+J,IAAI1V,EAAMia,GAGlB,WAAQC,EAAKC,aAAana,yCAGvBA,GACNoD,KAAKuI,MAAM8J,IAAIzV,IACfoD,KAAKuI,MAAMyO,OAAOpa,mCAIjBA,GACL,OAAIA,aAAgByL,SACTzL,EAEJoD,KAAKuI,MAAMrL,IAAIN,YAgBfqa,GAZO,WAClB,IAAI1O,EAAQ,KAQZ,OALkB,OAAVA,IACAA,EAAQ,IAAIiO,IAETjO,EAPO,uaCrBtB,SAAS2O,GAASC,EAAWlM,EAAUmM,EAAUC,GAC7C,IAAMC,EApEV,SAAsBH,EAAWlM,GAC7B,IAAMsD,KAEAgJ,EADaJ,EAAUK,uBACC/L,eAwB9B,OArBA1O,OAAO6Z,QAAQW,GAAY3O,QAAQ,SAAA6O,GAAW,IAAT7Z,EAAS8Z,GAAAD,EAAA,MACtCxM,GAAYA,EAAStJ,QACU,IAA3BsJ,EAASlF,QAAQnI,IACjB2Q,EAAOvI,KAAKpI,GAGhB2Q,EAAOvI,KAAKpI,KAeb2Q,EAyCWoJ,CAAYR,EAAWlM,GACnC2M,EAhCV,SAAwBT,GAA0B,IAAfC,EAAelS,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MACxCkG,KACAyM,EAAYT,EAEZU,EADaX,EAAUK,uBACDlM,aACxBuL,EAAUI,GAAac,iBAa3B,MAZwB,mBAAbX,IACPP,EAAUO,GAEdra,OAAO6Z,QAAQkB,GAAUlP,QAAQ,SAAAoP,GAAW,IAATpa,EAAS8Z,GAAAM,EAAA,MACX,iBAAlBZ,EAASxZ,KAChBia,EAAUja,GAAOqZ,GAAagB,QAAQJ,EAAUja,IAAQqZ,GAAagB,QAAQJ,EAAUja,IAAQiZ,GAEtE,mBAAlBO,EAASxZ,KAChBia,EAAUja,QAAOsC,GAErBkL,EAAOxN,GAAOia,EAAUja,IAAQqZ,GAAagB,QAAQH,EAASla,GAAKsa,aAAerB,IAE/EzL,EAcY+M,CAAchB,EAAWC,GACtCnE,EAAakE,EAAUK,uBACvBY,EAAgBnF,EAAW9H,YAC3BkN,EAASpF,EAAWrW,KACpB0b,KACAC,KACAhN,KACA0G,KACAlH,KACFyN,SAEJzb,OAAO6Z,QAAQwB,GAAexP,QAAQ,SAAA6P,GAAkB,IAAAC,EAAAhB,GAAAe,EAAA,GAAhB7a,EAAgB8a,EAAA,GAAXpb,EAAWob,EAAA,KACpB,IAA5BpB,EAAUvR,QAAQnI,IAAega,EAAWha,MAC5C2N,EAAOvF,KAAKsD,KAAYhM,EAAMiO,WAC1BjO,EAAMiO,SAASC,OAASrM,EAAUC,QAClCmZ,EAAWvS,KAAKpI,GACTN,EAAMiO,SAASC,OAASrM,EAAUE,WACzCiZ,EAAatS,KAAKpI,MAK9B,IAAI+a,EAAW,EAoCf,OAnCA3M,EAAmBmL,EAAUlH,YAAa,SAAC5T,GACvC,IAAIuc,EAAO,GACXN,EAAa1P,QAAQ,SAACiQ,GAClBD,EAAUA,EAAV,IAAkBR,EAAcS,GAAGnL,aAAa3C,KAAK1O,UAEnC6D,IAAlB+R,EAAQ2G,IACR3G,EAAQ2G,GAAQD,EAChB5N,EAAK/E,SACLsS,EAAa1P,QAAQ,SAACiQ,GAClB9N,EAAK4N,GAAUE,GAAKT,EAAcS,GAAGnL,aAAa3C,KAAK1O,KAE3Dkc,EAAW3P,QAAQ,SAACiQ,GAChB9N,EAAK4N,GAAUE,IAAMT,EAAcS,GAAGnL,aAAa3C,KAAK1O,MAE5Dsc,GAAY,GAEZJ,EAAW3P,QAAQ,SAACiQ,GAChB9N,EAAKkH,EAAQ2G,IAAOC,GAAG7S,KAAKoS,EAAcS,GAAGnL,aAAa3C,KAAK1O,QAK3E0O,EAAKnC,QAAQ,SAACkQ,GACV,IAAMzI,EAAQyI,EACdP,EAAW3P,QAAQ,SAACiQ,GAChBxI,EAAMwI,GAAKjB,EAAWiB,GAAGC,EAAID,QAGjCxB,GACAA,EAAkB0B,wBAClBP,EAAenB,GAGfmB,EAAe,IAAIQ,GAAUjO,EAAMQ,GAAU3O,KAAMyb,IAEhDG,ECjIJ,SAASS,GAAmB9J,EAAKC,GACpC,IAIM8J,EAAkB9K,EAJFe,EAAIO,gBACJN,EAAIM,iBAK1B,OAAO,SAACa,EAAWE,GACf,IAAI0I,GAAc,EASlB,OARAD,EAAgBtQ,QAAQ,SAACiL,GAGjBsF,IAFA5I,EAAUsD,GAAWvW,QACrBmT,EAAUoD,GAAWvW,QAAS6b,KAM/BA,GCjBR,SAASC,GAAOjK,EAAKC,GACxB,IAAMqF,KACAlJ,KACAmJ,KACA3J,KACA0E,EAAgBN,EAAIO,gBACpBC,EAAgBP,EAAIM,gBACpBiF,EAAwBlF,EAActE,YACtCyJ,EAAwBjF,EAAcxE,YACtCvO,EAAU6S,EAAc7S,KAAxB,UAAsC+S,EAAc/S,KAG1D,IAAK8N,EAAWyE,EAAI0F,eAAe1I,MAAM,KAAKgC,OAAQiB,EAAIyF,eAAe1I,MAAM,KAAKgC,QAChF,OAAO,KAgBX,SAAS2G,EAAmBC,EAAI5J,GAC5Ba,EAAmB+I,EAAG9E,YAAa,SAAC5T,GAChC,IAAMgU,KACF4E,EAAW,GACfP,EAAc9L,QAAQ,SAACsM,GACnB,IAAM5X,EAAQ6N,EAAU+J,GAAYxH,aAAa3C,KAAK1O,GACtD4Y,OAAgB3X,EAChB+S,EAAM6E,GAAc5X,IAEnBmX,EAAUQ,KACXlK,EAAK/E,KAAKqK,GACVoE,EAAUQ,IAAY,KASlC,OAhCC9F,EAAI0F,eAAe1I,MAAM,KAAMvD,QAAQ,SAACiL,GACrC,IAAMxI,EAAQsJ,EAAsBd,GACpCtI,EAAOvF,KAAKsD,KAAY+B,EAAME,WAC9BmJ,EAAc1O,KAAKqF,EAAME,SAAS3O,QA0BtCkY,EAAkB3F,EAAKwF,GACvBG,EAAkB1F,EAAKwF,GAEhB,IAAIoE,GAAUjO,EAAMQ,GAAU3O,SCvDlC,SAASyc,GAAeC,EAAYC,EAAYlK,GACnD,OAAOH,EAAaoK,EAAYC,EAAYlK,GAAU,EAAOX,EAAME,WAGhE,SAAS4K,GAAgBF,EAAYC,EAAYlK,GACpD,OAAOH,EAAaqK,EAAYD,EAAYjK,GAAU,EAAOX,EAAMG,0QCWlD4K,cAQjB,SAAAC,EAAahM,EAAczB,gGAAY0N,CAAA3Z,KAAA0Z,GACnC1Z,KAAK0N,aAAeA,EACpB1N,KAAKiM,WAAaA,8CAUlB,MAAM,IAAI8D,MAAM,wDAUhB,OAAO/P,KAAK0N,aAAanC,sCAUzB,OAAOvL,KAAK0N,aAAa9Q,oCAUzB,OAAOoD,KAAK0N,aAAanC,OAAOC,uCAUhC,OAAOxL,KAAK0N,aAAanC,OAAOqO,8CAUhC,OAAO5Z,KAAK0N,aAAanC,OAAOsO,kDAUhC,OAAO7Z,KAAK0N,aAAanC,OAAOuO,aAAe9Z,KAAK0N,aAAanC,OAAO3O,oCASpE,IAAA8Z,EAAA1W,KACE+K,KAIN,OAHAiB,EAAmBhM,KAAKiM,WAAY,SAAC5P,GACjC0O,EAAK/E,KAAK0Q,EAAKhJ,aAAa3C,KAAK1O,MAE9B0O,qQC1GMgP,irBAAkBN,yCAY/B,OAHKzZ,KAAKga,gBACNha,KAAKga,cAAgBha,KAAKia,uBAEvBja,KAAKga,4DAUZ,MAAM,IAAIjK,MAAM,0RCpBHmK,irBAAoBH,0CASjC,OAAOnb,EAAiBC,0DAUL,IAAAiY,EAAA9W,KACb4Y,EAAO,IAAI7K,IACXf,KAUN,OAPAhB,EAAmBhM,KAAKiM,WAAY,SAAC5P,GACjC,IAAMyR,EAAQgJ,EAAKpJ,aAAa3C,KAAK1O,GAChCuc,EAAKvG,IAAIvE,KACV8K,EAAK5K,IAAIF,GACTd,EAAOhH,KAAK8H,MAGbd,qQChCMmN,irBAAiBJ,sDAQX,IAAAjD,EAAA9W,KACb4Y,EAAO,IAAI7K,IACXf,KAYN,OARAhB,EAAmBhM,KAAKiM,WAAY,SAAC5P,GACjC,IAAMyR,EAAQgJ,EAAKpJ,aAAa3C,KAAK1O,GAChCuc,EAAKvG,IAAIvE,KACV8K,EAAK5K,IAAIF,GACTd,EAAOhH,KAAK8H,MAIbd,yDAUqB,IAAAoN,EAAApa,KACtB4Y,EAAO,IAAI7K,IACbsM,EAAU,EACVC,SACAC,EAAUC,OAAOC,kBAoBrB,OAjBAzO,EAAmBhM,KAAKiM,WAAY,SAAC5P,GACjC,IAAMyR,EAAQsM,EAAK1M,aAAa3C,KAAK1O,GAEjCuc,EAAKvG,IAAIvE,KAGb8K,EAAK5K,IAAIF,GAEJuM,KAKLE,EAAUhQ,KAAK4C,IAAIoN,EAASzM,EAAQwM,GACpCA,EAAYxM,GALRwM,EAAYxM,KAQhBuM,GAAW,EACJ,KAGJE,mCAUP,OAAOva,KAAK0N,aAAanC,OAAOxL,0QCvEnB2a,irBAAeX,sDAS5B,IAAMY,EAAU3a,KAAK0N,aAAanC,OAAOqP,KACzC,OAAQD,EAAQ,GAAIA,EAAQA,EAAQhZ,OAAS,mCAU7C,OAAO3B,KAAK0N,aAAanC,OAAOqP,wQClBnBC,irBAAgBpB,yCAY7B,OAHKzZ,KAAKga,gBACNha,KAAKga,cAAgBha,KAAKia,uBAEvBja,KAAKga,6CAUZ,OAAOha,KAAK0N,aAAanC,OAAOuP,wCAUhC,OAAO9a,KAAK0N,aAAanC,OAAO2M,UXmFb,6CW1ER,IACH6C,EAAiB/a,KAAK0N,aAAanC,OAAnCwP,aACR,OAAOA,aAAwB1S,SAAW0S,EAAelQ,gDAUzD,MAAM,IAAIkF,MAAM,0RCrDHiL,irBAAmBH,0CAShC,OAAO5b,EAAeC,yDAUH,IAAA4X,EAAA9W,KACfmN,EAAMqN,OAAOC,kBACbrN,EAAMoN,OAAOS,kBAajB,OAVAjP,EAAmBhM,KAAKiM,WAAY,SAAC5P,GACjC,IAAMyR,EAAQgJ,EAAKpJ,aAAa3C,KAAK1O,GACjCyR,EAAQX,IACRA,EAAMW,GAENA,EAAQV,IACRA,EAAMU,MAINX,EAAKC,sQCvCA8N,4KAQb,MAAM,IAAInL,MAAM,0RCLHoL,irBAA0BD,sCAQpC/Z,GACH,YAAgBjB,IAARiB,GAA6B,OAARA,EAAgB,KAAOkF,OAAOlF,GAAKia,0QCRnDC,eAOjB,SAAAC,EAAa/P,gGAAQgQ,CAAAvb,KAAAsb,GAAA,IAAA5E,mKAAA8E,CAAAxb,MAAAsb,EAAAG,WAAA1e,OAAA2e,eAAAJ,IAAA9e,KAAAwD,OAAA,OAEjB0W,EAAKnL,OAASA,EACdmL,EAAKiF,KAAO,KAHKjF,qUAPmBwE,sCAoBjC/Z,GACH,OAAInB,KAAKuL,OAAOxL,QACZC,KAAK2b,KAAO3b,KAAK2b,MAAQ,IAAI7b,EAAkBE,KAAKuL,OAAOxL,QACpDC,KAAK2b,KAAKxT,cAAchH,GAAKmJ,YAKhC,IAAI1K,KAAKuB,sQC7BJya,irBAAqBV,sCAQ/B/Z,GACH,GAAY,OAARA,QAAwBjB,IAARiB,EAChB,OAAO,KAGX,IAGM0a,GAFN1a,EAAMkF,OAAOlF,IAEO8G,MAHN,6BAId,OAAK4T,EAIKA,EAAQ,GAAlB,IAAwBA,EAAQ,GAHrB,wQClBEC,irBAAyBZ,sCAQnC/Z,GAEH,OADAA,EAAM4a,WAAW5a,EAAK,IACfqZ,OAAOwB,MAAM7a,GAAO,KAAOA,qQCXrB8a,cAUjB,SAAAC,EAAatf,EAAMmO,EAAMQ,EAAQnJ,gGAAQ+Z,CAAAnc,KAAAkc,GACrClc,KAAKpD,KAAOA,EACZoD,KAAKuL,OAASA,EACdvL,KAAKoC,OAASA,EACdpC,KAAK+K,KAAO/K,KAAKoc,UAAUrR,gDAUpBA,GAAM,IAAA2L,EAAA1W,KACb,OAAO+K,EAAKlD,IAAI,SAAAiG,GAAA,OAAS4I,EAAKtU,OAAOmE,MAAMuH,cCiE5C,SAASuO,GAAaC,EAAY/Q,EAAQgR,GAC7C,IAAMC,KAUN,OARMD,GAAWA,EAAQ5a,SACrB4a,EAAUhR,EAAO1D,IAAI,SAAAiC,GAAA,OAAQA,EAAKlN,QAGtC2f,EAAQ3T,QAAQ,SAAC6T,EAAQpgB,GACrBmgB,EAAWC,GAAUpgB,IAGlBkP,EAAO1D,IAAI,SAAAiC,GAAA,OAzFtB,SAAyBiB,EAAMQ,GAC3BR,EAAOA,MACP,IAAI2C,SAEJ,OAAQnC,EAAOC,MACf,KAAKrM,EAAUC,QACX,OAAQmM,EAAOqO,SACf,KAAK3a,EAAeC,WAGpB,QAEI,OADAwO,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAIuQ,IACxD,IAAId,GAAWtN,EAAf,MAAkC3C,EAAKpJ,OAAS,IAE/D,KAAKxC,EAAUE,UACX,OAAQkM,EAAOqO,SACf,KAAKhb,EAAiBC,YAElB,OADA6O,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAI4P,IACxD,IAAIjB,GAAYxM,EAAhB,MAAmC3C,EAAKpJ,OAAS,IAC5D,KAAK/C,EAAiBE,SAElB,OADA4O,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAI8P,GAAe9P,IACvE,IAAI4O,GAASzM,EAAb,MAAgC3C,EAAKpJ,OAAS,IACzD,KAAK/C,EAAiBI,OAElB,OADA0O,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAIqQ,IACxD,IAAIlB,GAAOhN,EAAX,MAA8B3C,EAAKpJ,OAAS,IACvD,QAEI,OADA+L,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAI4P,IACxD,IAAIjB,GAAYxM,EAAhB,MAAmC3C,EAAKpJ,OAAS,IAEhE,QAEI,OADA+L,EAAe,IAAIuO,GAAa1Q,EAAO3O,KAAMmO,EAAMQ,EAAQ,IAAI4P,IACxD,IAAIjB,GAAYxM,EAAhB,MAAmC3C,EAAKpJ,OAAS,KA0DlC+a,CAAgBJ,EAAWE,EAAW1S,EAAKlN,OAAQkN,KC3GlE,IAAA6S,IACXC,WAAYre,EAAWI,MCuCZ,IAAAke,GAvBf,SAAiB1L,EAAK1K,GAIlBA,EAAU1J,OAAOuW,WAFbwJ,gBAAgB,GAEuBrW,GAE3C,IAAIgW,SACEM,KACA/W,EAAOsC,EAAYyU,GAYzB,OAPIN,EAHAhW,EAAQqW,eAGC3L,EAAI/J,OAAO,EAAG,GAAG,MAK9B+J,EAAIvI,QAAQ,SAAAyC,GAAA,OAASrF,qIAAAgX,CAAQ3R,OAErBoR,EAAQM,ICvChBE,MACAC,MACAC,GAAQ,GACRC,GAAU,GACVC,GAAS,GAEb,SAASC,GAAgBP,GACvB,OAAO,IAAI1U,SAAS,IAAK,WAAa0U,EAAQlV,IAAI,SAASjL,EAAMP,GAC/D,OAAOkhB,KAAKC,UAAU5gB,GAAQ,OAASP,EAAI,MAC1C4G,KAAK,KAAO,KA0BF,IAAAwa,GAAA,SAASC,GACtB,IAAIC,EAAW,IAAIvd,OAAO,KAAQsd,EAAY,SAC1CE,EAAYF,EAAUG,WAAW,GAWrC,SAASC,EAAUxd,EAAM6T,GACvB,IAII5W,EAJAwgB,KACAC,EAAI1d,EAAKqB,OACTsc,EAAI,EACJngB,EAAI,EAEJogB,EAAMF,GAAK,EACXG,GAAM,EAMV,SAASlY,IACP,GAAIiY,EAAK,OAAOhB,GAChB,GAAIiB,EAAK,OAAOA,GAAM,EAAOlB,GAG7B,IAAI5gB,EAAUK,EAAP0hB,EAAIH,EACX,GAAI3d,EAAKud,WAAWO,KAAOjB,GAAO,CAChC,KAAOc,IAAMD,GAAK1d,EAAKud,WAAWI,KAAOd,IAAS7c,EAAKud,aAAaI,KAAOd,KAI3E,OAHK9gB,EAAI4hB,IAAMD,EAAGE,GAAM,GACdxhB,EAAI4D,EAAKud,WAAWI,QAAUb,GAASe,GAAM,EAC9CzhB,IAAM2gB,KAAUc,GAAM,EAAU7d,EAAKud,WAAWI,KAAOb,MAAWa,GACpE3d,EAAK4T,MAAMkK,EAAI,EAAG/hB,EAAI,GAAGkE,QAAQ,MAAO,KAIjD,KAAO0d,EAAID,GAAG,CACZ,IAAKthB,EAAI4D,EAAKud,WAAWxhB,EAAI4hB,QAAUb,GAASe,GAAM,OACjD,GAAIzhB,IAAM2gB,GAAUc,GAAM,EAAU7d,EAAKud,WAAWI,KAAOb,MAAWa,OACtE,GAAIvhB,IAAMkhB,EAAW,SAC1B,OAAOtd,EAAK4T,MAAMkK,EAAG/hB,GAIvB,OAAO6hB,GAAM,EAAM5d,EAAK4T,MAAMkK,EAAGJ,GAGnC,IA7BI1d,EAAKud,WAAWG,EAAI,KAAOZ,MAAWY,EACtC1d,EAAKud,WAAWG,EAAI,KAAOX,MAAUW,GA4BjCzgB,EAAI0I,OAAaiX,IAAK,CAE5B,IADA,IAAIpE,KACGvb,IAAM0f,IAAO1f,IAAM2f,IAAKpE,EAAI9S,KAAKzI,GAAIA,EAAI0I,IAC5CkO,GAA4B,OAAtB2E,EAAM3E,EAAE2E,EAAKhb,OACvBigB,EAAK/X,KAAK8S,GAGZ,OAAOiF,EAgBT,SAASM,EAAUvF,GACjB,OAAOA,EAAIjR,IAAIyW,GAAarb,KAAKya,GAGnC,SAASY,EAAYhe,GACnB,OAAe,MAARA,EAAe,GAChBqd,EAASY,KAAKje,GAAQ,IAAM,IAAOA,EAAKC,QAAQ,KAAM,MAAU,IAChED,EAGR,OACEiG,MAlFF,SAAejG,EAAM6T,GACnB,IAAIqK,EAASzB,EAASgB,EAAOD,EAAUxd,EAAM,SAASwY,EAAKzc,GACzD,GAAImiB,EAAS,OAAOA,EAAQ1F,EAAKzc,EAAI,GACrC0gB,EAAUjE,EAAK0F,EAAUrK,EA9B/B,SAAyB4I,EAAS5I,GAChC,IAAIpW,EAASuf,GAAgBP,GAC7B,OAAO,SAASjE,EAAKzc,GACnB,OAAO8X,EAAEpW,EAAO+a,GAAMzc,EAAG0gB,IA2BM0B,CAAgB3F,EAAK3E,GAAKmJ,GAAgBxE,KAGzE,OADAiF,EAAKhB,QAAUA,MACRgB,GA6EPD,UAAWA,EACX/d,OA1BF,SAAgBge,EAAMhB,GAEpB,OADe,MAAXA,IAAiBA,EA9EzB,SAAsBgB,GACpB,IAAIW,EAAY3hB,OAAOY,OAAO,MAC1Bof,KAUJ,OARAgB,EAAKnV,QAAQ,SAASkQ,GACpB,IAAK,IAAI6F,KAAU7F,EACX6F,KAAUD,GACd3B,EAAQ/W,KAAK0Y,EAAUC,GAAUA,KAKhC5B,EAkE0B6B,CAAab,KACpChB,EAAQlV,IAAIyW,GAAarb,KAAKya,IAAYzP,OAAO8P,EAAKlW,IAAI,SAASiR,GACzE,OAAOiE,EAAQlV,IAAI,SAAS8W,GAC1B,OAAOL,EAAYxF,EAAI6F,MACtB1b,KAAKya,MACNza,KAAK,OAqBT4b,WAlBF,SAAoBd,GAClB,OAAOA,EAAKlW,IAAIwW,GAAWpb,KAAK,SCzGhC6b,GAAMrB,GAAI,KCAVsB,IDEkBD,GAAIvY,MACAuY,GAAIhB,UACPgB,GAAI/e,OACA+e,GAAID,WCLrBpB,GAAI,OAEQsB,GAAIxY,MACAwY,GAAIjB,UACPiB,GAAIhf,OACAgf,GAAIF,WC4BhB,IAAAG,GAXf,SAAiB/U,EAAKxD,GAKlBA,EAAU1J,OAAOuW,WAHbwJ,gBAAgB,EAChBmC,eAAgB,KAEuBxY,GAE3C,IAAMyY,EAAMzB,GAAMhX,EAAQwY,gBAC1B,OAAOpC,GAAOqC,EAAIpB,UAAU7T,GAAMxD,ICoBvB,IAAA0Y,GAxBf,SAAmBhO,GACf,IAAMsL,KACFpgB,EAAI,EACJ+iB,SACErC,KACA/W,EAAOsC,EAAYyU,GAgBzB,OAdA5L,EAAIvI,QAAQ,SAACkB,GACT,IAAMrB,KACN,IAAK,IAAI7K,KAAOkM,EACRlM,KAAO6e,EACP2C,EAAiB3C,EAAO7e,IAExB6e,EAAO7e,GAAOvB,IACd+iB,EAAiB/iB,EAAI,GAEzBoM,EAAO2W,GAAkBtV,EAAKlM,GAElCoI,eAAQyC,MAGJ1L,OAAO6I,KAAK6W,GAASM,ICrBlB,IAAAsC,GAhBf,SAAetU,EAAMtE,GACjB,IAAI6Y,SAEJ,GtCWG,SAAmBne,GACtB,MAAsB,iBAARA,EsCZVoe,CAASxU,GACTuU,EAAYN,QACT,GAAI7U,EAAQY,IAASZ,EAAQY,EAAK,IACrCuU,EAAYzC,OACT,KAAI1S,EAAQY,IAA0B,IAAhBA,EAAKpJ,StCH/B,SAAmBR,GACtB,OAAOA,IAAQpE,OAAOoE,GsCE4Bqe,CAASzU,EAAK,IAG5D,MAAM,IAAIgF,MAAM,mCAFhBuP,EAAYH,GAKhB,OAAOG,EAAUvU,EAAMtE,iiBCX3B,SAASgZ,GAAsBhX,EAAQpM,GACnC,IAAMqjB,KADgCC,GAAA,EAAAC,GAAA,EAAAC,OAAA3f,EAAA,IAEtC,QAAA4f,EAAAC,EAAkBtX,EAAlBrL,OAAA4iB,cAAAL,GAAAG,EAAAC,EAAAjN,QAAAmN,MAAAN,GAAA,EAA0B,KAAjBtU,EAAiByU,EAAAxiB,MACtBoiB,EAAKrU,EAAMzO,QAAU,IAAI8O,EAAML,EAAMqC,aAAa3C,KAAK1O,GAAIgP,IAHzB,MAAA6U,GAAAN,GAAA,EAAAC,EAAAK,EAAA,aAAAP,GAAAI,EAAAI,QAAAJ,EAAAI,SAAA,WAAAP,EAAA,MAAAC,GAKtC,OAAOH,EAGJ,SAASlP,GAAiB/H,GAC7B,IAAMiX,KAEN,OADA3iB,OAAO6I,KAAK6C,GAAQG,QAAQ,SAAChL,GAAU8hB,EAAK9hB,GAAO,IAAI8N,EAAMjD,EAAO7K,GAAMA,KACnE8hB,EAGJ,IAAMU,GAAe,SAAA3I,EAA8B4I,EAAmBC,GAAmB,IAAAC,EAAAC,GAAA/I,EAAA,GAAlExL,EAAkEsU,EAAA,GAAtDrN,EAAsDqN,EAAA,GACxFE,EAASvN,EAAcvR,OAASuR,EAAc/G,MAAM,QACpDuU,EAAkBL,EAAkBlV,YACpCwV,EAAYF,EAAO5Y,IAAI,SAAA+Y,GAAA,OTgCxB,SAAoClT,EAAczB,GAAY,IACzDV,EAAWmC,EAAXnC,OAER,OAAQA,EAAOC,MACf,KAAKrM,EAAUC,QACX,OAAQmM,EAAOqO,SACf,KAAK3a,EAAeC,WAEpB,QACI,OAAO,IAAI8b,GAAWtN,EAAczB,GAE5C,KAAK9M,EAAUE,UACX,OAAQkM,EAAOqO,SACf,KAAKhb,EAAiBC,YAClB,OAAO,IAAIqb,GAAYxM,EAAczB,GACzC,KAAKrN,EAAiBE,SAClB,OAAO,IAAIqb,GAASzM,EAAczB,GACtC,KAAKrN,EAAiBI,OAClB,OAAO,IAAI0b,GAAOhN,EAAczB,GACpC,QACI,OAAO,IAAIiO,GAAYxM,EAAczB,GAE7C,QACI,OAAO,IAAIiO,GAAYxM,EAAczB,ISvDN4U,CAA2BH,EAAgBE,GAAMlT,aAAczB,KAClG,OAAOnB,EAAWE,gBAAgB2V,EAAWL,IAGpCQ,GAAoB,SAACC,EAAOC,GAAuC,IAUvEC,EAV2CxU,EAA4BvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAAfgc,EAAehc,UAAA,GACxEic,SACAH,IAAcvS,GACd0S,GACIC,GAAIJ,EACJK,KAAM5U,EACN6U,SAAUJ,GAEdH,EAAMQ,YAAYvb,KAAKmb,KAGvBA,YAAAK,GAAiBN,IACjBH,EAAMQ,YAAY5f,OAAS,GAC3Bsf,EAAAF,EAAMQ,aAAYvb,KAAlBqB,MAAA4Z,EAAAO,GAA0BL,MA2BrBM,GAAyB,SAACV,EAAOW,GAA4B,IAAhBjV,EAAgBvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAChE8b,EAAYvU,EAAOuU,WAAahS,EAChC2S,EAAkBlV,EAAOkV,kBAAmB,EAC9CC,KAIAA,EAHCF,EAAW/f,OAGN+f,EAAW7Z,IAAI,SAAAga,GAAA,OAAc,SAAC1K,GAChC,IAAMvD,EAAUuD,EAAU2K,UACpBvW,EAASqI,EAAQrI,OACjBwW,EAAe5K,EAAU6K,kBACzBC,EAAc9K,EAAUzH,gBAAgBvE,YACxCJ,EAAO6I,EAAQ7I,KACfiC,EAASjQ,OAAOmlB,OAAOH,GAAcnP,OAAO,SAACC,EAAKsP,GAEpD,OADAtP,EAAIsP,EAAEC,IAAIxlB,MAAQqlB,EAAYE,EAAEC,IAAIxlB,MAAMoQ,SACnC6F,OAGX,OAAO,SAACpK,GAgBJ,QAfiBsC,EAAKpJ,QAAiBoJ,EAAKsX,KAAK,SAAAvJ,GAAA,OAAOvN,EAAOuK,MAAM,SAACwM,GAClE,KAAMA,EAAU1lB,QAAQ6L,GACpB,OAAO,EAEX,IAAMnL,EAAQmL,EAAO6Z,EAAU1lB,MAAM2lB,UACrC,GAAIZ,GAAmBW,EAAU9W,OAASrM,EAAUC,QAChD,OAAO9B,GAAS0P,EAAOsV,EAAU1lB,MAAM,IAAMU,GAAS0P,EAAOsV,EAAU1lB,MAAM,GAGjF,GAAI0lB,EAAU9W,OAASrM,EAAUE,UAC7B,OAAO,EAEX,IAAM0T,EAAMgP,EAAaO,EAAU1lB,MAAMsF,MACzC,OAAO4W,EAAI/F,KAAStK,EAAO6Z,EAAU1lB,MAAM2lB,eAzBpB,CA6BhCV,MA/BI,kBAAM,IAkCjB,IAAIW,SACAxB,IAAchS,EAEdwT,EADoBzB,EAAM0B,OAAM,GAAO,GACXC,OAAO,SAAAja,GAAA,OAAUmZ,EAAI9L,MAAM,SAAA6M,GAAA,OAAMA,EAAGla,OAC5Dma,WAAW,EACXplB,KAAM8B,EAAcG,MAGxB+iB,EAAgBzB,EAAM0B,OAAM,GAAO,GAAOC,OAAO,SAAAja,GAAA,OAAUmZ,EAAIS,KAAK,SAAAM,GAAA,OAAMA,EAAGla,OACzEjL,KAAM8B,EAAcG,IACpBmjB,WAAW,IAInB,OAAOJ,GAGEK,GAAkB,SAACC,EAAUC,EAAUC,EAAcC,GAC9D,IAAMC,EAASJ,EAASL,MAAMQ,EAAYL,WACpC3W,EAjFkB,SAACA,EAAYxD,EAAQsa,EAAUtW,GACvD,IAAM0W,KACFC,GAAqB,EAErBC,SACAC,EAAU,SAAAphB,GAAA,OAAS6gB,EAAStD,GAAqBhX,EAAQvG,GAAQA,IAerE,OAjBeuK,EAATjP,OAGO8B,EAAcE,UACvB8jB,EAAU,SAAAphB,GAAA,OAAU6gB,EAAStD,GAAqBhX,EAAQvG,MAE9D8J,EAAmBC,EAAY,SAAC5P,GACxBinB,EAAQjnB,MACmB,IAAvB+mB,GAA4B/mB,IAAO+mB,EAAoB,GACvDC,EAAKF,EAAcxhB,OAAS,EAC5BwhB,EAAcE,GAASF,EAAcE,GAAIlX,MAAM,KAAK,GAApD,IAA0D9P,GAE1D8mB,EAAcnd,KAAd,GAAsB3J,GAE1B+mB,EAAoB/mB,KAGrB8mB,EAAclgB,KAAK,KA6DPsgB,CACfL,EAAOjT,YACPiT,EAAO1L,uBAAuB/O,OAC9Bsa,EACAC,GASJ,OAPAE,EAAOjT,YAAchE,EACrBiX,EAAOnK,wBAAwByK,wBAE3BP,EAAYL,WACZ9B,GAAkBoC,EAAQzU,GAAyBhC,OAAQuW,GAAgBD,GAGxEG,GAGEO,GAAmB,SAACX,EAAUY,EAAWjX,EAAQkX,GAC1D,IAAMT,EAASJ,EAASL,MAAMhW,EAAOmW,WACjCgB,EAAgBF,EAkBpB,OAjBIjX,EAAOjP,OAAS8B,EAAcE,UAC9BokB,EAAgBD,EAAU9V,OAAO,SAAAgG,GAAA,OAA+C,IAAlC6P,EAAU3d,QAAQ8N,MAIpEqP,EAAOrO,eAAiB+O,EAAc3gB,KAAK,KAC3CigB,EAAOnK,wBAAwByK,wBAE3B/W,EAAOmW,WACP9B,GACIoC,EACAzU,GACEiV,YAAWjX,SAAQoX,gBAAiBD,GACtC,MAIDV,GAGEY,GAAa,SAACC,EAAUhZ,EAAMQ,EAAQ9E,GAC/CA,EAAU1J,OAAOuW,OAAOvW,OAAOuW,UAAWqJ,IAAgBlW,GAC1D,IAAMud,EAAcC,EAAUxd,EAAQmW,YAEtC,IAAMoH,GAAsC,mBAAhBA,EACxB,MAAM,IAAIjU,MAAJ,mCAA6CtJ,EAAQmW,WAArD,WALiD,IAAAsH,EAQ3BF,EAAYjZ,EAAMtE,GARS0d,EAAA3D,GAAA0D,EAAA,GAQpDzH,EARoD0H,EAAA,GAQ5CC,EAR4CD,EAAA,GASrDlZ,EAAWoR,GAAa+H,EAAe7Y,EAAQkR,GAG/C4H,EAAYvZ,EAAWE,gBAAgBC,EAAUxE,EAAQ7J,MAK/D,OAJAmnB,EAASO,mBAAqBD,EAE9BN,EAAS9T,YAAcmU,EAAcziB,QAAUyiB,EAAc,GAAGziB,OAAzC,MAAuDyiB,EAAc,GAAGziB,OAAS,GAAM,GAC9GoiB,EAASlP,eAAkBtJ,EAAO1D,IAAI,SAAAgR,GAAA,OAAKA,EAAEjc,OAAOqG,OAC7C8gB,GAGE/P,GAAgB,SAACzI,EAAQF,GAGlC,IAFA,IAAIhP,EAAI,EAEDA,EAAIkP,EAAO5J,SAAUtF,EACxB,GAAIgP,IAAUE,EAAOlP,GAAGO,KACpB,OACI4O,KAAMD,EAAOlP,GAAGud,SAAWrO,EAAOlP,GAAGmP,KACrCtJ,MAAO7F,GAInB,OAAO,MAgCLkoB,GAAgC,SAAC1C,EAAW1K,GAAc,IAI5BqN,EAAAC,EAJ4BC,EA5B3B,SAACC,GAClC,IAAMC,EAAaD,EAAMpD,YACrBsD,KACA7D,SACJ,GAAI4D,GAAoC,IAAtBA,EAAWjjB,OAEzB,OADAqf,EAAY4D,EAAW,GAAGxD,IAE1B,KAAK3S,EACDoW,GAAUD,EAAW,GAAGtD,UACxB,MACJ,KAAK7S,EACDoW,GAAUD,EAAW,GAAGvD,KAAKwC,iBAC7B,MACJ,KAAKpV,EACDuS,EAAY,UACZ6D,GAAUD,EAAW,GAAGvD,KAAKyD,cAAc3Y,MAAM,KAAMyY,EAAW,GAAGtD,UAO7E,OACIN,YACA6D,UAK0BE,CAAsB5N,GAA5C6J,EADoD0D,EACpD1D,UAAW6D,EADyCH,EACzCG,OACfG,EAAiBnD,EAAU,GAC3BoD,EAAiBpD,EAAU,GAC3Bb,GAAa6D,EAAOljB,SACpBqjB,GAAiBR,EAAA3C,EAAU,IAAGb,GAAb3Z,MAAAmd,EAAAhD,GAA2BqD,GAA3B5W,SACb2U,WAAW,MAEfqC,GAAiBR,EAAA5C,EAAU,IAAGb,GAAb3Z,MAAAod,EAAAjD,GAA2BqD,GAA3B5W,SACb2U,WAAW,OAGnB,OAAQoC,EAAgBC,IAWtBC,GAAuB,SAAvBA,EAAwB/N,EAAW0K,GAA8C,IAAnCpV,EAAmCvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAAtBigB,EAAsBjgB,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAC7EkgB,EAAqBD,EAAaC,mBAClCC,EAAgBF,EAAaE,kBAE/BlO,IAAciO,MAIAC,EAAc1jB,SAA+C,IAAtC0jB,EAActf,QAAQoR,KAElDA,EAAUmO,kBAAkBzD,EAAWpV,GAEnC0K,EAAUoO,UAClB3c,QAAQ,SAAC+b,GAAU,IAAAa,EACejB,GAA8B1C,EAAW8C,GADxDc,EAAAjF,GAAAgF,EAAA,GACnBR,EADmBS,EAAA,GACHR,EADGQ,EAAA,GAExBP,EAAqBP,GAAQK,EAAgBC,GAAiBxY,EAAQ0Y,OA0BjEO,GAA2B,SAACC,EAAaC,EAAYC,EAAgBpZ,GAC9E,IAAI6U,SACAO,SACIiE,EAA4CD,EAA5CC,qBAAsBC,EAAsBF,EAAtBE,kBACxBC,EAAsBH,EAAeI,SACrCC,EAA8BzZ,EAAOyZ,4BAMvCC,KAEJ,GAAoB,OAAhBR,IAA8C,IAAtBlZ,EAAO2Z,WAC/BD,IACI7E,kBAED,KAAAtJ,EACCqO,EAAkBtpB,OAAOmlB,OAAO4D,EAAqBQ,iBAC/B,IAAtBP,IACAM,EAAkBA,EAAgBxY,OAAO,SAAAlR,GAAA,OAAKA,EAAE8P,OAAOwZ,WAAaD,KAGxE,IAAMO,EAAmBF,EAAgBxY,OAjB5B,SAAC2Y,GAEd,OADe/Z,EAAO4C,UAAa,kBAAM,IAC3BmX,EAAO/Z,KAeqC5E,IAAI,SAAA4e,GAAA,OAAUA,EAAOha,OAAO6U,WAEhF+D,KAEN,IAA0B,IAAtBU,EAA6B,CAC7B,IAAMW,EAAwB3pB,OAAOmlB,OAAO4D,EAAqBQ,gBAEjEI,EAAsB9d,QAAQ,SAAC+d,GAC3B,IAAMC,EAAaD,EAAUla,QACI,IAA7Bma,EAAWC,eAA2BD,EAAWH,SAAWha,EAAOga,QAC/DG,EAAWX,WAAaD,IAC5BX,EAAcrf,KAAK2gB,EAAU5F,QAC7BO,EAAWoF,EAAsB7Y,OAAO,SAAAlR,GAAA,OAAKA,IAAMgqB,IAAW9e,IAAI,SAAAlL,GAAA,OAAKA,EAAE8P,OAAO6U,YACvE3f,QAAUwkB,EAAUngB,MACzBsb,WACAwF,OAAQH,EAAU5F,MAClBgG,KA/CU,SAArBC,EAAsBjG,GAAqB,IAAdgG,EAAc7hB,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAKpD,OAJsB,OAAlB6b,EAAMkG,UACNF,EAAK/gB,KAAK+a,GACViG,EAAmBjG,EAAMkG,QAASF,IAE/BA,EA0CmBC,CAAmBL,EAAU5F,YAOnDO,GAAWtJ,MAAG/J,OAAH5G,MAAA2Q,KAAA/J,OAAAuT,GAAiB+E,IAAkBZ,KAAc9X,OAAO,SAAAlR,GAAA,OAAW,OAANA,IACxEwpB,EAAUngB,MACNsb,WACA+D,wBAAmBA,EAAnB7D,GAAqC/U,EAAO4Y,sBAIpD,IAAM6B,EAAYtB,EAAW7E,MAEvBoG,EAAapqB,OAAOuW,QACtB8T,kBAAmBzB,EACnBK,uBACDvZ,GAEG4a,EAAmBzB,EAAW0B,aAChCpB,GAA+BmB,IAC/BxF,EAAYJ,GAAuB4F,EAAkB/F,GACjDK,gBAAiBuE,IAErBhB,GAAqBmC,EAAkBxF,EAAWsF,IAGtDhB,EAAUvd,QAAQ,SAAC2e,GACf,IAAMC,EAAmB/F,GAAuByF,EAAWK,EAAIjG,UACzDyF,EAAOQ,EAAIR,KAEjB,GAAIA,EAAM,CACN,IAAMvE,EA1HO,SAACX,EAAWkF,GACjC,IAAK,IAAI1qB,EAAI,EAAGwU,EAAMkW,EAAKplB,OAAQtF,EAAIwU,EAAKxU,IAAK,CAC7C,IAAM0kB,EAAQgG,EAAK1qB,GACnBwlB,EAAY0C,GAA8B1C,EAAWd,GAEzD,OAAOc,EAqHuB4F,CAAiBD,EAAkBT,EAAKW,WAC9DH,EAAIT,OAAOxB,kBAAkB9C,EAAe2E,QAE5CjC,GAAqBgC,EAAWM,EAAkBL,GAC9C9B,cAAekC,EAAIlC,cACnBD,mBAAoBc,GAA+BmB,iQC8HpDM,cA1dX,SAAAC,iGAAwBC,CAAA7nB,KAAA4nB,GACpB,IAAIE,SAEJ9nB,KAAKinB,QAAU,KACfjnB,KAAKuhB,eACLvhB,KAAKulB,aALe,QAAA/c,EAAAtD,UAAAvD,OAARkjB,EAAQnc,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAARkc,EAAQlc,GAAAzD,UAAAyD,GAOE,IAAlBkc,EAAOljB,SAAkBmmB,EAASjD,EAAO,cAAe+C,GAExD5nB,KAAK6U,eAAiBiT,EAAOjT,eAC7B7U,KAAKiQ,YAAc6X,EAAO7X,YAC1BjQ,KAAKinB,QAAUa,EACf9nB,KAAKskB,mBAAqBtkB,KAAKinB,QAAQ3C,mBACvCtkB,KAAK+nB,gBAAkB1d,IACvBrK,KAAK+Y,wBAAwByK,0BAE7BM,GAAUkE,cAAChoB,MAAXiO,OAAoB4W,IACpB7kB,KAAK+nB,gBAAkB/nB,KAAKskB,mBAAmB1nB,KAC/CoD,KAAK+Y,wBAAwByK,wBAC7BxjB,KAAKioB,uBACD3B,kBACA4B,qEA0BR,OAAOloB,KAAK0P,gBAAgBjH,OAAOZ,IAAI,SAAAlL,GAAA,OAAKA,EAAE4O,6CAY9C,OAAOvL,KAAK+nB,wDAIZ,OAAO/nB,KAAKmoB,4DAMZ,OAFAnoB,KAAKmoB,YAAc/H,IAAcpgB,KAAKiQ,YAAajQ,KAAK6U,gBACnD7U,KAAKwX,uBAAwBxX,KAAK+nB,iBAChC/nB,oDAIP,OAAOA,KAAKskB,gDAiCV8D,EAAU/Y,GACZ,OAAOH,EAAalP,KAAMooB,EAAU/Y,uCAuB3B+Y,GACT,OAAOlZ,EAAalP,KAAMooB,EAAUnP,GAAkBjZ,KAAMooB,IAAW,iCAqBpEC,GACH,OAAOjP,GAAMpZ,KAAMqoB,sCAoBXC,GACR,OAAO9T,EAAWxU,KAAMsoB,kCAmDpBvF,EAAUtW,GACd,IAAM8b,GACF/qB,KAAM8B,EAAcC,OACpBqjB,WAAW,GAITK,GAAgBL,WAFtBnW,EAAS1P,OAAOuW,UAAWiV,EAAW9b,IAEEmW,WACpC4F,SAEA/b,EAAOjP,OAAS8B,EAAcG,IAa9B+oB,GAZiB3F,GACb7iB,KACA+iB,GACEvlB,KAAM8B,EAAcC,QACtB0jB,GAEaJ,GACb7iB,KACA+iB,GACEvlB,KAAM8B,EAAcE,SACtByjB,IAIJuF,EAAM3F,GACF7iB,KACA+iB,EACAtW,EACAwW,GAIR,OAAOuF,oCAsBP,OAAQxoB,KAAKiQ,YAAYtO,SAAW3B,KAAK6U,eAAelT,uCAUhB,IAArCihB,IAAqC1d,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,KAAAA,UAAA,GACpCujB,SACJ,IAAmB,OAFqBvjB,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,KAAAA,UAAA,IAEd,CACtB,IAAM0O,EAAU5T,KAAK8hB,SACjB4G,cAAc,IAEZ3d,EAAO6I,EAAQ7I,KACfQ,EAASqI,EAAQrI,OACjBod,EAAW5d,EAAKlD,IAAI,SAACiR,GACvB,IAAM8P,KAIN,OAHArd,EAAO3C,QAAQ,SAACyC,EAAOhP,GACnBusB,EAAOvd,EAAMzO,MAAQkc,EAAIzc,KAEtBusB,IAEXH,EAAe,IAAIzoB,KAAK6oB,YAAYF,EAAUpd,QAG9Ckd,EAAe,IAAIzoB,KAAK6oB,YAAY7oB,MAMxC,OAHI4iB,GACA5iB,KAAKulB,UAAUvf,KAAKyiB,GAEjBA,kCA8CF/E,EAAWjX,GAChB,IAAM8b,GACF/qB,KAAM8B,EAAcC,OACpBqjB,WAAW,GAEfnW,EAAS1P,OAAOuW,UAAWiV,EAAW9b,GACtC,IAAMqc,EAAc9oB,KAAKgiB,kBACnB2B,EAAY5mB,OAAO6I,KAAKkjB,GACtBtrB,EAASiP,EAATjP,KAEJurB,EAAsBrF,EAAU9Q,OAAO,SAACC,EAAKxH,GAM7C,MAL+B,WAA3BA,EAAMwd,YAAYjsB,KAClBiW,EAAI7M,KAAJqB,MAAAwL,wHAAAmW,CAAYrF,EAAU9V,OAAO,SAAAgG,GAAA,OAA0C,IAA7BA,EAAUoV,OAAO5d,OACpDA,KAASyd,GAChBjW,EAAI7M,KAAKqF,GAENwH,OAGXkW,EAAsBrgB,MAAMI,KAAK,IAAIiF,IAAIgb,IAAsBlhB,IAAI,SAAAwD,GAAA,OAASA,EAAM+P,SAClF,IAAIjE,SAEA3Z,IAAS8B,EAAcG,IASvB0X,GARsBsM,GAAiBzjB,KAAM+oB,GACzCvrB,KAAM8B,EAAcC,OACpBqjB,UAAWnW,EAAOmW,WACnBe,GACkBF,GAAiBzjB,KAAM+oB,GACxCvrB,KAAM8B,EAAcE,QACpBojB,UAAWnW,EAAOmW,WACnBe,IAIHxM,EADsBsM,GAAiBzjB,KAAM+oB,EAAqBtc,EAAQkX,GAI9E,OAAOxM,4CAIP,OAAOnX,KAAKkpB,6DAWZ,OAPAlpB,KAAKkpB,aAAelpB,KAAKmoB,YAAY1f,OAAOmK,OAAO,SAACC,EAAKsW,EAAU9sB,GAK/D,OAJAwW,EAAIsW,EAASvsB,SACTsF,MAAO7F,EACP+lB,KAAOxlB,KAAMusB,EAASvsB,OAAQ4O,KAAM2d,EAAS3d,OAAQoO,QAASuP,EAASvP,YAEpE/G,OAEJ7S,uCAWPA,KAAKinB,QAAQmC,YAAYppB,MACzBA,KAAKinB,QAAU,yCA6BNtC,GACT,IAAI5R,EAAM/S,KAAKulB,UAAU8D,UAAU,SAAAC,GAAA,OAAWA,IAAY3E,KACjD,IAAT5R,GAAa/S,KAAKulB,UAAUne,OAAO2L,EAAK,qCAYjCwW,GAA4B,IAApBC,EAAoBtkB,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MACnC4b,GAAkB9gB,KAAMyO,EAAwB,KAAM+a,GACtDxpB,KAAKinB,QAAUsC,EACfA,EAAOhE,UAAUvf,KAAKhG,6qBC2Cf8Q,eAvdX,SAAAzS,IAAsB,IAAAoZ,+FAAAgS,CAAAzpB,KAAA3B,GAAA,QAAAmK,EAAAtD,UAAAvD,OAANmF,EAAM4B,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAN7B,EAAM6B,GAAAzD,UAAAyD,GAAA,IAAA+N,mKAAAgT,CAAA1pB,MAAAyX,EAAApZ,EAAAod,WAAA1e,OAAA2e,eAAArd,IAAA7B,KAAA6K,MAAAoQ,GAAAzX,MAAAiO,OACTnH,KADS,OAGlB4P,EAAKiT,kBACLjT,EAAKkT,mBAJalT,qUArCFiR,wCAyFXlhB,GAQLA,EAAU1J,OAAOuW,WANbuW,MAAO,MACPxnB,UAAW,KACXynB,SAAS,EACTpB,cAAc,EACdva,SAEoC1H,GACxC,IAAMgC,EAASzI,KAAKwX,uBAAuB/O,OAErCshB,EAAgB/W,EAAYxW,KAC9BwD,KACAA,KAAKwX,uBAAuB/O,OAC5BzI,KAAKiQ,YACLxJ,EAAQiiB,aAAejgB,EAAOZ,IAAI,SAAAlL,GAAA,OAAKA,EAAEC,SAAQqG,OAASjD,KAAK6U,eAC/DpO,EAAQ0H,MAEJoF,WAA8B,WAAlB9M,EAAQojB,MACpBxW,SAAU5M,EAAQqjB,UAI1B,IAAKrjB,EAAQpE,UACT,OAAO0nB,EAxBG,IA2BN1nB,EAAcoE,EAAdpE,UACA0I,EAAuBgf,EAAvBhf,KAAMQ,EAAiBwe,EAAjBxe,OAAQ6H,EAAS2W,EAAT3W,KAChB4W,EAAaze,EAAO1D,IAAK,SAAAxE,GAAA,OAAKA,EAAEzG,OAEhCqtB,EADgBltB,OAAO6I,KAAKvD,GACAuQ,OAAO,SAACC,EAAKC,GAC3C,IAAMC,EAAMiX,EAAWjkB,QAAQ+M,GAI/B,OAHa,IAATC,GACAF,EAAI7M,MAAM+M,EAAK1Q,EAAUyQ,KAEtBD,OAiCX,MA9BsB,WAAlBpM,EAAQojB,MACRI,EAAYrhB,QAAQ,SAACshB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnBnf,EAAKof,GAAMvhB,QAAQ,SAACkF,EAAOuc,GACvBtf,EAAKof,GAAME,GAAYD,EAAM5tB,UACzB0D,EACA4N,EACAsF,EAAKiX,GACL9e,EAAO4e,QAKnBpf,EAAKnC,QAAQ,SAACkF,EAAOuc,GACjBJ,EAAYrhB,QAAQ,SAACshB,GACjB,IAAMC,EAAOD,EAAK,GACZE,EAAQF,EAAK,GAEnBpc,EAAMqc,GAAQC,EAAM5tB,UAChB0D,EACA4N,EAAMqc,GACN/W,EAAKiX,GACL9e,EAAO4e,QAMhBJ,kCA2BFO,GAAwD,IAA7ClT,EAA6ClS,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAA9BuH,EAA8BvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,IAAnB0d,WAAW,GAC/CkC,KAAmBwF,EAAUrnB,OAC/B4hB,GAAU7kB,KAAMsqB,EAAWlT,GACzBoB,EAAetB,GAAAqT,aAAW1F,GAahC,OAXIpY,EAAOmW,YACP5iB,KAAKulB,UAAUvf,KAAKwS,GACpBsI,GACItI,EACA/J,GACE6b,YAAWxF,gBAAe/M,eAAgBd,GAAac,kBACzDX,IAIRoB,EAAayO,QAAUjnB,KAChBwY,+BAsDLrF,GACF,IAAMqX,EAAUxqB,KAAK8hB,SACjB+H,MAAO,MACP1b,KAAMgF,IAGJsX,GADSD,EAAQjf,OAAO1D,IAAI,SAAAwD,GAAA,OAASA,EAAMzO,QACnBqR,OAAOuc,EAAQzf,MAEvC2f,EAAW,IAAI1qB,KAAK6oB,YAAY4B,EAAcD,EAAQjf,QAAUqR,WAAY,WAElF,OADA8N,EAASd,gBAAkBzW,EACpBuX,mCAGDrf,GACN,IAAMwI,EAAYxI,EAAMzO,OACxBoD,KAAK6U,gBAAL,IAA2BhB,EAC3B,IAAMwM,EAAoBrgB,KAAKskB,mBAE/B,GAAKjE,EAAkBlV,YAAYE,EAAMzO,QAElC,CACH,IAAMiM,EAAawX,EAAkB5X,OAAO4gB,UAAU,SAAAsB,GAAA,OAAaA,EAAU/tB,SAAWiX,IACxFhL,GAAc,IAAMwX,EAAkB5X,OAAOI,GAAcwC,QAH3DgV,EAAkB5X,OAAOzC,KAAKqF,GAOlC,OADArL,KAAK+Y,wBAAwByK,wBACtBxjB,+CAoCQuL,EAAQqf,GAA6D,IAAjDne,EAAiDvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,IAAtC0d,WAAW,EAAMiI,YAAY,GACrE9I,EAAe/hB,KAAKgiB,kBACpB8I,EAAUF,EAAW1W,MAAM,EAAG0W,EAAWjpB,OAAS,GAClDopB,EAAaH,EAAWA,EAAWjpB,OAAS,GAElD,GAAIogB,EAAaxW,EAAO3O,QAAU6P,EAAOoe,WACrC,MAAM,IAAI9a,MAASxE,EAAO3O,KAApB,mCAEV,IAAMouB,EAAkBF,EAAQjjB,IAAI,SAACwD,GACjC,IAAM4f,EAAYlJ,EAAa1W,GAC/B,IAAK4f,EAED,MAAM,IAAIlb,MAAS1E,EAAb,gCAEV,OAAO4f,EAAU/oB,QAGjBugB,EAAQziB,KAAKyiB,QAEXyI,EAAKzI,EAAM/S,gBAAgBjH,OAC3B0iB,EAAiBH,EAAgBnjB,IAAI,SAAAkL,GAAA,OAAOmY,EAAGnY,KAE/CqY,KACNpf,EAAmByW,EAAMxS,YAAa,SAAC5T,GACnC,IAAMgvB,EAAaF,EAAetjB,IAAI,SAAAwD,GAAA,OAASA,EAAMqC,aAAa3C,KAAK1O,KACvE+uB,EAAe/uB,GAAK0uB,qIAAAO,CAAcD,GAAdpd,QAA0B5R,EAAG6uB,OAzB+B,IAAAK,EA2BpElP,IAAc+O,IAAkB7f,IAAUA,EAAO3O,OAA1DyO,EA3B6EmgB,GAAAD,EAAA,MAkCpF,OANA9I,EAAMgJ,SAASpgB,GAEXoB,EAAOmW,WACP9B,GAAkB2B,EAAOhU,GAA0BhC,OAAQlB,EAAQ9C,OAAQqiB,GAAWC,GAGnFtI,oCAWAkD,GAA2D,IAA9ClZ,EAA8CvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAAjCwmB,EAAiCxmB,UAAA,GAAjBiiB,EAAiBjiB,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAC5DymB,EAAkBlf,EAAOkf,gBACzB3F,EAAsBvZ,EAAOwZ,SAC7B2F,EAAUnf,EAAOmf,QACjB1E,EFpHkB,SAAnB2E,EAAoB9K,GAC7B,OAAIA,EAAMkG,QACC4E,EAAiB9K,EAAMkG,SAE3BlG,EEgHe8K,CAAiB7rB,MAC7B8lB,EAAuBoB,EAAUe,sBAEjCrC,GACF0B,aF/HuB,SAAtBwE,EAAuB/K,GAChC,OAAIA,EAAMkG,SAAWlG,EAAMQ,YAAYwK,KAAK,SAAApvB,GAAA,MAAc,UAATA,EAAEykB,KACxC0K,EAAoB/K,EAAMkG,SAE9BlG,EEyHsB+K,CAAoB9rB,MAGzC+gB,MAAOmG,GAgBX,OAbAwE,GFL0B,SAAC5F,GAA6C,IAAvBrZ,EAAuBvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MAAV6b,EAAU7b,UAAA,GACxE8mB,SACEL,EAAkBlf,EAAOkf,gBACzBrK,EAAW7U,EAAO6U,SAClB1jB,EAAS6O,EAAOga,OAAhB,IAA0Bha,EAAOwZ,SAGnC+F,EADAL,EACkB7F,EAAqBQ,eAErBR,EAAqBoC,iBAG1B,OAAb5G,SACO0K,EAAgBpuB,GAEvBouB,EAAgBpuB,IACZmjB,QACAtU,UEZcwf,CAAmBnG,EAAsBrZ,EAAQzM,MACnE0lB,GAAyBC,EAAaC,GAAcE,uBAAsBG,SAAUD,GAChFjpB,OAAOuW,QACHsY,WACDnf,IAEHkf,GF/B6B,SAAC7F,EAAsBF,EAAYC,GACxE,IAAMqC,EAAmBpC,EAAqBoC,iBAE9C,IAAK,IAAMzB,KAAUyB,EAAkB,CACnC,IACMtB,EADYsB,EAAiBzB,GACNha,OACvBuZ,EAAsBH,EAAepZ,OAAOwZ,SAC5CiG,GAAwBrG,EAAesB,WAAW+E,uBACpDrG,EAAesB,WAAW+E,sBAAsBtF,EAAYf,EAAepZ,QAC/E,GAAIma,EAAWX,WAAaD,GAAuBkG,EAAuB,CACtE,IAAMC,EAAgBvF,EAAWtF,SACjCoE,GAAyByG,EAAevG,GACpCE,uBACAC,mBAAmB,EACnBE,SAAUD,GACXY,KEiBHwF,CAA0BtG,EAAsBF,GAC5CnZ,SACA0a,eAIDnnB,gCAUPqsB,EAAWngB,GACX,OAAQmgB,GACR,InC7amB,cmC8afrsB,KAAK2pB,eAAe3jB,KAAKkG,GAG7B,OAAOlM,yCASEqsB,GACT,OAAQA,GACR,InC5bmB,cmC6bfrsB,KAAK2pB,kBAIT,OAAO3pB,+CAUQ6hB,EAAW+J,GAAS,IAAA9U,EAAA9W,KACfA,KAAK2pB,eACX/gB,QAAQ,SAAA+Z,GAAA,OAAMA,EAAGnmB,KAAKsa,EAAM+K,EAAW+J,iCAqDpDU,GAA6B,IAAd7f,EAAcvH,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,MACxBud,EAAQziB,KAAKyiB,QACb8J,EAAe9f,EAAO7P,MAAW0vB,EAAlB,UACrB,GAAItsB,KAAKgiB,kBAAkBuK,KAAkBvsB,KAAKgiB,kBAAkBsK,GAChE,MAAM,IAAIvc,MAAJ,SAAmBuc,EAAnB,oBAEV,IACME,EAAUhgB,EADFxM,KAAKskB,mBAAmB7b,OAAOsjB,KAAK,SAAAU,GAAA,OAAaA,EAAU7vB,SAAW0vB,IACvCtsB,KAAKiQ,YAAaxD,GACzDigB,EAAWrQ,IAAcmQ,EAAQzhB,QAE/BnO,KAAM2vB,EACN/gB,KAAMrM,EAAUE,UAChBua,QAAShb,EAAiBI,OAC1B4b,MACIpZ,MAAOgrB,EAAQhrB,MACfiM,IAAK+e,EAAQ/e,QAEhB8e,IAAe,GAGxB,OAFA9J,EAAMgJ,SAASiB,GACf5L,GAAkB2B,EAAOhU,GAAsB6d,gBAAe7f,SAAQ8f,gBAAgB,MAC/E9J,qCAlcP,OAAOxL,YCtFA0V,GAAoD/W,GAApDT,IAAKyX,GAA+ChX,GAA/CF,IAAKmX,GAA0CjX,GAA1CzI,IAAK2f,GAAqClX,GAArCxI,IAAK2f,GAAgCnX,GAAhCG,MAAOiX,GAAyBpX,GAAzBI,KAAMiX,GAAmBrX,GAAnBK,MAAYiX,GAAOtX,GAAZM,YCqBvDpF,GAAUqc,WACNC,QC6LmB,mBAAAC,EAAAnoB,UAAAvD,OAAI2rB,EAAJ5kB,MAAA2kB,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAID,EAAJC,GAAAroB,UAAAqoB,GAAA,OACnB,SAACxY,GAAqC,IAC9ByY,EAAYzY,EACZ0Y,SACEC,KACA9K,GAJ4B1d,UAAAvD,OAAA,QAAAzB,IAAAgF,UAAA,GAAAA,UAAA,IAAtB0d,WAAW,IAIEA,UAezB,OAbA0K,EAAW1kB,QAAQ,SAACoY,GAChBwM,EAAYxM,EAAUwM,GACtBE,EAAY1nB,KAAZqB,MAAAqmB,wHAAAC,CAAoBH,EAAUjM,cACzBkM,IACDA,EAAYD,KAIpB5K,GAAa4K,EAAUI,UAAU7Y,EAAI2Y,GACjCA,EAAY/rB,OAAS,GACrB8rB,EAAUI,UAGPL,IDhNXM,IC2He,mBAAAC,EAAA7oB,UAAAvD,OAAImF,EAAJ4B,MAAAqlB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIlnB,EAAJknB,GAAA9oB,UAAA8oB,GAAA,OAAa,SAAAjZ,GAAA,OAAMA,EAAG+Y,IAAHzmB,MAAA0N,EAAUjO,KD1H5C4b,OC+BkB,mBAAAla,EAAAtD,UAAAvD,OAAImF,EAAJ4B,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAI7B,EAAJ6B,GAAAzD,UAAAyD,GAAA,OAAa,SAAAoM,GAAA,OAAMA,EAAG2N,OAAHrb,MAAA0N,EAAajO,KD9BlDmnB,QC8DmB,mBAAAC,EAAAhpB,UAAAvD,OAAImF,EAAJ4B,MAAAwlB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIrnB,EAAJqnB,GAAAjpB,UAAAipB,GAAA,OAAa,SAAApZ,GAAA,OAAMA,EAAGkZ,QAAH5mB,MAAA0N,EAAcjO,KD7DpDyjB,QCqJmB,mBAAA6D,EAAAlpB,UAAAvD,OAAImF,EAAJ4B,MAAA0lB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIvnB,EAAJunB,GAAAnpB,UAAAmpB,GAAA,OAAa,SAAAtZ,GAAA,OAAMA,EAAGwV,QAAHljB,MAAA0N,EAAcjO,KDpJpDwnB,kBEtB6B,mBAAA9lB,EAAAtD,UAAAvD,OAAImF,EAAJ4B,MAAAF,GAAAG,EAAA,EAAAA,EAAAH,EAAAG,IAAI7B,EAAJ6B,GAAAzD,UAAAyD,GAAA,OAAa,SAAAoM,GAAA,OAAMA,EAAGuZ,kBAAHjnB,MAAA0N,EAAwBjO,KFuBxEqH,KEdgB,mBAAA+f,EAAAhpB,UAAAvD,OAAImF,EAAJ4B,MAAAwlB,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAIrnB,EAAJqnB,GAAAjpB,UAAAipB,GAAA,OAAa,SAAApZ,GAAA,OAAMA,EAAG5G,KAAH9G,MAAA0N,EAAWjO,KFe9CoI,eACAqf,WAAA/Z,EACAga,YG9BG,SAAsBlV,EAAYC,GACrC,OAAOrK,EAAaoK,EAAYC,EAAYN,GAAkBK,EAAYC,IAAa,IH8BvFF,iBACAG,kBACAiV,c3BvBG,SAAwBnV,EAAYC,EAAYlK,GACnD,OAAO+J,GAAMC,GAAcC,EAAYC,EAAYlK,GAAWmK,GAAeF,EAAYC,EAAYlK,K2BuBrGqf,MAAAtV,IAEJtI,GAAU6d,MAAQC,EAClB7xB,OAAOuW,OAAOxC,GAAW+d,GACzB/d,GAAUhR,kBAAoBA,EAC9BgR,GAAUge,WAAavwB,EACvBuS,GAAUie,cAAgBzvB,EAC1BwR,GAAUke,QAAUC,GAAID,QAET,IAAAhW,GAAAkW,EAAA","file":"datamodel.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"DataModel\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"DataModel\"] = factory();\n\telse\n\t\troot[\"DataModel\"] = factory();\n})(window, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 1);\n","const DataModel = require('./export');\n\nmodule.exports = DataModel.default ? DataModel.default : DataModel;\n","/**\n * DataFormat Enum defines the format of the input data.\n * Based on the format of the data the respective adapter is loaded.\n *\n * @readonly\n * @enum {string}\n */\nconst DataFormat = {\n    FLAT_JSON: 'FlatJSON',\n    DSV_STR: 'DSVStr',\n    DSV_ARR: 'DSVArr',\n    AUTO: 'Auto'\n};\n\nexport default DataFormat;\n","/**\n * DimensionSubtype enum defines the sub types of the Dimensional Field.\n *\n * @readonly\n * @enum {string}\n */\nconst DimensionSubtype = {\n    CATEGORICAL: 'categorical',\n    TEMPORAL: 'temporal',\n    GEO: 'geo',\n    BINNED: 'binned'\n};\n\nexport default DimensionSubtype;\n","/**\n * MeasureSubtype enum defines the sub types of the Measure Field.\n *\n * @readonly\n * @enum {string}\n */\nconst MeasureSubtype = {\n    CONTINUOUS: 'continuous'\n};\n\nexport default MeasureSubtype;\n","/**\n * FieldType enum defines the high level field based on which visuals are controlled.\n * Measure in a high level is numeric field and Dimension in a high level is string field.\n *\n * @readonly\n * @enum {string}\n */\nconst FieldType = {\n    MEASURE: 'measure',\n    DIMENSION: 'dimension'\n};\n\nexport default FieldType;\n","/**\n * Filtering mode enum defines the filering modes of DataModel.\n *\n * @readonly\n * @enum {string}\n */\nconst FilteringMode = {\n    NORMAL: 'normal',\n    INVERSE: 'inverse',\n    ALL: 'all'\n};\n\nexport default FilteringMode;\n","/**\n * Creates a JS native date object from input\n *\n * @param {string | number | Date} date Input using which date object to be created\n * @return {Date} : JS native date object\n */\nfunction convertToNativeDate (date) {\n    if (date instanceof Date) {\n        return date;\n    }\n\n    return new Date(date);\n}\n/**\n * Apply padding before a number if its less than 1o. This is used when constant digit's number to be returned\n * between 0 - 99\n *\n * @param {number} n Input to be padded\n * @return {string} Padded number\n */\nfunction pad (n) {\n    return (n < 10) ? (`0${n}`) : n;\n}\n/*\n * DateFormatter utility to convert any date format to any other date format\n * DateFormatter parse a date time stamp specified by a user abiding by rules which are defined\n * by user in terms of token. It creates JS native date object from the user specified format.\n * That native date can also be displayed\n * in any specified format.\n * This utility class only takes care of format conversion only\n */\n\n/*\n * Escapes all the special character that are used in regular expression.\n * Like\n * RegExp.escape('sgfd-$') // Output: sgfd\\-\\$\n *\n * @param text {String} : text which is to be escaped\n */\nRegExp.escape = function (text) {\n    return text.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n};\n\n/**\n * DateTimeFormatter class to convert any user format of date time stamp to any other format\n * of date time stamp.\n *\n * @param {string} format Format of the date given. For the above date,\n * 'year: %Y, month: %b, day: %d'.\n * @class\n */\n/* istanbul ignore next */ function DateTimeFormatter (format) {\n    this.format = format;\n    this.dtParams = undefined;\n    this.nativeDate = undefined;\n}\n\n// The identifier of the tokens\nDateTimeFormatter.TOKEN_PREFIX = '%';\n\n// JS native Date constructor takes the date params (year, month, etc) in a certail sequence.\n// This defines the sequence of the date parameters in the constructor.\nDateTimeFormatter.DATETIME_PARAM_SEQUENCE = {\n    YEAR: 0,\n    MONTH: 1,\n    DAY: 2,\n    HOUR: 3,\n    MINUTE: 4,\n    SECOND: 5,\n    MILLISECOND: 6\n};\n\n/*\n * This is a default number parsing utility. It tries to parse a number in integer, if parsing is unsuccessful, it\n * gives back a default value.\n *\n * @param: defVal {Number} : Default no if the parsing to integer is not successful\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be parsed.\n */\nDateTimeFormatter.defaultNumberParser = function (defVal) {\n    return function (val) {\n        let parsedVal;\n        if (isFinite(parsedVal = parseInt(val, 10))) {\n            return parsedVal;\n        }\n\n        return defVal;\n    };\n};\n\n/*\n * This is a default number range utility. It tries to find an element in the range. If not found it returns a\n * default no as an index.\n *\n * @param: range {Array} : The list which is to be serached\n * @param: defVal {Number} : Default no if the serach and find does not return anything\n * @return {Function} : An closure function which is to be called by passing an the value which needs to be found\n */\nDateTimeFormatter.defaultRangeParser = function (range, defVal) {\n    return (val) => {\n        let i;\n        let l;\n\n        if (!val) { return defVal; }\n\n        const nVal = val.toLowerCase();\n\n        for (i = 0, l = range.length; i < l; i++) {\n            if (range[i].toLowerCase() === nVal) {\n                return i;\n            }\n        }\n\n        if (i === undefined) {\n            return defVal;\n        }\n        return null;\n    };\n};\n\n/*\n * Defines the tokens which are supporter by the dateformatter. Using this definitation a value gets extracted from\n * the user specifed date string. This also formats the value for display purpose from native JS date.\n * The definition of each token contains the following named properties\n * {\n *     %token_name% : {\n *         name: name of the token, this is used in reverse lookup,\n *         extract: a function that returns the regular expression to extract that piece of information. All the\n *                  regex should be gouped by using ()\n *         parser: a function which receives value extracted by the above regex and parse it to get the date params\n *         formatter: a formatter function that takes milliseconds or JS Date object and format the param\n *                  represented by the token only.\n *     }\n * }\n *\n * @return {Object} : Definition of the all the supported tokens.\n */\nDateTimeFormatter.getTokenDefinitions = function () {\n    const daysDef = {\n        short: [\n            'Sun',\n            'Mon',\n            'Tue',\n            'Wed',\n            'Thu',\n            'Fri',\n            'Sat'\n        ],\n        long: [\n            'Sunday',\n            'Monday',\n            'Tuesday',\n            'Wednesday',\n            'Thursday',\n            'Friday',\n            'Saturday'\n        ]\n    };\n    const monthsDef = {\n        short: [\n            'Jan',\n            'Feb',\n            'Mar',\n            'Apr',\n            'May',\n            'Jun',\n            'Jul',\n            'Aug',\n            'Sep',\n            'Oct',\n            'Nov',\n            'Dec'\n        ],\n        long: [\n            'January',\n            'February',\n            'March',\n            'April',\n            'May',\n            'June',\n            'July',\n            'August',\n            'September',\n            'October',\n            'November',\n            'December'\n        ]\n    };\n\n    const definitions = {\n        H: {\n            // 24 hours format\n            name: 'H',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n\n                return d.getHours().toString();\n            }\n        },\n        l: {\n            // 12 hours format\n            name: 'l',\n            index: 3,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours() % 12;\n\n                return (hours === 0 ? 12 : hours).toString();\n            }\n        },\n        p: {\n            // AM or PM\n            name: 'p',\n            index: 3,\n            extract () { return '(AM|PM)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'AM' : 'PM');\n            }\n        },\n        P: {\n            // am or pm\n            name: 'P',\n            index: 3,\n            extract () { return '(am|pm)'; },\n            parser: (val) => {\n                if (val) {\n                    return val.toLowerCase();\n                }\n                return null;\n            },\n            formatter: (val) => {\n                const d = convertToNativeDate(val);\n                const hours = d.getHours();\n\n                return (hours < 12 ? 'am' : 'pm');\n            }\n        },\n        M: {\n            // Two digit minutes 00 - 59\n            name: 'M',\n            index: 4,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const mins = d.getMinutes();\n\n                return pad(mins);\n            }\n        },\n        S: {\n            // Two digit seconds 00 - 59\n            name: 'S',\n            index: 5,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const seconds = d.getSeconds();\n\n                return pad(seconds);\n            }\n        },\n        K: {\n            // Milliseconds\n            name: 'K',\n            index: 6,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const ms = d.getMilliseconds();\n\n                return ms.toString();\n            }\n        },\n        a: {\n            // Short name of day, like Mon\n            name: 'a',\n            index: 2,\n            extract () { return `(${daysDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.short[day]).toString();\n            }\n        },\n        A: {\n            // Long name of day, like Monday\n            name: 'A',\n            index: 2,\n            extract () { return `(${daysDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(daysDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDay();\n\n                return (daysDef.long[day]).toString();\n            }\n        },\n        e: {\n            // 8 of March, 11 of November\n            name: 'e',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return day.toString();\n            }\n        },\n        d: {\n            // 08 of March, 11 of November\n            name: 'd',\n            index: 2,\n            extract () { return '(\\\\d+)'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const day = d.getDate();\n\n                return pad(day);\n            }\n        },\n        b: {\n            // Short month, like Jan\n            name: 'b',\n            index: 1,\n            extract () { return `(${monthsDef.short.join('|')})`; },\n            parser: DateTimeFormatter.defaultRangeParser(monthsDef.short),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.short[month]).toString();\n            }\n        },\n        B: {\n            // Long month, like January\n            name: 'B',\n            index: 1,\n            extract () { return `(${monthsDef.long.join('|')})`; },\n            parser: DateTimeFormatter.defaultNumberParser(monthsDef.long),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return (monthsDef.long[month]).toString();\n            }\n        },\n        m: {\n            // Two digit month of year like 01 for January\n            name: 'm',\n            index: 1,\n            extract () { return '(\\\\d+)'; },\n            parser (val) { return DateTimeFormatter.defaultNumberParser()(val) - 1; },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const month = d.getMonth();\n\n                return pad(month + 1);\n            }\n        },\n        y: {\n            // Short year like 90 for 1990\n            name: 'y',\n            index: 0,\n            extract () { return '(\\\\d{4})'; },\n            parser (val) {\n                if (val) {\n                    const l = val.length;\n                    val = val.substring(l - 2, l);\n                }\n\n                return DateTimeFormatter.defaultNumberParser()(val);\n            },\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                let year = d.getFullYear().toString();\n                let l;\n\n                if (year) {\n                    l = year.length;\n                    year = year.substring(l - 2, l);\n                }\n\n                return year;\n            }\n        },\n        Y: {\n            // Long year like 1990\n            name: 'Y',\n            index: 0,\n            extract () { return '(\\\\d{4})'; },\n            parser: DateTimeFormatter.defaultNumberParser(),\n            formatter (val) {\n                const d = convertToNativeDate(val);\n                const year = d.getFullYear().toString();\n\n                return year;\n            }\n        }\n    };\n\n    return definitions;\n};\n\n/*\n * The tokens which works internally is not user friendly in terms of memorizing the names. This gives a formal\n * definition to the informal notations.\n *\n * @return {Object} : Formal definition of the tokens\n */\nDateTimeFormatter.getTokenFormalNames = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n\n    return {\n        HOUR: definitions.H,\n        HOUR_12: definitions.l,\n        AMPM_UPPERCASE: definitions.p,\n        AMPM_LOWERCASE: definitions.P,\n        MINUTE: definitions.M,\n        SECOND: definitions.S,\n        SHORT_DAY: definitions.a,\n        LONG_DAY: definitions.A,\n        DAY_OF_MONTH: definitions.e,\n        DAY_OF_MONTH_CONSTANT_WIDTH: definitions.d,\n        SHORT_MONTH: definitions.b,\n        LONG_MONTH: definitions.B,\n        MONTH_OF_YEAR: definitions.m,\n        SHORT_YEAR: definitions.y,\n        LONG_YEAR: definitions.Y\n    };\n};\n\n/*\n * This defines the rules and declares dependencies that resolves a date parameter (year, month etc) from\n * the date time parameter array.\n *\n * @return {Object} : An object that contains dependencies and a resolver function. The dependencies values are fed\n *                  to the resolver function in that particular sequence only.\n */\nDateTimeFormatter.tokenResolver = function () {\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const defaultResolver = (...args) => { // eslint-disable-line require-jsdoc\n        let i = 0;\n        let arg;\n        let targetParam;\n        const l = args.length;\n\n        for (; i < l; i++) {\n            arg = args[i];\n            if (args[i]) {\n                targetParam = arg;\n            }\n        }\n\n        if (!targetParam) { return null; }\n\n        return targetParam[0].parser(targetParam[1]);\n    };\n\n    return {\n        YEAR: [definitions.y, definitions.Y,\n            defaultResolver\n        ],\n        MONTH: [definitions.b, definitions.B, definitions.m,\n            defaultResolver\n        ],\n        DAY: [definitions.a, definitions.A, definitions.e, definitions.d,\n            defaultResolver\n        ],\n        HOUR: [definitions.H, definitions.l, definitions.p, definitions.P,\n            function (hourFormat24, hourFormat12, ampmLower, ampmUpper) {\n                let targetParam;\n                let amOrpm;\n                let isPM;\n                let val;\n\n                if (hourFormat12 && (amOrpm = (ampmLower || ampmUpper))) {\n                    if (amOrpm[0].parser(amOrpm[1]) === 'pm') {\n                        isPM = true;\n                    }\n\n                    targetParam = hourFormat12;\n                } else if (hourFormat12) {\n                    targetParam = hourFormat12;\n                } else {\n                    targetParam = hourFormat24;\n                }\n\n                if (!targetParam) { return null; }\n\n                val = targetParam[0].parser(targetParam[1]);\n                if (isPM) {\n                    val += 12;\n                }\n                return val;\n            }\n        ],\n        MINUTE: [definitions.M,\n            defaultResolver\n        ],\n        SECOND: [definitions.S,\n            defaultResolver\n        ]\n    };\n};\n\n/*\n * Finds token from the format rule specified by a user.\n * @param format {String} : The format of the input date specified by the user\n * @return {Array} : An array of objects which contains the available token and their occurence index in the format\n */\nDateTimeFormatter.findTokens = function (format) {\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenLiterals = Object.keys(definitions);\n    const occurrence = [];\n    let i;\n    let forwardChar;\n\n    while ((i = format.indexOf(tokenPrefix, i + 1)) >= 0) {\n        forwardChar = format[i + 1];\n        if (tokenLiterals.indexOf(forwardChar) === -1) { continue; }\n\n        occurrence.push({\n            index: i,\n            token: forwardChar\n        });\n    }\n\n    return occurrence;\n};\n\n/*\n * Format any JS date to a specified date given by user.\n *\n * @param date {Number | Date} : The date object which is to be formatted\n * @param format {String} : The format using which the date will be formatted for display\n */\nDateTimeFormatter.formatAs = function (date, format) {\n    const nDate = convertToNativeDate(date);\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    let formattedStr = String(format);\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    let token;\n    let formattedVal;\n    let i;\n    let l;\n\n    for (i = 0, l = occurrence.length; i < l; i++) {\n        token = occurrence[i].token;\n        formattedVal = definitions[token].formatter(nDate);\n        formattedStr = formattedStr.replace(new RegExp(tokenPrefix + token, 'g'), formattedVal);\n    }\n\n    return formattedStr;\n};\n\n/*\n * Parses the user specified date string to extract the date time params.\n *\n * @return {Array} : Value of date time params in an array [year, month, day, hour, minutes, seconds, milli]\n */\nDateTimeFormatter.prototype.parse = function (dateTimeStamp, options) {\n    const tokenResolver = DateTimeFormatter.tokenResolver();\n    const dtParams = this.extractTokenValue(dateTimeStamp);\n    const dtParamSeq = DateTimeFormatter.DATETIME_PARAM_SEQUENCE;\n    const noBreak = options && options.noBreak;\n    const dtParamArr = [];\n    const args = [];\n    let resolverKey;\n    let resolverParams;\n    let resolverFn;\n    let val;\n    let i;\n    let param;\n    let resolvedVal;\n    let l;\n\n    for (resolverKey in tokenResolver) {\n        if (!{}.hasOwnProperty.call(tokenResolver, resolverKey)) { continue; }\n\n        args.length = 0;\n        resolverParams = tokenResolver[resolverKey];\n        resolverFn = resolverParams.splice(resolverParams.length - 1, 1)[0];\n\n        for (i = 0, l = resolverParams.length; i < l; i++) {\n            param = resolverParams[i];\n            val = dtParams[param.name];\n\n            if (val === undefined) {\n                args.push(null);\n            } else {\n                args.push([param, val]);\n            }\n        }\n\n        resolvedVal = resolverFn.apply(this, args);\n\n        if ((resolvedVal === undefined || resolvedVal === null) && !noBreak) {\n            break;\n        }\n\n        dtParamArr[dtParamSeq[resolverKey]] = resolvedVal;\n    }\n\n    return dtParamArr;\n};\n\n/*\n * Extract the value of the token from user specified date time string.\n *\n * @return {Object} : An key value pair which contains the tokens as key and value as pair\n */\nDateTimeFormatter.prototype.extractTokenValue = function (dateTimeStamp) {\n    const format = this.format;\n    const definitions = DateTimeFormatter.getTokenDefinitions();\n    const tokenPrefix = DateTimeFormatter.TOKEN_PREFIX;\n    const occurrence = DateTimeFormatter.findTokens(format);\n    const tokenObj = {};\n\n    let lastOccurrenceIndex;\n    let occObj;\n    let occIndex;\n    let targetText;\n    let regexFormat;\n\n    let l;\n    let i;\n\n    regexFormat = String(format);\n\n    const tokenArr = occurrence.map(obj => obj.token);\n    const occurrenceLength = occurrence.length;\n    for (i = occurrenceLength - 1; i >= 0; i--) {\n        occIndex = occurrence[i].index;\n\n        if (occIndex + 1 === regexFormat.length - 1) {\n            lastOccurrenceIndex = occIndex;\n            continue;\n        }\n\n        if (lastOccurrenceIndex === undefined) {\n            lastOccurrenceIndex = regexFormat.length;\n        }\n\n        targetText = regexFormat.substring(occIndex + 2, lastOccurrenceIndex);\n        regexFormat = regexFormat.substring(0, occIndex + 2) +\n            RegExp.escape(targetText) +\n            regexFormat.substring(lastOccurrenceIndex, regexFormat.length);\n\n        lastOccurrenceIndex = occIndex;\n    }\n\n    for (i = 0; i < occurrenceLength; i++) {\n        occObj = occurrence[i];\n        regexFormat = regexFormat.replace(tokenPrefix + occObj.token, definitions[occObj.token].extract());\n    }\n\n    const extractValues = dateTimeStamp.match(new RegExp(regexFormat)) || [];\n    extractValues.shift();\n\n    for (i = 0, l = tokenArr.length; i < l; i++) {\n        tokenObj[tokenArr[i]] = extractValues[i];\n    }\n    return tokenObj;\n};\n\n/*\n * Give back the JS native date formed from  user specified date string\n *\n * @return {Date} : Native JS Date\n */\nDateTimeFormatter.prototype.getNativeDate = function (dateTimeStamp) {\n    if (dateTimeStamp instanceof Date) {\n        return dateTimeStamp;\n    } else if (isFinite(dateTimeStamp) && !!this.format) {\n        return new Date(dateTimeStamp);\n    }\n\n    const dtParams = this.dtParams = this.parse(dateTimeStamp);\n\n    dtParams.unshift(null);\n    this.nativeDate = new (Function.prototype.bind.apply(Date, dtParams))();\n    return this.nativeDate;\n};\n\n/*\n * Represents JS native date to a user specified format.\n *\n * @param format {String} : The format according to which the date is to be represented\n * @return {String} : The formatted date string\n */\nDateTimeFormatter.prototype.formatAs = function (format, dateTimeStamp) {\n    let nativeDate;\n\n    if (dateTimeStamp) {\n        nativeDate = this.nativeDate = this.getNativeDate(dateTimeStamp);\n    } else if (!(nativeDate = this.nativeDate)) {\n        nativeDate = this.getNativeDate(dateTimeStamp);\n    }\n\n    return DateTimeFormatter.formatAs(nativeDate, format);\n};\n\nexport { DateTimeFormatter as default };\n","/**\n * The utility function to calculate major column.\n *\n * @param {Object} store - The store object.\n * @return {Function} Returns the push function.\n */\nexport default (store) => {\n    let i = 0;\n    return (...fields) => {\n        fields.forEach((val, fieldIndex) => {\n            if (!(store[fieldIndex] instanceof Array)) {\n                store[fieldIndex] = Array.from({ length: i });\n            }\n            store[fieldIndex].push(val);\n        });\n        i++;\n    };\n};\n","/* eslint-disable */\nconst OBJECTSTRING = 'object';\nconst objectToStrFn = Object.prototype.toString;\nconst objectToStr = '[object Object]';\nconst arrayToStr = '[object Array]';\n\nfunction checkCyclicRef(obj, parentArr) {\n    let i = parentArr.length;\n    let bIndex = -1;\n\n    while (i) {\n        if (obj === parentArr[i]) {\n            bIndex = i;\n            return bIndex;\n        }\n        i -= 1;\n    }\n\n    return bIndex;\n}\n\nfunction merge(obj1, obj2, skipUndef, tgtArr, srcArr) {\n    var item,\n        srcVal,\n        tgtVal,\n        str,\n        cRef;\n    // check whether obj2 is an array\n    // if array then iterate through it's index\n    // **** MOOTOOLS precution\n\n    if (!srcArr) {\n        tgtArr = [obj1];\n        srcArr = [obj2];\n    }\n    else {\n        tgtArr.push(obj1);\n        srcArr.push(obj2);\n    }\n\n    if (obj2 instanceof Array) {\n        for (item = 0; item < obj2.length; item += 1) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (typeof tgtVal !== OBJECTSTRING) {\n                if (!(skipUndef && tgtVal === undefined)) {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                    srcVal = obj1[item] = tgtVal instanceof Array ? [] : {};\n                }\n                cRef = checkCyclicRef(tgtVal, srcArr);\n                if (cRef !== -1) {\n                    srcVal = obj1[item] = tgtArr[cRef];\n                }\n                else {\n                    merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                }\n            }\n        }\n    }\n    else {\n        for (item in obj2) {\n            try {\n                srcVal = obj1[item];\n                tgtVal = obj2[item];\n            }\n            catch (e) {\n                continue;\n            }\n\n            if (tgtVal !== null && typeof tgtVal === OBJECTSTRING) {\n                // Fix for issue BUG: FWXT-602\n                // IE < 9 Object.prototype.toString.call(null) gives\n                // '[object Object]' instead of '[object Null]'\n                // that's why null value becomes Object in IE < 9\n                str = objectToStrFn.call(tgtVal);\n                if (str === objectToStr) {\n                    if (srcVal === null || typeof srcVal !== OBJECTSTRING) {\n                        srcVal = obj1[item] = {};\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else if (str === arrayToStr) {\n                    if (srcVal === null || !(srcVal instanceof Array)) {\n                        srcVal = obj1[item] = [];\n                    }\n                    cRef = checkCyclicRef(tgtVal, srcArr);\n                    if (cRef !== -1) {\n                        srcVal = obj1[item] = tgtArr[cRef];\n                    }\n                    else {\n                        merge(srcVal, tgtVal, skipUndef, tgtArr, srcArr);\n                    }\n                }\n                else {\n                    obj1[item] = tgtVal;\n                }\n            }\n            else {\n                if (skipUndef && tgtVal === undefined) {\n                    continue;\n                }\n                obj1[item] = tgtVal;\n            }\n        }\n    }\n    return obj1;\n}\n\n\nfunction extend2 (obj1, obj2, skipUndef) {\n    //if none of the arguments are object then return back\n    if (typeof obj1 !== OBJECTSTRING && typeof obj2 !== OBJECTSTRING) {\n        return null;\n    }\n\n    if (typeof obj2 !== OBJECTSTRING || obj2 === null) {\n        return obj1;\n    }\n\n    if (typeof obj1 !== OBJECTSTRING) {\n        obj1 = obj2 instanceof Array ? [] : {};\n    }\n    merge(obj1, obj2, skipUndef);\n    return obj1;\n}\n\nexport { extend2 as default };\n","/**\n * Checks whether the value is an array.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an array otherwise returns false.\n */\nexport function isArray (val) {\n    return Array.isArray(val);\n}\n\n/**\n * Checks whether the value is an object.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is an object otherwise returns false.\n */\nexport function isObject (val) {\n    return val === Object(val);\n}\n\n/**\n * Checks whether the value is a string value.\n *\n * @param  {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is a string value otherwise returns false.\n */\nexport function isString (val) {\n    return typeof val === 'string';\n}\n\n/**\n * Checks whether the value is callable.\n *\n * @param {*} val - The value to be checked.\n * @return {boolean} Returns true if the value is callable otherwise returns false.\n */\nexport function isCallable (val) {\n    return typeof val === 'function';\n}\n\n/**\n * Returns the unique values from the input array.\n *\n * @param {Array} data - The input array.\n * @return {Array} Returns a new array of unique values.\n */\nexport function uniqueValues (data) {\n    return [...new Set(data)];\n}\n\nexport const getUniqueId = () => `id-${new Date().getTime()}${Math.round(Math.random() * 10000)}`;\n\nconst unique = arr => ([...new Set(arr)]);\n\n/**\n * Gets the minimum difference between two consecutive numbers  in an array.\n * @param {Array} arr Array of numbers\n * @param {number} index index of the value\n * @return {number} minimum difference between values\n */\nexport const getMinDiff = (arr, index) => {\n    let diff;\n    let uniqueVals;\n    if (index !== undefined) {\n        uniqueVals = unique(arr.map(d => d[index]));\n    } else {\n        uniqueVals = unique(arr);\n    }\n    if (uniqueVals.length > 1) {\n        diff = Math.abs(uniqueVals[1] - uniqueVals[0]);\n        for (let i = 2, len = uniqueVals.length; i < len; i++) {\n            diff = Math.min(diff, Math.abs(uniqueVals[i] - uniqueVals[i - 1]));\n        }\n    } else {\n        diff = uniqueVals[0];\n    }\n\n    return diff;\n};\n\n/**\n * Checks Whether two arrays have same content.\n *\n * @param {Array} arr1 - The first array.\n * @param {Array} arr2 - The 2nd array.\n * @return {boolean} Returns whether two array have same content.\n */\nexport function isArrEqual(arr1, arr2) {\n    if (!isArray(arr1) || !isArray(arr2)) {\n        return arr1 === arr2;\n    }\n\n    if (arr1.length !== arr2.length) {\n        return false;\n    }\n\n    for (let i = 0; i < arr1.length; i++) {\n        if (arr1[i] !== arr2[i]) {\n            return false;\n        }\n    }\n\n    return true;\n}\n\n/**\n * Checks Whether two arrays have same content.\n *\n * @param {Array} arr1 - The first array.\n * @param {Array} arr2 - The 2nd array.\n * @return {boolean} Returns whether two array have same content.\n */\nexport function formatNumber(val) {\n    return val;\n}\n","import { FieldType } from './enums';\nimport { getUniqueId } from './utils';\n\nconst fieldStore = {\n    data: {},\n\n    createNamespace (fieldArr, name) {\n        const dataId = name || getUniqueId();\n        this.data[dataId] = {\n            name: dataId,\n            fields: fieldArr,\n            fieldsObj () {\n                const retObj = {};\n                this.fields.forEach((field) => {\n                    retObj[field.name()] = field;\n                });\n                return retObj;\n            },\n            getMeasure () {\n                const retObj = {};\n                this.fields.forEach((field) => {\n                    if (field.schema().type === FieldType.MEASURE) {\n                        retObj[field.name()] = field;\n                    }\n                });\n                return retObj;\n            },\n            getDimension () {\n                const retObj = {};\n                this.fields.forEach((field) => {\n                    if (field.schema().type === FieldType.DIMENSION) {\n                        retObj[field.name()] = field;\n                    }\n                });\n                return retObj;\n            },\n        };\n        return this.data[dataId];\n    },\n};\n\nexport default fieldStore;\n","/**\n * The wrapper class on top of the primitive value of a field.\n *\n * @todo Need to have support for StringValue, NumberValue, DateTimeValue\n * and GeoValue. These types should expose predicate API mostly.\n */\nclass Value {\n\n  /**\n   * Creates new Value instance.\n   *\n   * @param {*} val - the primitive value from the field cell.\n   * @param {string | Field} field - The field from which the value belongs.\n   */\n    constructor (val, field) {\n        Object.defineProperty(this, '_value', {\n            enumerable: false,\n            configurable: false,\n            writable: false,\n            value: val\n        });\n\n        this.field = field;\n    }\n\n  /**\n   * Returns the field value.\n   *\n   * @return {*} Returns the current value.\n   */\n    get value () {\n        return this._value;\n    }\n\n  /**\n   * Converts to human readable string.\n   *\n   * @override\n   * @return {string} Returns a human readable string of the field value.\n   *\n   */\n    toString () {\n        return String(this.value);\n    }\n\n  /**\n   * Returns the value of the field.\n   *\n   * @override\n   * @return {*} Returns the field value.\n   */\n    valueOf () {\n        return this.value;\n    }\n}\n\nexport default Value;\n","/**\n * Iterates through the diffSet array and call the callback with the current\n * index.\n *\n * @param {string} rowDiffset - The row diffset string e.g. '0-4,6,10-13'.\n * @param {Function} callback - The callback function to be called with every index.\n */\nexport function rowDiffsetIterator (rowDiffset, callback) {\n    if (rowDiffset.length > 0) {\n        const rowDiffArr = rowDiffset.split(',');\n        rowDiffArr.forEach((diffStr) => {\n            const diffStsArr = diffStr.split('-');\n            const start = +(diffStsArr[0]);\n            const end = +(diffStsArr[1] || diffStsArr[0]);\n            if (end >= start) {\n                for (let i = start; i <= end; i += 1) {\n                    callback(i);\n                }\n            }\n        });\n    }\n}\n","import { rowDiffsetIterator } from './row-diffset-iterator';\n\n/**\n * Creates bin f from the data and the supplied config.\n *\n * @param {Array} data - The input data.\n * @param {Object} config - The config object.\n * @param {number} config.binSize - The size of the bin.\n * @param {number} config.numOfBins - The number of bins to be created.\n * @return {Array} Returns an array of created bins.\n */\nexport function createBinnedFieldData (field, rowDiffset, config) {\n    let { buckets, binCount, binSize, start } = config;\n    let dataStore = [];\n    let binnedData = [];\n    let [min, max] = field.domain();\n    let oriMax = max;\n    let stops = [];\n    let binEnd;\n    let prevEndpoint;\n    let mid;\n    let range;\n\n    // create dataStore with index according to rowDiffSet\n    rowDiffsetIterator(rowDiffset, (i) => {\n        dataStore.push({\n            data: field.partialField.data[i],\n            index: i\n        });\n    });\n\n    // create buckets if buckets not given\n    if (!buckets) {\n        max += 1;\n        binSize = binSize || (max - min) / binCount;\n\n        const extraBinELm = (max - min) % binSize;\n        if (!binCount && extraBinELm !== 0) {\n            max = max + binSize - extraBinELm;\n        }\n        binEnd = min + binSize;\n        while (binEnd <= max) {\n            stops.push(binEnd);\n            binEnd += binSize;\n        }\n        start = start || min;\n        buckets = { start, stops };\n    }\n\n    // initialize intial bucket start\n    prevEndpoint = buckets.start === 0 ? 0 : buckets.start || min;\n\n    // mark each data in dataStore to respective buckets\n    buckets.stops.forEach((endPoint) => {\n        let tempStore = dataStore.filter(datum => datum.data >= prevEndpoint && datum.data < endPoint);\n        tempStore.forEach((datum) => { binnedData[datum.index] = `${prevEndpoint}-${endPoint}`; });\n        prevEndpoint = endPoint;\n    });\n\n    // create a bin for values less than start\n    dataStore.filter(datum => datum.data < buckets.start)\n                    .forEach((datum) => { binnedData[datum.index] = `${min}-${buckets.start}`; });\n\n    // create a bin for values more than end\n    dataStore.filter(datum => datum.data >= buckets.stops[buckets.stops.length - 1])\n                    .forEach((datum) =>\n                    { binnedData[datum.index] = `${buckets.stops[buckets.stops.length - 1]}-${oriMax}`; });\n\n    // create range and mid\n    // append start to bucket marks\n    buckets.stops.unshift(buckets.start);\n    range = new Set(buckets.stops);\n\n    // Add endpoints to buckets marks if not added\n    if (min < buckets.start) { range.add(min); }\n    if (oriMax > buckets.stops[buckets.stops.length - 1]) { range.add(oriMax); }\n\n    range = [...range].sort((a, b) => a - b);\n    mid = [];\n\n    for (let i = 1; i < range.length; i++) {\n        mid.push((range[i - 1] + range[i]) / 2);\n    }\n    return { data: binnedData, mid, range };\n}\n","/**\n * The helper function that returns an array of common schema\n * from two fieldStore instances.\n *\n * @param {FieldStore} fs1 - The first FieldStore instance.\n * @param {FieldStore} fs2 - The second FieldStore instance.\n * @return {Array} An array containing the common schema.\n */\nexport function getCommonSchema (fs1, fs2) {\n    const retArr = [];\n    const fs1Arr = [];\n    fs1.fields.forEach((field) => {\n        fs1Arr.push(field.schema().name);\n    });\n    fs2.fields.forEach((field) => {\n        if (fs1Arr.indexOf(field.schema().name) !== -1) {\n            retArr.push(field.schema().name);\n        }\n    });\n    return retArr;\n}\n","export { DataFormat, FilteringMode } from '../enums';\n/**\n * The event name for data propagation.\n */\nexport const PROPAGATION = 'propagation';\n\n/**\n * The name of the unique row id column in DataModel.\n */\nexport const ROW_ID = '__id__';\n\n/**\n * The enums for operation names performed on DataModel.\n */\nexport const DM_DERIVATIVES = {\n    SELECT: 'select',\n    PROJECT: 'project',\n    GROUPBY: 'group',\n    COMPOSE: 'compose',\n    CAL_VAR: 'calculatedVariable',\n    BIN: 'bin'\n};\n\nexport const JOINS = {\n    CROSS: 'cross',\n    LEFTOUTER: 'leftOuter',\n    RIGHTOUTER: 'rightOuter',\n    NATURAL: 'natural',\n    FULLOUTER: 'fullOuter'\n};\n\nexport const LOGICAL_OPERATORS = {\n    AND: 'and',\n    OR: 'or'\n};\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { getCommonSchema } from './get-common-schema';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { JOINS } from '../constants';\nimport { prepareJoinData } from '../helper';\n/**\n * Default filter function for crossProduct.\n *\n * @return {boolean} Always returns true.\n */\nfunction defaultFilterFn() { return true; }\n\n/**\n * Implementation of cross product operation between two DataModel instances.\n * It internally creates the data and schema for the new DataModel.\n *\n * @param {DataModel} dataModel1 - The left DataModel instance.\n * @param {DataModel} dataModel2 - The right DataModel instance.\n * @param {Function} filterFn - The filter function which is used to filter the tuples.\n * @param {boolean} [replaceCommonSchema=false] - The flag if the common name schema should be there.\n * @return {DataModel} Returns The newly created DataModel instance from the crossProduct operation.\n */\nexport function crossProduct (dm1, dm2, filterFn, replaceCommonSchema = false, jointype = JOINS.CROSS) {\n    const schema = [];\n    const data = [];\n    const applicableFilterFn = filterFn || defaultFilterFn;\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreName = dm1FieldStore.name;\n    const dm2FieldStoreName = dm2FieldStore.name;\n    const name = `${dm1FieldStore.name}.${dm2FieldStore.name}`;\n    const commonSchemaList = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    if (dm1FieldStoreName === dm2FieldStoreName) {\n        throw new Error('DataModels must have different alias names');\n    }\n    // Here prepare the schema\n    dm1FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1 && !replaceCommonSchema) {\n            tmpSchema.name = `${dm1FieldStore.name}.${tmpSchema.name}`;\n        }\n        schema.push(tmpSchema);\n    });\n    dm2FieldStore.fields.forEach((field) => {\n        const tmpSchema = extend2({}, field.schema());\n        if (commonSchemaList.indexOf(tmpSchema.name) !== -1) {\n            if (!replaceCommonSchema) {\n                tmpSchema.name = `${dm2FieldStore.name}.${tmpSchema.name}`;\n                schema.push(tmpSchema);\n            }\n        } else {\n            schema.push(tmpSchema);\n        }\n    });\n\n    // Here prepare Data\n    rowDiffsetIterator(dm1._rowDiffset, (i) => {\n        let rowAdded = false;\n        let rowPosition;\n        rowDiffsetIterator(dm2._rowDiffset, (ii) => {\n            const tuple = [];\n            const userArg = {};\n            userArg[dm1FieldStoreName] = {};\n            userArg[dm2FieldStoreName] = {};\n            dm1FieldStore.fields.forEach((field) => {\n                tuple.push(field.partialField.data[i]);\n                userArg[dm1FieldStoreName][field.name()] = field.partialField.data[i];\n            });\n            dm2FieldStore.fields.forEach((field) => {\n                if (!(commonSchemaList.indexOf(field.schema().name) !== -1 && replaceCommonSchema)) {\n                    tuple.push(field.partialField.data[ii]);\n                }\n                userArg[dm2FieldStoreName][field.name()] = field.partialField.data[ii];\n            });\n            const dm1Fields = prepareJoinData(userArg[dm1FieldStoreName]);\n            const dm2Fields = prepareJoinData(userArg[dm2FieldStoreName]);\n            if (applicableFilterFn(dm1Fields, dm2Fields)) {\n                const tupleObj = {};\n                tuple.forEach((cellVal, iii) => {\n                    tupleObj[schema[iii].name] = cellVal;\n                });\n                if (rowAdded && JOINS.CROSS !== jointype) {\n                    data[rowPosition] = tupleObj;\n                }\n                else {\n                    data.push(tupleObj);\n                    rowAdded = true;\n                    rowPosition = i;\n                }\n            }\n            else if ((jointype === JOINS.LEFTOUTER || jointype === JOINS.RIGHTOUTER) && !rowAdded) {\n                const tupleObj = {};\n                let len = dm1FieldStore.fields.length - 1;\n                tuple.forEach((cellVal, iii) => {\n                    if (iii <= len) {\n                        tupleObj[schema[iii].name] = cellVal;\n                    }\n                    else {\n                        tupleObj[schema[iii].name] = null;\n                    }\n                });\n                rowAdded = true;\n                rowPosition = i;\n                data.push(tupleObj);\n            }\n        });\n    });\n\n    return new DataModel(data, schema, { name });\n}\n","/**\n * The default sort function.\n *\n * @param {*} a - The first value.\n * @param {*} b - The second value.\n * @return {number} Returns the comparison result e.g. 1 or 0 or -1.\n */\nfunction defSortFn (a, b) {\n    const a1 = `${a}`;\n    const b1 = `${b}`;\n    if (a1 < b1) {\n        return -1;\n    }\n    if (a1 > b1) {\n        return 1;\n    }\n    return 0;\n}\n\n/**\n * The helper function for merge sort which creates the sorted array\n * from the two halves of the input array.\n *\n * @param {Array} arr - The target array which needs to be merged.\n * @param {number} lo - The starting index of the first array half.\n * @param {number} mid - The ending index of the first array half.\n * @param {number} hi - The ending index of the second array half.\n * @param {Function} sortFn - The sort function.\n */\nfunction merge (arr, lo, mid, hi, sortFn) {\n    const mainArr = arr;\n    const auxArr = [];\n    for (let i = lo; i <= hi; i += 1) {\n        auxArr[i] = mainArr[i];\n    }\n    let a = lo;\n    let b = mid + 1;\n\n    for (let i = lo; i <= hi; i += 1) {\n        if (a > mid) {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        } else if (b > hi) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else if (sortFn(auxArr[a], auxArr[b]) <= 0) {\n            mainArr[i] = auxArr[a];\n            a += 1;\n        } else {\n            mainArr[i] = auxArr[b];\n            b += 1;\n        }\n    }\n}\n\n/**\n * The helper function for merge sort which would be called\n * recursively for sorting the array halves.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {number} lo - The starting index of the array half.\n * @param {number} hi - The ending index of the array half.\n * @param {Function} sortFn - The sort function.\n * @return {Array} Returns the target array itself.\n */\nfunction sort (arr, lo, hi, sortFn) {\n    if (hi === lo) { return arr; }\n\n    const mid = lo + Math.floor((hi - lo) / 2);\n    sort(arr, lo, mid, sortFn);\n    sort(arr, mid + 1, hi, sortFn);\n    merge(arr, lo, mid, hi, sortFn);\n\n    return arr;\n}\n\n/**\n * The implementation of merge sort.\n * It is used in DataModel for stable sorting as it is not sure\n * what the sorting algorithm used by browsers is stable or not.\n *\n * @param {Array} arr - The target array which needs to be sorted.\n * @param {Function} [sortFn=defSortFn] - The sort function.\n * @return {Array} Returns the input array itself in sorted order.\n */\nexport function mergeSort (arr, sortFn = defSortFn) {\n    if (arr.length > 1) {\n        sort(arr, 0, arr.length - 1, sortFn);\n    }\n    return arr;\n}\n","import { FieldType, DimensionSubtype } from '../enums';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { mergeSort } from './merge-sort';\nimport { fieldInSchema } from '../helper';\nimport { isCallable, isArray, } from '../utils';\n/**\n * Generates the sorting functions to sort the data of a DataModel instance\n * according to the input data type.\n *\n * @param {string} dataType - The data type e.g. 'measure', 'datetime' etc.\n * @param {string} sortType - The sorting order i.e. 'asc' or 'desc'.\n * @param {integer} index - The index of the data which will be sorted.\n * @return {Function} Returns the the sorting function.\n */\nfunction getSortFn (dataType, sortType, index) {\n    let retFunc;\n    switch (dataType) {\n    case FieldType.MEASURE:\n    case DimensionSubtype.TEMPORAL:\n        if (sortType === 'desc') {\n            retFunc = (a, b) => b[index] - a[index];\n        } else {\n            retFunc = (a, b) => a[index] - b[index];\n        }\n        break;\n    default:\n        retFunc = (a, b) => {\n            const a1 = `${a[index]}`;\n            const b1 = `${b[index]}`;\n            if (a1 < b1) {\n                return sortType === 'desc' ? 1 : -1;\n            }\n            if (a1 > b1) {\n                return sortType === 'desc' ? -1 : 1;\n            }\n            return 0;\n        };\n    }\n    return retFunc;\n}\n\n/**\n * Groups the data according to the specified target field.\n *\n * @param {Array} data - The input data array.\n * @param {number} fieldIndex - The target field index within schema array.\n * @return {Array} Returns an array containing the grouped data.\n */\nfunction groupData(data, fieldIndex) {\n    const hashMap = new Map();\n    const groupedData = [];\n\n    data.forEach((datum) => {\n        const fieldVal = datum[fieldIndex];\n        if (hashMap.has(fieldVal)) {\n            groupedData[hashMap.get(fieldVal)][1].push(datum);\n        } else {\n            groupedData.push([fieldVal, [datum]]);\n            hashMap.set(fieldVal, groupedData.length - 1);\n        }\n    });\n\n    return groupedData;\n}\n\n/**\n * Creates the argument value used for sorting function when sort is done\n * with another fields.\n *\n * @param {Array} groupedDatum - The grouped datum for a single dimension field value.\n * @param {Array} targetFields - An array of the sorting fields.\n * @param {Array} targetFieldDetails - An array of the sorting field details in schema.\n * @return {Object} Returns an object containing the value of sorting fields and the target field name.\n */\nfunction createSortingFnArg(groupedDatum, targetFields, targetFieldDetails) {\n    const arg = {\n        label: groupedDatum[0]\n    };\n\n    targetFields.reduce((acc, next, idx) => {\n        acc[next] = groupedDatum[1].map(datum => datum[targetFieldDetails[idx].index]);\n        return acc;\n    }, arg);\n\n    return arg;\n}\n\n/**\n * Sorts the data before return in dataBuilder.\n *\n * @param {Object} dataObj - An object containing the data and schema.\n * @param {Array} sortingDetails - An array containing the sorting configs.\n */\nfunction sortData(dataObj, sortingDetails) {\n    const { data, schema } = dataObj;\n    let fieldName;\n    let sortMeta;\n    let fDetails;\n    let i = sortingDetails.length - 1;\n\n    for (; i >= 0; i--) {\n        fieldName = sortingDetails[i][0];\n        sortMeta = sortingDetails[i][1];\n        fDetails = fieldInSchema(schema, fieldName);\n\n        if (!fDetails) {\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n\n        if (isCallable(sortMeta)) {\n            // eslint-disable-next-line no-loop-func\n            mergeSort(data, (a, b) => sortMeta(a[fDetails.index], b[fDetails.index]));\n        } else if (isArray(sortMeta)) {\n            const groupedData = groupData(data, fDetails.index);\n            const sortingFn = sortMeta[sortMeta.length - 1];\n            const targetFields = sortMeta.slice(0, sortMeta.length - 1);\n            const targetFieldDetails = targetFields.map(f => fieldInSchema(schema, f));\n\n            groupedData.forEach((groupedDatum) => {\n                groupedDatum.push(createSortingFnArg(groupedDatum, targetFields, targetFieldDetails));\n            });\n\n            mergeSort(groupedData, (a, b) => {\n                const m = a[2];\n                const n = b[2];\n                return sortingFn(m, n);\n            });\n\n            // Empty the array\n            data.length = 0;\n            groupedData.forEach((datum) => {\n                data.push(...datum[1]);\n            });\n        } else {\n            sortMeta = String(sortMeta).toLowerCase() === 'desc' ? 'desc' : 'asc';\n            mergeSort(data, getSortFn(fDetails.type, sortMeta, fDetails.index));\n        }\n    }\n\n    dataObj.uids = [];\n    data.forEach((value) => {\n        dataObj.uids.push(value.pop());\n    });\n}\n\n\n/**\n * Builds the actual data array.\n *\n * @param {Array} fieldStore - An array of field.\n * @param {string} rowDiffset - A string consisting of which rows to be included eg. '0-2,4,6';\n * @param {string} colIdentifier - A string consisting of the details of which column\n * to be included eg 'date,sales,profit';\n * @param {Object} sortingDetails - An object containing the sorting details of the DataModel instance.\n * @param {Object} options - The options required to create the type of the data.\n * @return {Object} Returns an object containing the multidimensional array and the relative schema.\n */\nexport function dataBuilder (fieldStore, rowDiffset, colIdentifier, sortingDetails, options) {\n    const defOptions = {\n        addUid: false,\n        columnWise: false\n    };\n    options = Object.assign({}, defOptions, options);\n\n    const retObj = {\n        schema: [],\n        data: [],\n        uids: []\n    };\n    const addUid = options.addUid;\n    const reqSorting = sortingDetails && sortingDetails.length > 0;\n    // It stores the fields according to the colIdentifier argument\n    const tmpDataArr = [];\n    // Stores the fields according to the colIdentifier argument\n    const colIArr = colIdentifier.split(',');\n\n    colIArr.forEach((colName) => {\n        for (let i = 0; i < fieldStore.length; i += 1) {\n            if (fieldStore[i].name() === colName) {\n                tmpDataArr.push(fieldStore[i]);\n                break;\n            }\n        }\n    });\n\n    // Inserts the schema to the schema object\n    tmpDataArr.forEach((field) => {\n        /** @todo Need to use extend2 here otherwise user can overwrite the schema. */\n        retObj.schema.push(field.schema());\n    });\n\n    if (addUid) {\n        retObj.schema.push({\n            name: 'uid',\n            type: 'identifier'\n        });\n    }\n\n    rowDiffsetIterator(rowDiffset, (i) => {\n        retObj.data.push([]);\n        const insertInd = retObj.data.length - 1;\n        let start = 0;\n        tmpDataArr.forEach((field, ii) => {\n            retObj.data[insertInd][ii + start] = field.partialField.data[i];\n        });\n        if (addUid) {\n            retObj.data[insertInd][tmpDataArr.length] = i;\n        }\n        // Creates an array of unique identifiers for each row\n        retObj.uids.push(i);\n\n        // If sorting needed then there is the need to expose the index\n        // mapping from the old index to its new index\n        if (reqSorting) { retObj.data[insertInd].push(i); }\n    });\n\n    // Handles the sort functionality\n    if (reqSorting) {\n        sortData(retObj, sortingDetails);\n    }\n\n    if (options.columnWise) {\n        const tmpData = Array(...Array(retObj.schema.length)).map(() => []);\n        retObj.data.forEach((tuple) => {\n            tuple.forEach((data, i) => {\n                tmpData[i].push(data);\n            });\n        });\n        retObj.data = tmpData;\n    }\n\n    return retObj;\n}\n","import DataModel from '../datamodel';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n\n/**\n * Performs the union operation between two dm instances.\n *\n * @todo Fix the conflicts between union and difference terminology here.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function difference (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n   // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     * @param {boolean} addData - If true only tuple will be added to the data.\n     */\n    function prepareDataHelper(dm, fieldsObj, addData) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                if (addData) { data.push(tuple); }\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj, false);\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj, true);\n\n    return new DataModel(data, schema, { name });\n}\n\n","/**\n * Reducer function that takes care about the sum aggregation\n * @param  {Array} arr array of values\n * @return {number}     sum of the array\n */\nfunction sum (arr) {\n    let allNulls = true;\n    const isNestedArray = arr[0] instanceof Array;\n    const sumVal = arr.reduce((carry, a) => {\n        if (isNestedArray) {\n            return carry.map((x, i) => x + a[i]);\n        }\n        allNulls = allNulls && (a === null);\n        return carry + a;\n    }, isNestedArray ? Array(...Array(arr[0].length)).map(() => 0) : 0);\n    return allNulls ? null : sumVal;\n}\n\n/**\n * reducer function that takes care about the mean aggregation\n * @param  {Array} arr array of values\n * @return {number}     mean of the array\n */\nfunction avg (arr) {\n    const isNestedArray = arr[0] instanceof Array;\n    const len = arr.length || 1;\n    const arrSum = sum(arr);\n    if (isNestedArray) {\n        return arrSum.map(x => x / len);\n    }\n    return arrSum === null ? null : arrSum / len;\n}\n\n/**\n * reducer function that gives the min value\n * @param  {Array} arr array of values\n * @return {number}     min of the array\n */\nfunction min (arr) {\n    const isNestedArray = arr[0] instanceof Array;\n    if (isNestedArray) {\n        return arr.reduce((carry, a) => carry.map((x, i) => Math.min(x, a[i])),\n        Array(...Array(arr[0].length)).map(() => Infinity));\n    }\n    return arr.every(d => d === null) ? null : Math.min(...arr);\n}\n\n/**\n * reducer function that gives the max value\n * @param  {Array} arr array of values\n * @return {number}     max of the array\n */\nfunction max (arr) {\n    const isNestedArray = arr[0] instanceof Array;\n    if (isNestedArray) {\n        return arr.reduce((carry, a) => carry.map((x, i) => Math.max(x, a[i])),\n        Array(...Array(arr[0].length)).map(() => -Infinity));\n    }\n    return arr.every(d => d === null) ? null : Math.max(...arr);\n}\n\n/**\n * reducer function that gives the first value\n * @param  {Array} arr array of values\n * @return {number}     first value of the array\n */\nfunction first (arr) {\n    return arr[0];\n}\n\n/**\n * reducer function that gives the last value\n * @param  {Array} arr array of values\n * @return {number}     last value of the array\n */\nfunction last (arr) {\n    return arr[arr.length - 1];\n}\n\n/**\n * reducer function that gives the count value\n * @param  {Array} arr array of values\n * @return {number}     count of the array\n */\nfunction count (arr) {\n    const isNestedArray = arr[0] instanceof Array;\n    const len = arr.length;\n    if (isNestedArray) {\n        return Array(...Array(arr[0].length)).map(() => len);\n    }\n    return len;\n}\n\n/**\n * Calculates the variance of the input array.\n *\n * @param {Array.<number>} arr - The input array.\n * @return {number} Returns the variance of the input array.\n */\nfunction variance (arr) {\n    let mean = avg(arr);\n    return avg(arr.map(num => (num - mean) ** 2));\n}\n\n/**\n * Calculates the square root of the variance of the input array.\n *\n * @param {Array.<number>} arr - The input array.\n * @return {number} Returns the square root of the variance.\n */\nfunction std (arr) {\n    return Math.sqrt(variance(arr));\n}\n\n\nconst fnList = {\n    sum,\n    avg,\n    min,\n    max,\n    first,\n    last,\n    count,\n    std\n};\n\nconst defaultReducerName = 'sum';\n\nexport {\n    defaultReducerName,\n    sum as defReducer,\n    fnList,\n};\n","import { defReducer, fnList } from '../operator';\n\n/**\n * A page level storage which stores, registers, unregisters reducers for all the datamodel instances. There is only one\n * reducer store available in a page. All the datamodel instances receive same instance of reducer store. DataModel\n * out of the box provides handful of {@link reducer | reducers} which can be used as reducer funciton.\n *\n * @public\n * @namespace DataModel\n */\nclass ReducerStore {\n    constructor () {\n        this.store = new Map();\n        this.store.set('defReducer', defReducer);\n\n        Object.entries(fnList).forEach((key) => {\n            this.store.set(key[0], key[1]);\n        });\n    }\n\n    /**\n     * Changes the `defaultReducer` globally. For all the fields which does not have `defAggFn` mentioned in schema, the\n     * value of `defaultReducer` is used for aggregation.\n     *\n     * @public\n     *\n     * @param {string} [reducer='sum'] name of the default reducer. It picks up the definition from store by doing name\n     *      lookup. If no name is found then it takes `sum` as the default reducer.\n     *\n     * @return {ReducerStore} instance of the singleton store in page.\n     */\n    defaultReducer (...params) {\n        if (params.length) {\n            let reducer = params[0];\n            if (typeof reducer === 'function') {\n                this.store.set('defReducer', reducer);\n            } else if (typeof reducer === 'string') {\n                if (Object.keys(fnList).indexOf(reducer) !== -1) {\n                    this.store.set('defReducer', fnList[reducer]);\n                }\n            }\n            return this;\n        }\n\n        return this.store.get('defReducer');\n    }\n\n    /**\n     *\n     * Registers a {@link reducer | reducer}.\n     * A {@link reducer | reducer} has to be registered before it is used.\n     *\n     * @example\n     *  // find the mean squared value of a given set\n     *  const reducerStore = DataModel.Reducers();\n     *\n     *  reducers.register('meanSquared', (arr) => {\n     *      const squaredVal = arr.map(item => item * item);\n     *      let sum = 0;\n     *      for (let i = 0, l = squaredVal.length; i < l; i++) {\n     *          sum += squaredVal[i++];\n     *      }\n     *\n     *      return sum;\n     *  })\n     *\n     *  // datamodel (dm) is already prepared with cars.json\n     *  const dm1 = dm.groupBy(['origin'], {\n     *      accleration: 'meanSquared'\n     *  });\n     *\n     * @public\n     *\n     * @param {string} name formal name for a reducer. If the given name already exists in store it is overridden by new\n     *      definition.\n     * @param {Function} reducer definition of {@link reducer} function.\n     *\n     * @return {Function} function for unregistering the reducer.\n     */\n    register (name, reducer) {\n        if (typeof name === 'string' && typeof reducer === 'function') {\n            this.store.set(name, reducer);\n        }\n\n        return () => { this.__unregister(name); };\n    }\n\n    __unregister (name) {\n        if (this.store.has(name)) {\n            this.store.delete(name);\n        }\n    }\n\n    resolve (name) {\n        if (name instanceof Function) {\n            return name;\n        }\n        return this.store.get(name);\n    }\n}\n\nconst reducerStore = (function () {\n    let store = null;\n\n    function getStore () {\n        if (store === null) {\n            store = new ReducerStore();\n        }\n        return store;\n    }\n    return getStore();\n}());\n\nexport default reducerStore;\n","import { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport DataModel from '../export';\nimport reducerStore from '../utils/reducer-store';\nimport { FieldType } from '../enums';\n\n/**\n * This function sanitize the user given field and return a common Array structure field\n * list\n * @param  {DataModel} dataModel the dataModel operating on\n * @param  {Array} fieldArr  user input of field Array\n * @return {Array}           arrays of field name\n */\nfunction getFieldArr (dataModel, fieldArr) {\n    const retArr = [];\n    const fieldStore = dataModel.getPartialFieldspace();\n    const dimensions = fieldStore.getDimension();\n    // const measures = fieldStore.getMeasure();\n\n    Object.entries(dimensions).forEach(([key]) => {\n        if (fieldArr && fieldArr.length) {\n            if (fieldArr.indexOf(key) !== -1) {\n                retArr.push(key);\n            }\n        } else {\n            retArr.push(key);\n        }\n    });\n\n    // Object.entries(measures).forEach(([key]) => {\n    //     if (measures[key].subtype === MeasureSubtype.DISCRETE) {\n    //         if (fieldArr && fieldArr.length) {\n    //             if (fieldArr.indexOf(key) !== -1) {\n    //                 retArr.push(key);\n    //             }\n    //         } else {\n    //             retArr.push(key);\n    //         }\n    //     }\n    // });\n    return retArr;\n}\n\n/**\n * This sanitize the reducer provide by the user and create a common type of object.\n * user can give function Also\n * @param  {DataModel} dataModel     dataModel to worked on\n * @param  {Object|function} [reducers={}] reducer provided by the users\n * @return {Object}               object containing reducer function for every measure\n */\nfunction getReducerObj (dataModel, reducers = {}) {\n    const retObj = {};\n    const pReducers = reducers;\n    const fieldStore = dataModel.getPartialFieldspace();\n    const measures = fieldStore.getMeasure();\n    let reducer = reducerStore.defaultReducer();\n    if (typeof reducers === 'function') {\n        reducer = reducers;\n    }\n    Object.entries(measures).forEach(([key]) => {\n        if (typeof reducers[key] === 'string') {\n            pReducers[key] = reducerStore.resolve(pReducers[key]) ? reducerStore.resolve(pReducers[key]) : reducer;\n        }\n        if (typeof reducers[key] !== 'function') {\n            pReducers[key] = undefined;\n        }\n        retObj[key] = pReducers[key] || reducerStore.resolve(measures[key].defAggFn()) || reducer;\n    });\n    return retObj;\n}\n\n/**\n * main function which perform the group-by operations which reduce the measures value is the\n * fields are common according to the reducer function provided\n * @param  {DataModel} dataModel the dataModel to worked\n * @param  {Array} fieldArr  fields according to which the groupby should be worked\n * @param  {Object|Function} reducers  reducers function\n * @param {DataModel} existingDataModel Existing datamodel instance\n * @return {DataModel} new dataModel with the group by\n */\nfunction groupBy (dataModel, fieldArr, reducers, existingDataModel) {\n    const sFieldArr = getFieldArr(dataModel, fieldArr);\n    const reducerObj = getReducerObj(dataModel, reducers);\n    const fieldStore = dataModel.getPartialFieldspace();\n    const fieldStoreObj = fieldStore.fieldsObj();\n    const dbName = fieldStore.name;\n    const dimensionArr = [];\n    const measureArr = [];\n    const schema = [];\n    const hashMap = {};\n    const data = [];\n    let newDataModel;\n    // Prepare the schema\n    Object.entries(fieldStoreObj).forEach(([key, value]) => {\n        if (sFieldArr.indexOf(key) !== -1 || reducerObj[key]) {\n            schema.push(extend2({}, value.schema()));\n            if (value.schema().type === FieldType.MEASURE) {\n                measureArr.push(key);\n            } else if (value.schema().type === FieldType.DIMENSION) {\n                dimensionArr.push(key);\n            }\n        }\n    });\n    // Prepare the data\n    let rowCount = 0;\n    rowDiffsetIterator(dataModel._rowDiffset, (i) => {\n        let hash = '';\n        dimensionArr.forEach((_) => {\n            hash = `${hash}-${fieldStoreObj[_].partialField.data[i]}`;\n        });\n        if (hashMap[hash] === undefined) {\n            hashMap[hash] = rowCount;\n            data.push({});\n            dimensionArr.forEach((_) => {\n                data[rowCount][_] = fieldStoreObj[_].partialField.data[i];\n            });\n            measureArr.forEach((_) => {\n                data[rowCount][_] = [fieldStoreObj[_].partialField.data[i]];\n            });\n            rowCount += 1;\n        } else {\n            measureArr.forEach((_) => {\n                data[hashMap[hash]][_].push(fieldStoreObj[_].partialField.data[i]);\n            });\n        }\n    });\n    // reduction\n    data.forEach((row) => {\n        const tuple = row;\n        measureArr.forEach((_) => {\n            tuple[_] = reducerObj[_](row[_]);\n        });\n    });\n    if (existingDataModel) {\n        existingDataModel.__calculateFieldspace();\n        newDataModel = existingDataModel;\n    }\n    else {\n        newDataModel = new DataModel(data, schema, { name: dbName });\n    }\n    return newDataModel;\n}\n\nexport { groupBy, getFieldArr, getReducerObj };\n","import { getCommonSchema } from './get-common-schema';\n\n/**\n * The filter function used in natural join.\n * It generates a function that will have the logic to join two\n * DataModel instances by the process of natural join.\n *\n * @param {DataModel} dm1 - The left DataModel instance.\n * @param {DataModel} dm2 - The right DataModel instance.\n * @return {Function} Returns a function that is used in cross-product operation.\n */\nexport function naturalJoinFilter (dm1, dm2) {\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    // const dm1FieldStoreName = dm1FieldStore.name;\n    // const dm2FieldStoreName = dm2FieldStore.name;\n    const commonSchemaArr = getCommonSchema(dm1FieldStore, dm2FieldStore);\n\n    return (dm1Fields, dm2Fields) => {\n        let retainTuple = true;\n        commonSchemaArr.forEach((fieldName) => {\n            if (dm1Fields[fieldName].value ===\n                dm2Fields[fieldName].value && retainTuple) {\n                retainTuple = true;\n            } else {\n                retainTuple = false;\n            }\n        });\n        return retainTuple;\n    };\n}\n","import DataModel from '../export';\nimport { extend2 } from '../utils';\nimport { rowDiffsetIterator } from './row-diffset-iterator';\nimport { isArrEqual } from '../utils/helper';\n/**\n * Performs the union operation between two dm instances.\n *\n * @param {dm} dm1 - The first dm instance.\n * @param {dm} dm2 - The second dm instance.\n * @return {dm} Returns the newly created dm after union operation.\n */\nexport function union (dm1, dm2) {\n    const hashTable = {};\n    const schema = [];\n    const schemaNameArr = [];\n    const data = [];\n    const dm1FieldStore = dm1.getFieldspace();\n    const dm2FieldStore = dm2.getFieldspace();\n    const dm1FieldStoreFieldObj = dm1FieldStore.fieldsObj();\n    const dm2FieldStoreFieldObj = dm2FieldStore.fieldsObj();\n    const name = `${dm1FieldStore.name} union ${dm2FieldStore.name}`;\n\n    // For union the columns should match otherwise return a clone of the dm1\n    if (!isArrEqual(dm1._colIdentifier.split(',').sort(), dm2._colIdentifier.split(',').sort())) {\n        return null;\n    }\n\n    // Prepare the schema\n    (dm1._colIdentifier.split(',')).forEach((fieldName) => {\n        const field = dm1FieldStoreFieldObj[fieldName];\n        schema.push(extend2({}, field.schema()));\n        schemaNameArr.push(field.schema().name);\n    });\n\n    /**\n     * The helper function to create the data.\n     *\n     * @param {dm} dm - The dm instance for which the data is inserted.\n     * @param {Object} fieldsObj - The fieldStore object format.\n     */\n    function prepareDataHelper (dm, fieldsObj) {\n        rowDiffsetIterator(dm._rowDiffset, (i) => {\n            const tuple = {};\n            let hashData = '';\n            schemaNameArr.forEach((schemaName) => {\n                const value = fieldsObj[schemaName].partialField.data[i];\n                hashData += `-${value}`;\n                tuple[schemaName] = value;\n            });\n            if (!hashTable[hashData]) {\n                data.push(tuple);\n                hashTable[hashData] = true;\n            }\n        });\n    }\n\n    // Prepare the data\n    prepareDataHelper(dm1, dm1FieldStoreFieldObj);\n    prepareDataHelper(dm2, dm2FieldStoreFieldObj);\n\n    return new DataModel(data, schema, { name });\n}\n","import { crossProduct } from './cross-product';\nimport { JOINS } from '../constants';\nimport { union } from './union';\n\n\nexport function leftOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel1, dataModel2, filterFn, false, JOINS.LEFTOUTER);\n}\n\nexport function rightOuterJoin (dataModel1, dataModel2, filterFn) {\n    return crossProduct(dataModel2, dataModel1, filterFn, false, JOINS.RIGHTOUTER);\n}\n\nexport function fullOuterJoin (dataModel1, dataModel2, filterFn) {\n    return union(leftOuterJoin(dataModel1, dataModel2, filterFn), rightOuterJoin(dataModel1, dataModel2, filterFn));\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\n\n/**\n * In {@link DataModel}, every tabular data consists of column, a column is stored as field.\n * Field contains all the data for a given column in an array.\n *\n * Each record consists of several fields; the fields of all records form the columns.\n * Examples of fields: name, gender, sex etc.\n *\n * In DataModel, each field can have multiple attributes which describes its data and behaviour.\n * A field can have two types of data: Measure and Dimension.\n *\n * A Dimension Field is the context on which a data is categorized and the measure is the numerical values that\n * quantify the data set.\n * In short a dimension is the lens through which you are looking at your measure data.\n *\n * Refer to {@link Schema} to get info about possible field attributes.\n *\n * @public\n * @class\n */\nexport default class Field {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {PartialField} partialField - The partialField instance which holds the whole data.\n     * @param {string} rowDiffset - The data subset definition.\n     */\n    constructor (partialField, rowDiffset) {\n        this.partialField = partialField;\n        this.rowDiffset = rowDiffset;\n    }\n\n    /**\n     * Generates the field type specific domain.\n     *\n     * @public\n     * @abstract\n     */\n    domain () {\n        throw new Error('Not yet implemented');\n    }\n\n    /**\n     * Returns the the field schema.\n     *\n     * @public\n     * @return {string} Returns the field schema.\n     */\n    schema () {\n        return this.partialField.schema;\n    }\n\n    /**\n     * Returns the name of the field.\n     *\n     * @public\n     * @return {string} Returns the name of the field.\n     */\n    name () {\n        return this.partialField.name;\n    }\n\n    /**\n     * Returns the type of the field.\n     *\n     * @public\n     * @return {string} Returns the type of the field.\n     */\n    type () {\n        return this.partialField.schema.type;\n    }\n\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return this.partialField.schema.subtype;\n    }\n\n    /**\n     * Returns the description of the field.\n     *\n     * @public\n     * @return {string} Returns the description of the field.\n     */\n    description () {\n        return this.partialField.schema.description;\n    }\n\n    /**\n     * Returns the display name of the field.\n     *\n     * @public\n     * @return {string} Returns the display name of the field.\n     */\n    displayName () {\n        return this.partialField.schema.displayName || this.partialField.schema.name;\n    }\n\n    /**\n     * Returns the data associated with the field.\n     *\n     * @public\n     * @return {Array} Returns the data.\n     */\n    data () {\n        const data = [];\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            data.push(this.partialField.data[i]);\n        });\n        return data;\n    }\n}\n","import Field from '../field';\n\n/**\n * Represents dimension field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Dimension extends Field {\n    /**\n     * Returns the domain for the dimension field.\n     *\n     * @override\n     * @public\n     * @return {any} Returns the calculated domain.\n     */\n    domain () {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @abstract\n     */\n    calculateDataDomain () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { DimensionSubtype } from '../../enums';\nimport Dimension from '../dimension';\n\n/**\n * Represents categorical field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Categorical extends Dimension {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return DimensionSubtype.CATEGORICAL;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n        return domain;\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport Dimension from '../dimension';\n\n/**\n * Represents temporal field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Temporal extends Dimension {\n     /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the unique values.\n     */\n    calculateDataDomain () {\n        const hash = new Set();\n        const domain = [];\n\n        // here don't use this.data() as the iteration will be\n        // occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (!hash.has(datum)) {\n                hash.add(datum);\n                domain.push(datum);\n            }\n        });\n\n        return domain;\n    }\n\n\n    /**\n     * Calculates the minimum consecutive difference from the associated field data.\n     *\n     * @public\n     * @return {number} Returns the minimum consecutive diff in milliseconds.\n     */\n    minimumConsecutiveDifference () {\n        const hash = new Set();\n        let currIdx = 0;\n        let prevDatum;\n        let minDiff = Number.POSITIVE_INFINITY;\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n\n            if (hash.has(datum)) {\n                return;\n            }\n            hash.add(datum);\n\n            if (!currIdx++) {\n                prevDatum = datum;\n                return;\n            }\n\n            minDiff = Math.min(minDiff, datum - prevDatum);\n            prevDatum = datum;\n        });\n\n        if (currIdx <= 1) {\n            return null;\n        }\n\n        return minDiff;\n    }\n\n    /**\n     * Returns the format specified in the input schema while creating field.\n     *\n     * @public\n     * @return {string} Returns the datetime format.\n     */\n    format () {\n        return this.partialField.schema.format;\n    }\n}\n\n","import Dimension from '../dimension';\n\n/**\n * Represents binned field subtype.\n *\n * @public\n * @class\n * @extends Dimension\n */\nexport default class Binned extends Dimension {\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the last and first values of bins config array.\n     */\n    calculateDataDomain () {\n        const binsArr = this.partialField.schema.bins;\n        return [binsArr[0], binsArr[binsArr.length - 1]];\n    }\n\n    /**\n     * Returns the bins config provided while creating the field instance.\n     *\n     * @public\n     * @return {Array} Returns the bins array config.\n     */\n    bins () {\n        return this.partialField.schema.bins;\n    }\n}\n","import { formatNumber } from '../../utils';\nimport { defaultReducerName } from '../../operator/group-by-function';\nimport Field from '../field';\n\n/**\n * Represents measure field type.\n *\n * @public\n * @class\n * @extends Field\n */\nexport default class Measure extends Field {\n  /**\n   * Returns the domain for the measure field.\n   *\n   * @override\n   * @public\n   * @return {any} Returns the calculated domain.\n   */\n    domain() {\n        if (!this._cachedDomain) {\n            this._cachedDomain = this.calculateDataDomain();\n        }\n        return this._cachedDomain;\n    }\n\n  /**\n   * Returns the unit of the measure field.\n   *\n   * @public\n   * @return {string} Returns unit of the field.\n   */\n    unit() {\n        return this.partialField.schema.unit;\n    }\n\n  /**\n   * Returns the aggregation function name of the measure field.\n   *\n   * @public\n   * @return {string} Returns aggregation function name of the field.\n   */\n    defAggFn() {\n        return this.partialField.schema.defAggFn || defaultReducerName;\n    }\n\n  /**\n   * Returns the number format of the measure field.\n   *\n   * @public\n   * @return {Function} Returns number format of the field.\n   */\n    numberFormat() {\n        const { numberFormat } = this.partialField.schema;\n        return numberFormat instanceof Function ? numberFormat : formatNumber;\n    }\n\n  /**\n   * Calculates the corresponding field domain.\n   *\n   * @public\n   * @abstract\n   */\n    calculateDataDomain() {\n        throw new Error('Not yet implemented');\n    }\n}\n","import { rowDiffsetIterator } from '../../operator/row-diffset-iterator';\nimport { MeasureSubtype } from '../../enums';\nimport Measure from '../measure';\n\n/**\n * Represents continuous field subtype.\n *\n * @public\n * @class\n * @extends Measure\n */\nexport default class Continuous extends Measure {\n    /**\n     * Returns the subtype of the field.\n     *\n     * @public\n     * @override\n     * @return {string} Returns the subtype of the field.\n     */\n    subtype () {\n        return MeasureSubtype.CONTINUOUS;\n    }\n\n    /**\n     * Calculates the corresponding field domain.\n     *\n     * @public\n     * @override\n     * @return {Array} Returns the min and max values.\n     */\n    calculateDataDomain () {\n        let min = Number.POSITIVE_INFINITY;\n        let max = Number.NEGATIVE_INFINITY;\n\n        // here don't use this.data() as the iteration will be occurred two times on same data.\n        rowDiffsetIterator(this.rowDiffset, (i) => {\n            const datum = this.partialField.data[i];\n            if (datum < min) {\n                min = datum;\n            }\n            if (datum > max) {\n                max = datum;\n            }\n        });\n\n        return [min, max];\n    }\n}\n","/**\n * A interface to represent a parser which is responsible to parse the field.\n *\n * @public\n * @interface\n */\nexport default class FieldParser {\n    /**\n     * Parses a single value of a field and return the sanitized form.\n     *\n     * @public\n     * @abstract\n     */\n    parse () {\n        throw new Error('Not yet implemented');\n    }\n}\n","import FieldParser from '../field-parser';\n\n/**\n * A FieldParser which parses the categorical values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class CategoricalParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the stringified form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the stringified value.\n   */\n    parse (val) {\n        return (val === undefined || val === null) ? null : String(val).trim();\n    }\n}\n","import { DateTimeFormatter } from '../../../utils';\nimport FieldParser from '../field-parser';\n\n/**\n * A FieldParser which parses the temporal values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class TemporalParser extends FieldParser {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {Object} schema - The schema object for the corresponding field.\n     */\n    constructor (schema) {\n        super();\n        this.schema = schema;\n        this._dtf = null;\n    }\n\n    /**\n     * Parses a single value of a field and returns the millisecond value.\n     *\n     * @public\n     * @param {string|number} val - The value of the field.\n     * @return {number} Returns the millisecond value.\n     */\n    parse (val) {\n        if (this.schema.format) {\n            this._dtf = this._dtf || new DateTimeFormatter(this.schema.format);\n            return this._dtf.getNativeDate(val).getTime();\n        }\n\n        // If format is not present which means the value is such that\n        // it could be directly passed to Date constructor.\n        return +new Date(val);\n    }\n}\n","import FieldParser from '../field-parser';\n\n/**\n * A FieldParser which parses the binned values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class BinnedParser extends FieldParser {\n  /**\n   * Parses a single binned value of a field and returns the sanitized value.\n   *\n   * @public\n   * @param {string} val - The value of the field.\n   * @return {string} Returns the sanitized value.\n   */\n    parse (val) {\n        if (val === null || val === undefined) {\n            return null;\n        }\n\n        const regex = /^\\s*(\\d+)\\s*-\\s*(\\d+)\\s*$/;\n        val = String(val);\n\n        const matched = val.match(regex);\n        if (!matched) {\n            return null;\n        }\n\n        return `${matched[1]}-${matched[2]}`;\n    }\n}\n","import FieldParser from '../field-parser';\n\n/**\n * A FieldParser which parses the continuous values.\n *\n * @public\n * @class\n * @implements {FieldParser}\n */\nexport default class ContinuousParser extends FieldParser {\n  /**\n   * Parses a single value of a field and returns the number form.\n   *\n   * @public\n   * @param {string|number} val - The value of the field.\n   * @return {string} Returns the number value.\n   */\n    parse (val) {\n        val = parseFloat(val, 10);\n        return Number.isNaN(val) ? null : val;\n    }\n}\n","/**\n * Stores the full data and the metadata of a field. It provides\n * a single source of data from which the future Field\n * instance can get a subset of it with a rowDiffset config.\n *\n * @class\n * @public\n */\nexport default class PartialField {\n    /**\n     * Initialize a new instance.\n     *\n     * @public\n     * @param {string} name - The name of the field.\n     * @param {Array} data - The data array.\n     * @param {Object} schema - The schema object of the corresponding field.\n     * @param {FieldParser} parser - The parser instance corresponding to that field.\n     */\n    constructor (name, data, schema, parser) {\n        this.name = name;\n        this.schema = schema;\n        this.parser = parser;\n        this.data = this._sanitize(data);\n    }\n\n    /**\n     * Sanitizes the field data.\n     *\n     * @private\n     * @param {Array} data - The actual input data.\n     * @return {Array} Returns the sanitized data.\n     */\n    _sanitize (data) {\n        return data.map(datum => this.parser.parse(datum));\n    }\n}\n","import { FieldType, DimensionSubtype, MeasureSubtype } from './enums';\nimport {\n    Categorical,\n    Temporal,\n    Binned,\n    Continuous,\n    CategoricalParser,\n    TemporalParser,\n    BinnedParser,\n    ContinuousParser,\n    PartialField\n} from './fields';\n\n/**\n * Creates a field instance according to the provided data and schema.\n *\n * @param {Array} data - The field data array.\n * @param {Object} schema - The field schema object.\n * @return {Field} Returns the newly created field instance.\n */\nfunction createUnitField(data, schema) {\n    data = data || [];\n    let partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new ContinuousParser());\n            return new Continuous(partialField, `0-${data.length - 1}`);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.TEMPORAL:\n            partialField = new PartialField(schema.name, data, schema, new TemporalParser(schema));\n            return new Temporal(partialField, `0-${data.length - 1}`);\n        case DimensionSubtype.BINNED:\n            partialField = new PartialField(schema.name, data, schema, new BinnedParser());\n            return new Binned(partialField, `0-${data.length - 1}`);\n        default:\n            partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n            return new Categorical(partialField, `0-${data.length - 1}`);\n        }\n    default:\n        partialField = new PartialField(schema.name, data, schema, new CategoricalParser());\n        return new Categorical(partialField, `0-${data.length - 1}`);\n    }\n}\n\n\n/**\n * Creates a field instance from partialField and rowDiffset.\n *\n * @param {PartialField} partialField - The corresponding partial field.\n * @param {string} rowDiffset - The data subset config.\n * @return {Field} Returns the newly created field instance.\n */\nexport function createUnitFieldFromPartial(partialField, rowDiffset) {\n    const { schema } = partialField;\n\n    switch (schema.type) {\n    case FieldType.MEASURE:\n        switch (schema.subtype) {\n        case MeasureSubtype.CONTINUOUS:\n            return new Continuous(partialField, rowDiffset);\n        default:\n            return new Continuous(partialField, rowDiffset);\n        }\n    case FieldType.DIMENSION:\n        switch (schema.subtype) {\n        case DimensionSubtype.CATEGORICAL:\n            return new Categorical(partialField, rowDiffset);\n        case DimensionSubtype.TEMPORAL:\n            return new Temporal(partialField, rowDiffset);\n        case DimensionSubtype.BINNED:\n            return new Binned(partialField, rowDiffset);\n        default:\n            return new Categorical(partialField, rowDiffset);\n        }\n    default:\n        return new Categorical(partialField, rowDiffset);\n    }\n}\n\n/**\n * Creates the field instances with input data and schema.\n *\n * @param {Array} dataColumn - The data array for fields.\n * @param {Array} schema - The schema array for fields.\n * @param {Array} headers - The array of header names.\n * @return {Array.<Field>} Returns an array of newly created field instances.\n */\nexport function createFields(dataColumn, schema, headers) {\n    const headersObj = {};\n\n    if (!(headers && headers.length)) {\n        headers = schema.map(item => item.name);\n    }\n\n    headers.forEach((header, i) => {\n        headersObj[header] = i;\n    });\n\n    return schema.map(item => createUnitField(dataColumn[headersObj[item.name]], item));\n}\n","import { DataFormat } from './enums';\n\nexport default {\n    dataFormat: DataFormat.AUTO\n};\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in DSV array to a manageable internal format.\n *\n * @param {Array.<Array>} arr - A 2D array containing of the DSV data.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv data is header or not.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    [\"a\", \"b\", \"c\"],\n *    [1, 2, 3],\n *    [4, 5, 6],\n *    [7, 8, 9]\n * ];\n */\nfunction DSVArr (arr, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    let header;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    if (options.firstRowHeader) {\n        // If header present then mutate the array.\n        // Do in-place mutation to save space.\n        header = arr.splice(0, 1)[0];\n    } else {\n        header = [];\n    }\n\n    arr.forEach(field => push(...field));\n\n    return [header, columns];\n}\n\nexport default DSVArr;\n","var EOL = {},\n    EOF = {},\n    QUOTE = 34,\n    NEWLINE = 10,\n    RETURN = 13;\n\nfunction objectConverter(columns) {\n  return new Function(\"d\", \"return {\" + columns.map(function(name, i) {\n    return JSON.stringify(name) + \": d[\" + i + \"]\";\n  }).join(\",\") + \"}\");\n}\n\nfunction customConverter(columns, f) {\n  var object = objectConverter(columns);\n  return function(row, i) {\n    return f(object(row), i, columns);\n  };\n}\n\n// Compute unique columns in order of discovery.\nfunction inferColumns(rows) {\n  var columnSet = Object.create(null),\n      columns = [];\n\n  rows.forEach(function(row) {\n    for (var column in row) {\n      if (!(column in columnSet)) {\n        columns.push(columnSet[column] = column);\n      }\n    }\n  });\n\n  return columns;\n}\n\nexport default function(delimiter) {\n  var reFormat = new RegExp(\"[\\\"\" + delimiter + \"\\n\\r]\"),\n      DELIMITER = delimiter.charCodeAt(0);\n\n  function parse(text, f) {\n    var convert, columns, rows = parseRows(text, function(row, i) {\n      if (convert) return convert(row, i - 1);\n      columns = row, convert = f ? customConverter(row, f) : objectConverter(row);\n    });\n    rows.columns = columns || [];\n    return rows;\n  }\n\n  function parseRows(text, f) {\n    var rows = [], // output rows\n        N = text.length,\n        I = 0, // current character index\n        n = 0, // current line number\n        t, // current token\n        eof = N <= 0, // current token followed by EOF?\n        eol = false; // current token followed by EOL?\n\n    // Strip the trailing newline.\n    if (text.charCodeAt(N - 1) === NEWLINE) --N;\n    if (text.charCodeAt(N - 1) === RETURN) --N;\n\n    function token() {\n      if (eof) return EOF;\n      if (eol) return eol = false, EOL;\n\n      // Unescape quotes.\n      var i, j = I, c;\n      if (text.charCodeAt(j) === QUOTE) {\n        while (I++ < N && text.charCodeAt(I) !== QUOTE || text.charCodeAt(++I) === QUOTE);\n        if ((i = I) >= N) eof = true;\n        else if ((c = text.charCodeAt(I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        return text.slice(j + 1, i - 1).replace(/\"\"/g, \"\\\"\");\n      }\n\n      // Find next delimiter or newline.\n      while (I < N) {\n        if ((c = text.charCodeAt(i = I++)) === NEWLINE) eol = true;\n        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }\n        else if (c !== DELIMITER) continue;\n        return text.slice(j, i);\n      }\n\n      // Return last token before EOF.\n      return eof = true, text.slice(j, N);\n    }\n\n    while ((t = token()) !== EOF) {\n      var row = [];\n      while (t !== EOL && t !== EOF) row.push(t), t = token();\n      if (f && (row = f(row, n++)) == null) continue;\n      rows.push(row);\n    }\n\n    return rows;\n  }\n\n  function format(rows, columns) {\n    if (columns == null) columns = inferColumns(rows);\n    return [columns.map(formatValue).join(delimiter)].concat(rows.map(function(row) {\n      return columns.map(function(column) {\n        return formatValue(row[column]);\n      }).join(delimiter);\n    })).join(\"\\n\");\n  }\n\n  function formatRows(rows) {\n    return rows.map(formatRow).join(\"\\n\");\n  }\n\n  function formatRow(row) {\n    return row.map(formatValue).join(delimiter);\n  }\n\n  function formatValue(text) {\n    return text == null ? \"\"\n        : reFormat.test(text += \"\") ? \"\\\"\" + text.replace(/\"/g, \"\\\"\\\"\") + \"\\\"\"\n        : text;\n  }\n\n  return {\n    parse: parse,\n    parseRows: parseRows,\n    format: format,\n    formatRows: formatRows\n  };\n}\n","import dsv from \"./dsv\";\n\nvar csv = dsv(\",\");\n\nexport var csvParse = csv.parse;\nexport var csvParseRows = csv.parseRows;\nexport var csvFormat = csv.format;\nexport var csvFormatRows = csv.formatRows;\n","import dsv from \"./dsv\";\n\nvar tsv = dsv(\"\\t\");\n\nexport var tsvParse = tsv.parse;\nexport var tsvParseRows = tsv.parseRows;\nexport var tsvFormat = tsv.format;\nexport var tsvFormatRows = tsv.formatRows;\n","import { dsvFormat as d3Dsv } from 'd3-dsv';\nimport DSVArr from './dsv-arr';\n\n/**\n * Parses and converts data formatted in DSV string to a manageable internal format.\n *\n * @todo Support to be given for https://tools.ietf.org/html/rfc4180.\n * @todo Sample implementation https://github.com/knrz/CSV.js/.\n *\n * @param {string} str - The input DSV string.\n * @param {Object} options - Option to control the behaviour of the parsing.\n * @param {boolean} [options.firstRowHeader=true] - Whether the first row of the dsv string data is header or not.\n * @param {string} [options.fieldSeparator=\",\"] - The separator of two consecutive field.\n * @return {Array} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = `\n * a,b,c\n * 1,2,3\n * 4,5,6\n * 7,8,9\n * `\n */\nfunction DSVStr (str, options) {\n    const defaultOption = {\n        firstRowHeader: true,\n        fieldSeparator: ','\n    };\n    options = Object.assign({}, defaultOption, options);\n\n    const dsv = d3Dsv(options.fieldSeparator);\n    return DSVArr(dsv.parseRows(str), options);\n}\n\nexport default DSVStr;\n","import { columnMajor } from '../utils';\n\n/**\n * Parses and converts data formatted in JSON to a manageable internal format.\n *\n * @param {Array.<Object>} arr - The input data formatted in JSON.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n * @example\n *\n * // Sample input data:\n * const data = [\n *    {\n *      \"a\": 1,\n *      \"b\": 2,\n *      \"c\": 3\n *    },\n *    {\n *      \"a\": 4,\n *      \"b\": 5,\n *      \"c\": 6\n *    },\n *    {\n *      \"a\": 7,\n *      \"b\": 8,\n *      \"c\": 9\n *    }\n * ];\n */\nfunction FlatJSON (arr) {\n    const header = {};\n    let i = 0;\n    let insertionIndex;\n    const columns = [];\n    const push = columnMajor(columns);\n\n    arr.forEach((item) => {\n        const fields = [];\n        for (let key in item) {\n            if (key in header) {\n                insertionIndex = header[key];\n            } else {\n                header[key] = i++;\n                insertionIndex = i - 1;\n            }\n            fields[insertionIndex] = item[key];\n        }\n        push(...fields);\n    });\n\n    return [Object.keys(header), columns];\n}\n\nexport default FlatJSON;\n","import FlatJSON from './flat-json';\nimport DSVArr from './dsv-arr';\nimport DSVStr from './dsv-str';\nimport { isArray, isObject, isString } from '../utils';\n\n/**\n * Parses the input data and detect the format automatically.\n *\n * @param {string|Array} data - The input data.\n * @param {Object} options - An optional config specific to data format.\n * @return {Array.<Object>} Returns an array of headers and column major data.\n */\nfunction Auto (data, options) {\n    let converter;\n\n    if (isString(data)) {\n        converter = DSVStr;\n    } else if (isArray(data) && isArray(data[0])) {\n        converter = DSVArr;\n    } else if (isArray(data) && (data.length === 0 || isObject(data[0]))) {\n        converter = FlatJSON;\n    } else {\n        throw new Error('Couldn\\'t detect the data format');\n    }\n\n    return converter(data, options);\n}\n\nexport default Auto;\n","import { FieldType, FilteringMode } from './enums';\nimport fieldStore from './field-store';\nimport Value from './value';\nimport {\n    rowDiffsetIterator\n} from './operator';\nimport { DM_DERIVATIVES, LOGICAL_OPERATORS } from './constants';\nimport { createFields, createUnitFieldFromPartial } from './field-creator';\nimport defaultConfig from './default-config';\nimport * as converter from './converter';\n\n/**\n * Prepares the selection data.\n */\nfunction prepareSelectionData (fields, i) {\n    const resp = {};\n    for (let field of fields) {\n        resp[field.name()] = new Value(field.partialField.data[i], field);\n    }\n    return resp;\n}\n\nexport function prepareJoinData (fields) {\n    const resp = {};\n    Object.keys(fields).forEach((key) => { resp[key] = new Value(fields[key], key); });\n    return resp;\n}\n\nexport const updateFields = ([rowDiffset, colIdentifier], partialFieldspace, fieldStoreName) => {\n    let collID = colIdentifier.length ? colIdentifier.split(',') : [];\n    let partialFieldMap = partialFieldspace.fieldsObj();\n    let newFields = collID.map(coll => createUnitFieldFromPartial(partialFieldMap[coll].partialField, rowDiffset));\n    return fieldStore.createNamespace(newFields, fieldStoreName);\n};\n\nexport const persistDerivation = (model, operation, config = {}, criteriaFn) => {\n    let derivative;\n    if (operation !== DM_DERIVATIVES.COMPOSE) {\n        derivative = {\n            op: operation,\n            meta: config,\n            criteria: criteriaFn\n        };\n        model._derivation.push(derivative);\n    }\n    else {\n        derivative = [...criteriaFn];\n        model._derivation.length = 0;\n        model._derivation.push(...derivative);\n    }\n};\n\nexport const selectHelper = (rowDiffset, fields, selectFn, config) => {\n    const newRowDiffSet = [];\n    let lastInsertedValue = -1;\n    let { mode } = config;\n    let li;\n    let checker = index => selectFn(prepareSelectionData(fields, index), index);\n    if (mode === FilteringMode.INVERSE) {\n        checker = index => !selectFn(prepareSelectionData(fields, index));\n    }\n    rowDiffsetIterator(rowDiffset, (i) => {\n        if (checker(i)) {\n            if (lastInsertedValue !== -1 && i === (lastInsertedValue + 1)) {\n                li = newRowDiffSet.length - 1;\n                newRowDiffSet[li] = `${newRowDiffSet[li].split('-')[0]}-${i}`;\n            } else {\n                newRowDiffSet.push(`${i}`);\n            }\n            lastInsertedValue = i;\n        }\n    });\n    return newRowDiffSet.join(',');\n};\n\nexport const filterPropagationModel = (model, propModels, config = {}) => {\n    const operation = config.operation || LOGICAL_OPERATORS.AND;\n    const filterByMeasure = config.filterByMeasure || false;\n    let fns = [];\n    if (!propModels.length) {\n        fns = [() => false];\n    } else {\n        fns = propModels.map(propModel => ((dataModel) => {\n            const dataObj = dataModel.getData();\n            const schema = dataObj.schema;\n            const fieldsConfig = dataModel.getFieldsConfig();\n            const fieldsSpace = dataModel.getFieldspace().fieldsObj();\n            const data = dataObj.data;\n            const domain = Object.values(fieldsConfig).reduce((acc, v) => {\n                acc[v.def.name] = fieldsSpace[v.def.name].domain();\n                return acc;\n            }, {});\n\n            return (fields) => {\n                const include = !data.length ? false : data.some(row => schema.every((propField) => {\n                    if (!(propField.name in fields)) {\n                        return true;\n                    }\n                    const value = fields[propField.name].valueOf();\n                    if (filterByMeasure && propField.type === FieldType.MEASURE) {\n                        return value >= domain[propField.name][0] && value <= domain[propField.name][1];\n                    }\n\n                    if (propField.type !== FieldType.DIMENSION) {\n                        return true;\n                    }\n                    const idx = fieldsConfig[propField.name].index;\n                    return row[idx] === fields[propField.name].valueOf();\n                }));\n                return include;\n            };\n        })(propModel));\n    }\n\n    let filteredModel;\n    if (operation === LOGICAL_OPERATORS.AND) {\n        const clonedModel = model.clone(false, false);\n        filteredModel = clonedModel.select(fields => fns.every(fn => fn(fields)), {\n            saveChild: false,\n            mode: FilteringMode.ALL\n        });\n    } else {\n        filteredModel = model.clone(false, false).select(fields => fns.some(fn => fn(fields)), {\n            mode: FilteringMode.ALL,\n            saveChild: false\n        });\n    }\n\n    return filteredModel;\n};\n\nexport const cloneWithSelect = (sourceDm, selectFn, selectConfig, cloneConfig) => {\n    const cloned = sourceDm.clone(cloneConfig.saveChild);\n    const rowDiffset = selectHelper(\n        cloned._rowDiffset,\n        cloned.getPartialFieldspace().fields,\n        selectFn,\n        selectConfig\n    );\n    cloned._rowDiffset = rowDiffset;\n    cloned.__calculateFieldspace().calculateFieldsConfig();\n    // Store reference to child model and selector function\n    if (cloneConfig.saveChild) {\n        persistDerivation(cloned, DM_DERIVATIVES.SELECT, { config: selectConfig }, selectFn);\n    }\n\n    return cloned;\n};\n\nexport const cloneWithProject = (sourceDm, projField, config, allFields) => {\n    const cloned = sourceDm.clone(config.saveChild);\n    let projectionSet = projField;\n    if (config.mode === FilteringMode.INVERSE) {\n        projectionSet = allFields.filter(fieldName => projField.indexOf(fieldName) === -1);\n    }\n    // cloned._colIdentifier = sourceDm._colIdentifier.split(',')\n    //                         .filter(coll => projectionSet.indexOf(coll) !== -1).join();\n    cloned._colIdentifier = projectionSet.join(',');\n    cloned.__calculateFieldspace().calculateFieldsConfig();\n    // Store reference to child model and projection fields\n    if (config.saveChild) {\n        persistDerivation(\n            cloned,\n            DM_DERIVATIVES.PROJECT,\n            { projField, config, actualProjField: projectionSet },\n            null\n        );\n    }\n\n    return cloned;\n};\n\nexport const updateData = (relation, data, schema, options) => {\n    options = Object.assign(Object.assign({}, defaultConfig), options);\n    const converterFn = converter[options.dataFormat];\n\n    if (!(converterFn && typeof converterFn === 'function')) {\n        throw new Error(`No converter function found for ${options.dataFormat} format`);\n    }\n\n    const [header, formattedData] = converterFn(data, options);\n    const fieldArr = createFields(formattedData, schema, header);\n\n    // This will create a new fieldStore with the fields\n    const nameSpace = fieldStore.createNamespace(fieldArr, options.name);\n    relation._partialFieldspace = nameSpace;\n    // If data is provided create the default colIdentifier and rowDiffset\n    relation._rowDiffset = formattedData.length && formattedData[0].length ? `0-${formattedData[0].length - 1}` : '';\n    relation._colIdentifier = (schema.map(_ => _.name)).join();\n    return relation;\n};\n\nexport const fieldInSchema = (schema, field) => {\n    let i = 0;\n\n    for (; i < schema.length; ++i) {\n        if (field === schema[i].name) {\n            return {\n                type: schema[i].subtype || schema[i].type,\n                index: i\n            };\n        }\n    }\n    return null;\n};\n\n\nexport const getOperationArguments = (child) => {\n    const derivation = child._derivation;\n    let params = [];\n    let operation;\n    if (derivation && derivation.length === 1) {\n        operation = derivation[0].op;\n        switch (operation) {\n        case DM_DERIVATIVES.SELECT:\n            params = [derivation[0].criteria];\n            break;\n        case DM_DERIVATIVES.PROJECT:\n            params = [derivation[0].meta.actualProjField];\n            break;\n        case DM_DERIVATIVES.GROUPBY:\n            operation = 'groupBy';\n            params = [derivation[0].meta.groupByString.split(','), derivation[0].criteria];\n            break;\n        default:\n            break;\n        }\n    }\n\n    return {\n        operation,\n        params\n    };\n};\n\nconst applyExistingOperationOnModel = (propModel, dataModel) => {\n    const { operation, params } = getOperationArguments(dataModel);\n    let selectionModel = propModel[0];\n    let rejectionModel = propModel[1];\n    if (operation && params.length) {\n        selectionModel = propModel[0][operation](...params, {\n            saveChild: false\n        });\n        rejectionModel = propModel[1][operation](...params, {\n            saveChild: false\n        });\n    }\n    return [selectionModel, rejectionModel];\n};\n\nconst getFilteredModel = (propModel, path) => {\n    for (let i = 0, len = path.length; i < len; i++) {\n        const model = path[i];\n        propModel = applyExistingOperationOnModel(propModel, model);\n    }\n    return propModel;\n};\n\nconst propagateIdentifiers = (dataModel, propModel, config = {}, propModelInf = {}) => {\n    const nonTraversingModel = propModelInf.nonTraversingModel;\n    const excludeModels = propModelInf.excludeModels || [];\n\n    if (dataModel === nonTraversingModel) {\n        return;\n    }\n\n    const propagate = excludeModels.length ? excludeModels.indexOf(dataModel) === -1 : true;\n\n    propagate && dataModel.handlePropagation(propModel, config);\n\n    const children = dataModel._children;\n    children.forEach((child) => {\n        let [selectionModel, rejectionModel] = applyExistingOperationOnModel(propModel, child);\n        propagateIdentifiers(child, [selectionModel, rejectionModel], config, propModelInf);\n    });\n};\n\nexport const getRootGroupByModel = (model) => {\n    if (model._parent && model._derivation.find(d => d.op !== 'group')) {\n        return getRootGroupByModel(model._parent);\n    }\n    return model;\n};\n\nexport const getRootDataModel = (model) => {\n    if (model._parent) {\n        return getRootDataModel(model._parent);\n    }\n    return model;\n};\n\nexport const getPathToRootModel = (model, path = []) => {\n    if (model._parent !== null) {\n        path.push(model);\n        getPathToRootModel(model._parent, path);\n    }\n    return path;\n};\n\nexport const propagateToAllDataModels = (identifiers, rootModels, propagationInf, config) => {\n    let criteria;\n    let propModel;\n    const { propagationNameSpace, propagateToSource } = propagationInf;\n    const propagationSourceId = propagationInf.sourceId;\n    const propagateInterpolatedValues = config.propagateInterpolatedValues;\n    const filterFn = (entry) => {\n        const filter = config.filterFn || (() => true);\n        return filter(entry, config);\n    };\n\n    let criterias = [];\n\n    if (identifiers === null && config.persistent !== true) {\n        criterias = [{\n            criteria: []\n        }];\n    } else {\n        let actionCriterias = Object.values(propagationNameSpace.mutableActions);\n        if (propagateToSource !== false) {\n            actionCriterias = actionCriterias.filter(d => d.config.sourceId !== propagationSourceId);\n        }\n\n        const filteredCriteria = actionCriterias.filter(filterFn).map(action => action.config.criteria);\n\n        const excludeModels = [];\n\n        if (propagateToSource !== false) {\n            const sourceActionCriterias = Object.values(propagationNameSpace.mutableActions);\n\n            sourceActionCriterias.forEach((actionInf) => {\n                const actionConf = actionInf.config;\n                if (actionConf.applyOnSource === false && actionConf.action === config.action &&\n                        actionConf.sourceId !== propagationSourceId) {\n                    excludeModels.push(actionInf.model);\n                    criteria = sourceActionCriterias.filter(d => d !== actionInf).map(d => d.config.criteria);\n                    criteria.length && criterias.push({\n                        criteria,\n                        models: actionInf.model,\n                        path: getPathToRootModel(actionInf.model)\n                    });\n                }\n            });\n        }\n\n\n        criteria = [].concat(...[...filteredCriteria, identifiers]).filter(d => d !== null);\n        criterias.push({\n            criteria,\n            excludeModels: [...excludeModels, ...config.excludeModels || []]\n        });\n    }\n\n    const rootModel = rootModels.model;\n\n    const propConfig = Object.assign({\n        sourceIdentifiers: identifiers,\n        propagationSourceId\n    }, config);\n\n    const rootGroupByModel = rootModels.groupByModel;\n    if (propagateInterpolatedValues && rootGroupByModel) {\n        propModel = filterPropagationModel(rootGroupByModel, criteria, {\n            filterByMeasure: propagateInterpolatedValues\n        });\n        propagateIdentifiers(rootGroupByModel, propModel, propConfig);\n    }\n\n    criterias.forEach((inf) => {\n        const propagationModel = filterPropagationModel(rootModel, inf.criteria);\n        const path = inf.path;\n\n        if (path) {\n            const filteredModel = getFilteredModel(propagationModel, path.reverse());\n            inf.models.handlePropagation(filteredModel, propConfig);\n        } else {\n            propagateIdentifiers(rootModel, propagationModel, propConfig, {\n                excludeModels: inf.excludeModels,\n                nonTraversingModel: propagateInterpolatedValues && rootGroupByModel\n            });\n        }\n    });\n};\n\nexport const propagateImmutableActions = (propagationNameSpace, rootModels, propagationInf) => {\n    const immutableActions = propagationNameSpace.immutableActions;\n\n    for (const action in immutableActions) {\n        const actionInf = immutableActions[action];\n        const actionConf = actionInf.config;\n        const propagationSourceId = propagationInf.config.sourceId;\n        const filterImmutableAction = propagationInf.propConfig.filterImmutableAction ?\n            propagationInf.propConfig.filterImmutableAction(actionConf, propagationInf.config) : true;\n        if (actionConf.sourceId !== propagationSourceId && filterImmutableAction) {\n            const criteriaModel = actionConf.criteria;\n            propagateToAllDataModels(criteriaModel, rootModels, {\n                propagationNameSpace,\n                propagateToSource: false,\n                sourceId: propagationSourceId\n            }, actionConf);\n        }\n    }\n};\n\nexport const addToPropNamespace = (propagationNameSpace, config = {}, model) => {\n    let sourceNamespace;\n    const isMutableAction = config.isMutableAction;\n    const criteria = config.criteria;\n    const key = `${config.action}-${config.sourceId}`;\n\n    if (isMutableAction) {\n        sourceNamespace = propagationNameSpace.mutableActions;\n    } else {\n        sourceNamespace = propagationNameSpace.immutableActions;\n    }\n\n    if (criteria === null) {\n        delete sourceNamespace[key];\n    } else {\n        sourceNamespace[key] = {\n            model,\n            config\n        };\n    }\n\n    return this;\n};\n","import { FilteringMode } from './enums';\nimport { getUniqueId } from './utils';\nimport { persistDerivation, updateFields, cloneWithSelect, cloneWithProject, updateData } from './helper';\nimport { crossProduct, difference, naturalJoinFilter, union } from './operator';\nimport { DM_DERIVATIVES } from './constants';\n\n/**\n * Relation provides the definitions of basic operators of relational algebra like *selection*, *projection*, *union*,\n * *difference* etc.\n *\n * It is extended by {@link DataModel} to inherit the functionalities of relational algebra concept.\n *\n * @class\n * @public\n * @module Relation\n * @namespace DataModel\n */\nclass Relation {\n\n    /**\n     * Creates a new Relation instance by providing underlying data and schema.\n     *\n     * @private\n     *\n     * @param {Object | string | Relation} data - The input tabular data in dsv or json format or\n     * an existing Relation instance object.\n     * @param {Array} schema - An array of data schema.\n     * @param {Object} [options] - The optional options.\n     */\n    constructor (...params) {\n        let source;\n\n        this._parent = null;\n        this._derivation = [];\n        this._children = [];\n\n        if (params.length === 1 && ((source = params[0]) instanceof Relation)) {\n            // parent datamodel was passed as part of source\n            this._colIdentifier = source._colIdentifier;\n            this._rowDiffset = source._rowDiffset;\n            this._parent = source;\n            this._partialFieldspace = this._parent._partialFieldspace;\n            this._fieldStoreName = getUniqueId();\n            this.__calculateFieldspace().calculateFieldsConfig();\n        } else {\n            updateData(this, ...params);\n            this._fieldStoreName = this._partialFieldspace.name;\n            this.__calculateFieldspace().calculateFieldsConfig();\n            this._propagationNameSpace = {\n                mutableActions: {},\n                immutableActions: {}\n            };\n        }\n    }\n\n    /**\n     * Retrieves the {@link Schema | schema} details for every {@link Field | field} as an array.\n     *\n     * @public\n     *\n     * @return {Array.<Schema>} Array of fields schema.\n     *      ```\n     *      [\n     *          { name: 'Name', type: 'dimension' },\n     *          { name: 'Miles_per_Gallon', type: 'measure', numberFormat: (val) => `${val} miles / gallon` },\n     *          { name: 'Cylinder', type: 'dimension' },\n     *          { name: 'Displacement', type: 'measure', defAggFn: 'max' },\n     *          { name: 'HorsePower', type: 'measure', defAggFn: 'max' },\n     *          { name: 'Weight_in_lbs', type: 'measure', defAggFn: 'avg',  },\n     *          { name: 'Acceleration', type: 'measure', defAggFn: 'avg' },\n     *          { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *          { name: 'Origin' }\n     *      ]\n     *      ```\n     */\n    getSchema () {\n        return this.getFieldspace().fields.map(d => d.schema());\n    }\n\n    /**\n     * Returns the name of the {@link DataModel} instance. If no name was specified during {@link DataModel}\n     * initialization, then it returns a auto-generated name.\n     *\n     * @public\n     *\n     * @return {string} Name of the DataModel instance.\n     */\n    getName() {\n        return this._fieldStoreName;\n    }\n\n    getFieldspace () {\n        return this._fieldspace;\n    }\n\n    __calculateFieldspace () {\n        this._fieldspace = updateFields([this._rowDiffset, this._colIdentifier],\n             this.getPartialFieldspace(), this._fieldStoreName);\n        return this;\n    }\n\n    getPartialFieldspace () {\n        return this._partialFieldspace;\n    }\n\n    /**\n     * Performs {@link link_of_cross_product | cross-product} between two {@link DataModel} instances and returns a\n     * new {@link DataModel} instance containing the results. This operation is also called theta join.\n     *\n     * Cross product takes two set and create one set where each value of one set is paired with each value of another\n     * set.\n     *\n     * This method takes an optional predicate which filters the generated result rows. If the predicate returns true\n     * the combined row is included in the resulatant table.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.join(originDM)));\n     *\n     *  console.log(carsDM.join(originDM,\n     *      obj => obj.[originDM.getName()].Origin === obj.[carsDM.getName()].Origin));\n     *\n     * @text\n     * This is chained version of `join` operator. `join` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel to be joined with the current instance DataModel.\n     * @param {SelectionPredicate} filterFn - The predicate function that will filter the result of the crossProduct.\n     *\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    join (joinWith, filterFn) {\n        return crossProduct(this, joinWith, filterFn);\n    }\n\n    /**\n     * {@link natural_join | Natural join} is a special kind of cross-product join where filtering of rows are performed\n     * internally by resolving common fields are from both table and the rows with common value are included.\n     *\n     * @example\n     *  let originDM = dm.project(['Origin','Origin_Formal_Name']);\n     *  let carsDM = dm.project(['Name','Miles_per_Gallon','Origin'])\n     *\n     *  console.log(carsDM.naturalJoin(originDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} joinWith - The DataModel with which the current instance of DataModel on which the method is\n     *      called will be joined.\n     * @return {DataModel} New DataModel instance created after joining.\n     */\n    naturalJoin (joinWith) {\n        return crossProduct(this, joinWith, naturalJoinFilter(this, joinWith), true);\n    }\n\n    /**\n     * {@link link_to_union | Union} operation can be termed as vertical stacking of all rows from both the DataModel\n     * instances, provided that both of the {@link DataModel} instances should have same column names.\n     *\n     * @example\n     * console.log(EuropeanMakerDM.union(USAMakerDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} unionWith - DataModel instance for which union has to be applied with the instance on which\n     *      the method is called\n     *\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    union (unionWith) {\n        return union(this, unionWith);\n    }\n\n    /**\n     * {@link link_to_difference | Difference } operation only include rows which are present in the datamodel on which\n     * it was called but not on the one passed as argument.\n     *\n     * @example\n     * console.log(highPowerDM.difference(highExpensiveDM));\n     *\n     * @text\n     * This is chained version of `naturalJoin` operator. `naturalJoin` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {DataModel} differenceWith - DataModel instance for which difference has to be applied with the instance\n     *      on which the method is called\n     * @return {DataModel} New DataModel instance with the result of the operation\n     */\n    difference (differenceWith) {\n        return difference(this, differenceWith);\n    }\n\n    /**\n     * {@link link_to_selection | Selection} is a row filtering operation. It expects an predicate and an optional mode\n     * which control which all rows should be included in the resultant DataModel instance.\n     *\n     * {@link SelectionPredicate} is a function which returns a boolean value. For selection opearation the selection\n     * function is called for each row of DataModel instance with the current row passed as argument.\n     *\n     * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n     * of rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resulatant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  // with selection mode NORMAL:\n     *  const normDt = dt.select(fields => fields.Origin.value === \"USA\")\n     *  console.log(normDt));\n     *\n     * // with selection mode INVERSE:\n     * const inverDt = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.INVERSE })\n     * console.log(inverDt);\n     *\n     * // with selection mode ALL:\n     * const dtArr = dt.select(fields => fields.Origin.value === \"USA\", { mode: DataModel.FilteringMode.ALL })\n     * // print the selected parts\n     * console.log(dtArr[0]);\n     * // print the inverted parts\n     * console.log(dtArr[1]);\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {SelectionPredicate} selectFn - Predicate funciton which is called for each row with the current row\n     *      ```\n     *          function (row, i)  { ... }\n     *      ```\n     * @param {Object} [config] - The configuration object to control the inclusion exclusion of a row in resultant\n     *      DataModel instance\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection\n     *\n     * @return {DataModel} Returns the new DataModel instance(s) after operation.\n     */\n    select (selectFn, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n\n        const cloneConfig = { saveChild: config.saveChild };\n        let oDm;\n\n        if (config.mode === FilteringMode.ALL) {\n            const selectDm = cloneWithSelect(\n                this,\n                selectFn,\n                { mode: FilteringMode.NORMAL },\n                cloneConfig\n            );\n            const rejectDm = cloneWithSelect(\n                this,\n                selectFn,\n                { mode: FilteringMode.INVERSE },\n                cloneConfig\n            );\n            oDm = [selectDm, rejectDm];\n        } else {\n            oDm = cloneWithSelect(\n                this,\n                selectFn,\n                config,\n                cloneConfig\n            );\n        }\n\n        return oDm;\n    }\n\n    /**\n     * Retrieves a boolean value if the current {@link DataModel} instance has data.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'CarName', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     * const data = [];\n     *\n     * const dt = new DataModel(schema, data);\n     * console.log(dt.isEmpty());\n     *\n     * @public\n     *\n     * @return {Boolean} True if the datamodel has no data, otherwise false.\n     */\n    isEmpty () {\n        return !this._rowDiffset.length || !this._colIdentifier.length;\n    }\n\n    /**\n     * Creates a clone from the current DataModel instance with child parent relationship.\n     *\n     * @private\n     * @param {boolean} [saveChild=true] - Whether the cloned instance would be recorded in the parent instance.\n     * @return {DataModel} - Returns the newly cloned DataModel instance.\n     */\n    clone (saveChild = true, linkParent = true) {\n        let retDataModel;\n        if (linkParent === false) {\n            const dataObj = this.getData({\n                getAllFields: true\n            });\n            const data = dataObj.data;\n            const schema = dataObj.schema;\n            const jsonData = data.map((row) => {\n                const rowObj = {};\n                schema.forEach((field, i) => {\n                    rowObj[field.name] = row[i];\n                });\n                return rowObj;\n            });\n            retDataModel = new this.constructor(jsonData, schema);\n        }\n        else {\n            retDataModel = new this.constructor(this);\n        }\n\n        if (saveChild) {\n            this._children.push(retDataModel);\n        }\n        return retDataModel;\n    }\n\n    /**\n     * {@link Projection} is filter column (field) operation. It expects list of fields' name and either include those\n     * or exclude those based on {@link FilteringMode} on the resultant variable.\n     *\n     * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n     * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n     *\n     * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n     * resulatant datamodel.\n     *\n     * @warning\n     * Selection and rejection set is only a logical idea for concept explanation purpose.\n     *\n     * @example\n     *  const dm = new DataModel(schema, data);\n     *\n     *  // with projection mode NORMAL:\n     *  const normDt = dt.project([\"Name\", \"HorsePower\"]);\n     *  console.log(normDt.getData());\n     *\n     *  // with projection mode INVERSE:\n     *  const inverDt = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.INVERSE })\n     *  console.log(inverDt.getData());\n     *\n     *  // with selection mode ALL:\n     *  const dtArr = dt.project([\"Name\", \"HorsePower\"], { mode: DataModel.FilteringMode.ALL })\n     *  // print the normal parts\n     *  console.log(dtArr[0].getData());\n     *  // print the inverted parts\n     *  console.log(dtArr[1].getData());\n     *\n     * @text\n     * This is chained version of `select` operator. `select` can also be used as\n     * {@link link_to_join_op | functional operator}.\n     *\n     * @public\n     *\n     * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n     * @param {Object} [config] - An optional config to control the creation of new DataModel\n     * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n     *\n     * @return {DataModel} Returns the new DataModel instance after operation.\n     */\n    project (projField, config) {\n        const defConfig = {\n            mode: FilteringMode.NORMAL,\n            saveChild: true\n        };\n        config = Object.assign({}, defConfig, config);\n        const fieldConfig = this.getFieldsConfig();\n        const allFields = Object.keys(fieldConfig);\n        const { mode } = config;\n\n        let normalizedProjField = projField.reduce((acc, field) => {\n            if (field.constructor.name === 'RegExp') {\n                acc.push(...allFields.filter(fieldName => fieldName.search(field) !== -1));\n            } else if (field in fieldConfig) {\n                acc.push(field);\n            }\n            return acc;\n        }, []);\n\n        normalizedProjField = Array.from(new Set(normalizedProjField)).map(field => field.trim());\n        let dataModel;\n\n        if (mode === FilteringMode.ALL) {\n            let projectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.NORMAL,\n                saveChild: config.saveChild\n            }, allFields);\n            let rejectionClone = cloneWithProject(this, normalizedProjField, {\n                mode: FilteringMode.INVERSE,\n                saveChild: config.saveChild\n            }, allFields);\n            dataModel = [projectionClone, rejectionClone];\n        } else {\n            let projectionClone = cloneWithProject(this, normalizedProjField, config, allFields);\n            dataModel = projectionClone;\n        }\n\n        return dataModel;\n    }\n\n    getFieldsConfig () {\n        return this._fieldConfig;\n    }\n\n    calculateFieldsConfig () {\n        this._fieldConfig = this._fieldspace.fields.reduce((acc, fieldDef, i) => {\n            acc[fieldDef.name()] = {\n                index: i,\n                def: { name: fieldDef.name(), type: fieldDef.type(), subtype: fieldDef.subtype() }\n            };\n            return acc;\n        }, {});\n        return this;\n    }\n\n\n    /**\n     * Frees up the resources associated with the current DataModel instance and breaks all the links instance has in\n     * the DAG.\n     *\n     * @public\n     */\n    dispose () {\n        this._parent.removeChild(this);\n        this._parent = null;\n    }\n\n    /**\n     * Removes the specified child {@link DataModel} from the child list of the current {@link DataModel} instance.\n     *\n     * @example\n     * const schema = [\n     *    { name: 'Name', type: 'dimension' },\n     *    { name: 'HorsePower', type: 'measure' },\n     *    { name: \"Origin\", type: 'dimension' }\n     * ];\n     *\n     * const data = [\n     *    { Name: \"chevrolet chevelle malibu\", Horsepower: 130, Origin: \"USA\" },\n     *    { Name: \"citroen ds-21 pallas\", Horsepower: 115, Origin: \"Europe\" },\n     *    { Name: \"datsun pl510\", Horsepower: 88, Origin: \"Japan\" },\n     *    { Name: \"amc rebel sst\", Horsepower: 150, Origin: \"USA\"},\n     * ]\n     *\n     * const dt = new DataModel(schema, data);\n     *\n     * const dt2 = dt.select(fields => fields.Origin.value === \"USA\")\n     * dt.removeChild(dt2);\n     *\n     * @private\n     *\n     * @param {DataModel} child - Delegates the parent to remove this child.\n     */\n    removeChild (child) {\n        let idx = this._children.findIndex(sibling => sibling === child);\n        idx !== -1 ? this._children.splice(idx, 1) : true;\n    }\n\n    /**\n     * Adds the specified {@link DataModel} as a parent for the current {@link DataModel} instance.\n     *\n     * The optional criteriaQueue is an array containing the history of transaction performed on parent\n     *  {@link DataModel} to get the current one.\n     *\n     * @param {DataModel} parent - The datamodel instance which will act as parent.\n     * @param {Array} criteriaQueue - Queue contains in-between operation meta-data.\n     */\n    addParent (parent, criteriaQueue = []) {\n        persistDerivation(this, DM_DERIVATIVES.COMPOSE, null, criteriaQueue);\n        this._parent = parent;\n        parent._children.push(this);\n    }\n}\n\nexport default Relation;\n","/* eslint-disable default-case */\n\nimport { FieldType, DimensionSubtype } from './enums';\nimport {\n    persistDerivation,\n    getRootGroupByModel,\n    propagateToAllDataModels,\n    getRootDataModel,\n    propagateImmutableActions,\n    addToPropNamespace\n} from './helper';\nimport { DM_DERIVATIVES, PROPAGATION } from './constants';\nimport {\n    dataBuilder,\n    rowDiffsetIterator,\n    groupBy\n} from './operator';\nimport { createBinnedFieldData } from './operator/bucket-creator';\nimport Relation from './relation';\nimport reducerStore from './utils/reducer-store';\nimport { createFields } from './field-creator';\n\n/**\n * DataModel is an in-browser representation of tabular data. It supports\n * {@link https://en.wikipedia.org/wiki/Relational_algebra | relational algebra} operators as well as generic data\n * processing opearators.\n * DataModel extends {@link Relation} class which defines all the relational algebra opreators. DataModel gives\n * definition of generic data processing operators which are not relational algebra complient.\n *\n * @public\n * @class\n * @extends Relation\n * @memberof Datamodel\n */\nclass DataModel extends Relation {\n    /**\n     * Creates a new DataModel instance by providing data and schema. Data could be in the form of\n     * - Flat JSON\n     * - DSV String\n     * - 2D Array\n     *\n     * By default DataModel finds suitable adapter to serialize the data. DataModel also expects a\n     * {@link Schema | schema} for identifying the variables present in data.\n     *\n     * @constructor\n     * @example\n     * const data = loadData('cars.csv');\n     * const schema = [\n     *      { name: 'Name', type: 'dimension' },\n     *      { name: 'Miles_per_Gallon', type: 'measure', unit : 'cm', scale: '1000', numberformat: val => `${val}G`},\n     *      { name: 'Cylinders', type: 'dimension' },\n     *      { name: 'Displacement', type: 'measure' },\n     *      { name: 'Horsepower', type: 'measure' },\n     *      { name: 'Weight_in_lbs', type: 'measure' },\n     *      { name: 'Acceleration', type: 'measure' },\n     *      { name: 'Year', type: 'dimension', subtype: 'datetime', format: '%Y' },\n     *      { name: 'Origin', type: 'dimension' }\n     * ];\n     * const dm = new DataModel(data, schema, { name: 'Cars' });\n     * table(dm);\n     *\n     * @public\n     *\n     * @param {Array.<Object> | string | Array.<Array>} data Input data in any of the mentioned formats\n     * @param {Array.<Schema>} schema Defination of the variables. Order of the variables in data and order of the\n     *      variables in schema has to be same.\n     * @param {object} [options] Optional arguments to specify more settings regarding the creation part\n     * @param {string} [options.name] Name of the datamodel instance. If no name is given an auto generated name is\n     *      assigned to the instance.\n     * @param {string} [options.fieldSeparator=','] specify field separator type if the data is of type dsv string.\n     */\n    constructor (...args) {\n        super(...args);\n\n        this._onPropagation = [];\n        this._sortingDetails = [];\n    }\n\n    /**\n     * Reducers are simple functions which reduces an array of numbers to a representative number of the set.\n     * Like an array of numbers `[10, 20, 5, 15]` can be reduced to `12.5` if average / mean reducer function is\n     * applied. All the measure fields in datamodel (variables in data) needs a reducer to handle aggregation.\n     *\n     * @public\n     *\n     * @return {ReducerStore} Singleton instance of {@link ReducerStore}.\n     */\n    static get Reducers () {\n        return reducerStore;\n    }\n\n    /**\n     * Retrieve the data attached to an instance in JSON format.\n     *\n     * @example\n     * // DataModel instance is already prepared and assigned to dm variable\n     *  const data = dm.getData({\n     *      order: 'column',\n     *      formatter: {\n     *          origin: (val) => val === 'European Union' ? 'EU' : val;\n     *      }\n     *  });\n     *  console.log(data);\n     *\n     * @public\n     *\n     * @param {Object} [options] Options to control how the raw data is to be returned.\n     * @param {string} [options.order='row'] Defines if data is retieved in row order or column order. Possible values\n     *      are `'rows'` and `'columns'`\n     * @param {Function} [options.formatter=null] Formats the output data. This expects an object, where the keys are\n     *      the name of the variable needs to be formatted. The formatter function is called for each row passing the\n     *      value of the cell for a particular row as arguments. The formatter is a function in the form of\n     *      `function (value, rowId, schema) => { ... }`\n     *      Know more about {@link Fomatter}.\n     *\n     * @return {Array} Returns a multidimensional array of the data with schema. The return format looks like\n     *      ```\n     *          {\n     *              data,\n     *              schema\n     *          }\n     *      ```\n     */\n    getData (options) {\n        const defOptions = {\n            order: 'row',\n            formatter: null,\n            withUid: false,\n            getAllFields: false,\n            sort: []\n        };\n        options = Object.assign({}, defOptions, options);\n        const fields = this.getPartialFieldspace().fields;\n\n        const dataGenerated = dataBuilder.call(\n            this,\n            this.getPartialFieldspace().fields,\n            this._rowDiffset,\n            options.getAllFields ? fields.map(d => d.name()).join() : this._colIdentifier,\n            options.sort,\n            {\n                columnWise: options.order === 'column',\n                addUid: !!options.withUid\n            }\n        );\n\n        if (!options.formatter) {\n            return dataGenerated;\n        }\n\n        const { formatter } = options;\n        const { data, schema, uids } = dataGenerated;\n        const fieldNames = schema.map((e => e.name));\n        const fmtFieldNames = Object.keys(formatter);\n        const fmtFieldIdx = fmtFieldNames.reduce((acc, next) => {\n            const idx = fieldNames.indexOf(next);\n            if (idx !== -1) {\n                acc.push([idx, formatter[next]]);\n            }\n            return acc;\n        }, []);\n\n        if (options.order === 'column') {\n            fmtFieldIdx.forEach((elem) => {\n                const fIdx = elem[0];\n                const fmtFn = elem[1];\n\n                data[fIdx].forEach((datum, datumIdx) => {\n                    data[fIdx][datumIdx] = fmtFn.call(\n                        undefined,\n                        datum,\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        } else {\n            data.forEach((datum, datumIdx) => {\n                fmtFieldIdx.forEach((elem) => {\n                    const fIdx = elem[0];\n                    const fmtFn = elem[1];\n\n                    datum[fIdx] = fmtFn.call(\n                        undefined,\n                        datum[fIdx],\n                        uids[datumIdx],\n                        schema[fIdx]\n                    );\n                });\n            });\n        }\n\n        return dataGenerated;\n    }\n\n    /**\n     * Groups the data using particular dimensions and by reducing measures. It expects a list of dimensions using which\n     * it projects the datamodel and perform aggregations to reduce the duplicate tuples. Refer this\n     * {@link link_to_one_example_with_group_by | document} to know the intuition behind groupBy.\n     *\n     * DataModel by default provides definition of few {@link reducer | Reducers}.\n     * {@link ReducerStore | User defined reducers} can also be registered.\n     *\n     * This is the chained implementation of `groupBy`.\n     * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n     *\n     * @example\n     * const groupedDM = dm.groupBy(['Year'], { horsepower: 'max' } );\n     * console.log(groupedDm);\n     *\n     * @public\n     *\n     * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n     * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n     *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n     *      schema of the variable.\n     *\n     * @return {DataModel} Returns a new DataModel instance after performing the groupby.\n     */\n    groupBy (fieldsArr, reducers = {}, config = { saveChild: true }) {\n        const groupByString = `${fieldsArr.join()}`;\n        let params = [this, fieldsArr, reducers];\n        const newDataModel = groupBy(...params);\n\n        if (config.saveChild) {\n            this._children.push(newDataModel);\n            persistDerivation(\n                newDataModel,\n                DM_DERIVATIVES.GROUPBY,\n                { fieldsArr, groupByString, defaultReducer: reducerStore.defaultReducer() },\n                reducers\n            );\n        }\n\n        newDataModel._parent = this;\n        return newDataModel;\n    }\n\n    /**\n     * Performs sorting operation on the current {@link DataModel} instance according to the specified sorting details.\n     * Like every other operator it doesn't mutate the current DataModel instance on which it was called, instead\n     * returns a new DataModel instance containing the sorted data.\n     *\n     * DataModel support multi level sorting by listing the variables using which sorting needs to be performed and\n     * the type of sorting `ASC` or `DESC`.\n     *\n     * In the following example, data is sorted by `Origin` field in `DESC` order in first level followed by another\n     * level of sorting by `Acceleration` in `ASC` order.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * let sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\"] // Default value is ASC\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * // Sort with a custom sorting function\n     * sortedDm = dm.sort([\n     *    [\"Origin\", \"DESC\"]\n     *    [\"Acceleration\", (a, b) => a - b] // Custom sorting function\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @text\n     * DataModel also provides another sorting mechanism out of the box where sort is applied to a variable using\n     * another variable which determines the order.\n     * Like the above DataModel contains three fields `Origin`, `Name` and `Acceleration`. Now, the data in this\n     * model can be sorted by `Origin` field according to the average value of all `Acceleration` for a\n     * particular `Origin` value.\n     *\n     * @example\n     * // here dm is the pre-declared DataModel instance containing the data of 'cars.json' file\n     * const sortedDm = dm.sort([\n     *     ['Origin', ['Acceleration', (a, b) => avg(...a.Acceleration) - avg(...b.Acceleration)]]\n     * ]);\n     *\n     * console.log(dm.getData());\n     * console.log(sortedDm.getData());\n     *\n     * @public\n     *\n     * @param {Array.<Array>} sortingDetails - Sorting details based on which the sorting will be performed.\n     * @return {DataModel} Returns a new instance of DataModel with sorted data.\n     */\n    sort (sortingDetails) {\n        const rawData = this.getData({\n            order: 'row',\n            sort: sortingDetails\n        });\n        const header = rawData.schema.map(field => field.name);\n        const dataInCSVArr = [header].concat(rawData.data);\n\n        const sortedDm = new this.constructor(dataInCSVArr, rawData.schema, { dataFormat: 'DSVArr' });\n        sortedDm._sortingDetails = sortingDetails;\n        return sortedDm;\n    }\n\n    addField (field) {\n        const fieldName = field.name();\n        this._colIdentifier += `,${fieldName}`;\n        const partialFieldspace = this._partialFieldspace;\n\n        if (!partialFieldspace.fieldsObj()[field.name()]) {\n            partialFieldspace.fields.push(field);\n        } else {\n            const fieldIndex = partialFieldspace.fields.findIndex(fieldinst => fieldinst.name() === fieldName);\n            fieldIndex >= 0 && (partialFieldspace.fields[fieldIndex] = field);\n        }\n\n        this.__calculateFieldspace().calculateFieldsConfig();\n        return this;\n    }\n\n     /**\n     * Creates a new variable calculated from existing variable. This method expects the defination of the newly created\n     * variable and a function which resolves the value of the new variable from existing variables.\n     *\n     * Can create a new measure based on existing variables\n     * @example\n     *  // DataModel already prepared and assigned to dm vairable;\n     *  const newDm = dataModel.calculateVariable({\n     *      name: 'powerToWeight',\n     *      type: 'measure'\n     *  }, ['horsepower', 'weight_in_lbs', (hp, weight) => hp / weight ]);\n     *\n     *\n     * Can create a new dimension based on existing variables\n     * @example\n     *  // DataModel already prepared and assigned to dm vairable;\n     *  const child = dataModel.calculateVariable(\n     *     {\n     *       name: 'Efficiency',\n     *       type: 'dimension'\n     *     }, ['horsepower', (hp) => {\n     *      if (hp < 80) { return 'low'; },\n     *      else if (hp < 120) { return 'moderate'; }\n     *      else { return 'high' }\n     *  }]);\n     *\n     * @public\n     *\n     * @param {Schema} schema: Schema of newly defined variable\n     * @param {VariableResolver} resolver: Resolver format to resolve the current variable\n     *\n     * @return {DataModel} Instance of DataModel with the new field\n     */\n    calculateVariable (schema, dependency, config = { saveChild: true, replaceVar: false }) {\n        const fieldsConfig = this.getFieldsConfig();\n        const depVars = dependency.slice(0, dependency.length - 1);\n        const retrieveFn = dependency[dependency.length - 1];\n\n        if (fieldsConfig[schema.name] && !config.replaceVar) {\n            throw new Error(`${schema.name} field already exists in model.`);\n        }\n        const depFieldIndices = depVars.map((field) => {\n            const fieldSpec = fieldsConfig[field];\n            if (!fieldSpec) {\n                // @todo dont throw error here, use warning in production mode\n                throw new Error(`${field} is not a valid column name.`);\n            }\n            return fieldSpec.index;\n        });\n\n        let clone = this.clone();\n\n        const fs = clone.getFieldspace().fields;\n        const suppliedFields = depFieldIndices.map(idx => fs[idx]);\n\n        const computedValues = [];\n        rowDiffsetIterator(clone._rowDiffset, (i) => {\n            const fieldsData = suppliedFields.map(field => field.partialField.data[i]);\n            computedValues[i] = retrieveFn(...fieldsData, i, fs);\n        });\n        const [field] = createFields([computedValues], [schema], [schema.name]);\n        clone.addField(field);\n\n        if (config.saveChild) {\n            persistDerivation(clone, DM_DERIVATIVES.CAL_VAR, { config: schema, fields: depVars }, retrieveFn);\n        }\n\n        return clone;\n    }\n\n    /**\n     * Propagates changes across all the connected DataModel instances.\n     *\n     * @param {Array} identifiers - A list of identifiers that were interacted with.\n     * @param {Object} payload - The interaction specific details.\n     *\n     * @return {DataModel} DataModel instance.\n     */\n    propagate (identifiers, config = {}, addToNameSpace, propConfig = {}) {\n        const isMutableAction = config.isMutableAction;\n        const propagationSourceId = config.sourceId;\n        const payload = config.payload;\n        const rootModel = getRootDataModel(this);\n        const propagationNameSpace = rootModel._propagationNameSpace;\n        const rootGroupByModel = getRootGroupByModel(this);\n        const rootModels = {\n            groupByModel: rootGroupByModel,\n            model: rootModel\n        };\n\n        addToNameSpace && addToPropNamespace(propagationNameSpace, config, this);\n        propagateToAllDataModels(identifiers, rootModels, { propagationNameSpace, sourceId: propagationSourceId },\n            Object.assign({\n                payload\n            }, config));\n\n        if (isMutableAction) {\n            propagateImmutableActions(propagationNameSpace, rootModels, {\n                config,\n                propConfig\n            }, this);\n        }\n\n        return this;\n    }\n\n    /**\n     * Associates a callback with an event name.\n     *\n     * @param {string} eventName - The name of the event.\n     * @param {Function} callback - The callback to invoke.\n     * @return {DataModel} Returns this current DataModel instance itself.\n     */\n    on (eventName, callback) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation.push(callback);\n            break;\n        }\n        return this;\n    }\n\n    /**\n     * Unsubscribes the callbacks for the provided event name.\n     *\n     * @param {string} eventName - The name of the event to unsubscribe.\n     * @return {DataModel} Returns the current DataModel instance itself.\n     */\n    unsubscribe (eventName) {\n        switch (eventName) {\n        case PROPAGATION:\n            this._onPropagation = [];\n            break;\n\n        }\n        return this;\n    }\n\n    /**\n     * This method is used to invoke the method associated with propagation.\n     *\n     * @param {Object} payload The interaction payload.\n     * @param {DataModel} identifiers The propagated DataModel.\n     * @memberof DataModel\n     */\n    handlePropagation (propModel, payload) {\n        let propListeners = this._onPropagation;\n        propListeners.forEach(fn => fn.call(this, propModel, payload));\n    }\n\n    /**\n     * Perfoms binning on a measure field based on a binning configuration. This method does not aggregate the number of\n     * rows present in DataModel instance after binning, it just adds a new field with the binned value. Refer binning\n     * {@link example_of_binning | example} to have a intuition of what binning is and the use case.\n     *\n     * Binning can be configured by\n     * - providing custom bin configuration with non uniform buckets\n     * - providing bin count\n     * - providing each bin size\n     *\n     * When custom buckets are provided as part of binning configuration\n     * @example\n     *  // DataModel already prepared and assigned to dm vairable\n     *  const buckets = {\n     *      start: 30\n     *      stops: [80, 100, 110]\n     *  };\n     *  const config = { buckets, name: 'binnedHP' }\n     *  const binDM = dataModel.bin('horsepower', config);\\\n     *\n     * @text\n     * When `binCount` is defined as part of binning configuration\n     * @example\n     *  // DataModel already prepared and assigned to dm vairable\n     *  const config = { binCount: 5, name: 'binnedHP' }\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @text\n     * When `binSize` is defined as part of binning configuration\n     * @example\n     *  // DataModel already prepared and assigned to dm vairable\n     *  const config = { binSize: 200, name: 'binnedHorsepower' }\n     *  const binDM = dataModel.bin('horsepower', config);\n     *\n     * @public\n     *\n     * @param {String} name Name of measure which will be used to create bin\n     * @param {Object} config Config required for bin creation\n     * @param {Array.<Number>} config.bucketObj.stops Defination of bucket ranges. Two subsequent number from arrays\n     *      are picked and a range is created. The first number from range is inclusive and the second number from range\n     *      is exclusive.\n     * @param {Number} [config.bucketObj.startAt] Force the start of the bin from a particular number.\n     *      If not mentioned, the start of the bin or the lower domain of the data if stops is not mentioned, else its\n     *      the first value of the stop.\n     * @param {Number} config.binSize Bucket size for each bin\n     * @param {Number} config.binCount Number of bins which will be created\n     * @param {String} config.name Name of the new binned field to be created\n     *\n     * @returns {DataModel} Instance of new DataModel with the newly created bin.\n     */\n    bin (dimensionName, config = { }) {\n        const clone = this.clone();\n        const binFieldName = config.name || `${dimensionName}_binned`;\n        if (this.getFieldsConfig()[binFieldName] || !this.getFieldsConfig()[dimensionName]) {\n            throw new Error(`Field ${dimensionName} already exists.`);\n        }\n        const field = this._partialFieldspace.fields.find(currfield => currfield.name() === dimensionName);\n        const dataSet = createBinnedFieldData(field, this._rowDiffset, config);\n        const binField = createFields([dataSet.data], [\n            {\n                name: binFieldName,\n                type: FieldType.DIMENSION,\n                subtype: DimensionSubtype.BINNED,\n                bins: {\n                    range: dataSet.range,\n                    mid: dataSet.mid\n                }\n            }], [binFieldName])[0];\n        clone.addField(binField);\n        persistDerivation(clone, DM_DERIVATIVES.BIN, { dimensionName, config, binFieldName }, null);\n        return clone;\n    }\n}\n\nexport default DataModel;\n","import { fnList } from '../operator/group-by-function';\n\nexport const { sum, avg, min, max, first, last, count, std: sd } = fnList;\n","import DataModel from './datamodel';\nimport {\n  compose,\n  bin,\n  select,\n  project,\n  groupby as groupBy,\n  calculateVariable,\n  sort,\n  crossProduct,\n  difference,\n  naturalJoin,\n  leftOuterJoin,\n  rightOuterJoin,\n  fullOuterJoin,\n  union\n} from './operator';\nimport * as Stats from './stats';\nimport * as enums from './enums';\nimport { DateTimeFormatter } from './utils';\nimport { DataFormat, FilteringMode } from './constants';\nimport pkg from '../package.json';\n\nDataModel.Operators = {\n    compose,\n    bin,\n    select,\n    project,\n    groupBy,\n    calculateVariable,\n    sort,\n    crossProduct,\n    difference,\n    naturalJoin,\n    leftOuterJoin,\n    rightOuterJoin,\n    fullOuterJoin,\n    union\n};\nDataModel.Stats = Stats;\nObject.assign(DataModel, enums);\nDataModel.DateTimeFormatter = DateTimeFormatter;\nDataModel.DataFormat = DataFormat;\nDataModel.FilteringMode = FilteringMode;\nDataModel.version = pkg.version;\n\nexport default DataModel;\n","\n/**\n * DataModel's opearators are exposed as composable functional operators as well as chainable operators. Chainable\n * operators are called on the instances of {@link Datamodel} and {@link Relation} class.\n *\n * Those same operators can be used as composable operators from `DataModel.Operators` namespace.\n *\n * All these operators have similar behaviour. All these operators when called with the argument returns a function\n * which expects a DataModel instance.\n *\n * @public\n * @module Operators\n * @namespace DataModel\n */\n\n/**\n * This is functional version of selection operator. {@link link_to_selection | Selection} is a row filtering operation.\n * It takes {@link SelectionPredicate | predicate} for filtering criteria and returns a function.\n * The returned function is called with the DataModel instance on which the action needs to be performed.\n *\n * {@link SelectionPredicate} is a function which returns a boolean value. For selection opearation the selection\n * function is called for each row of DataModel instance with the current row passed as argument.\n *\n * After executing {@link SelectionPredicate} the rows are labeled as either an entry of selection set or an entry\n * of rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * [Warn] Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * [Error] `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @example\n * const select = DataModel.Operators.select;\n * usaCarsFn = select(fields => fields.Origin.value === 'USA');\n * usaCarsDm = usaCarsFn(dm);\n * console.log(usaCarsDm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {SelectionPredicate} selectFn - Predicate funciton which is called for each row with the current row\n *      ```\n *          function (row, i)  { ... }\n *      ```\n * @param {Object} [config] - The configuration object to control the inclusion exclusion of a row in resultant\n *      DataModel instance\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - The mode of the selection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const select = (...args) => dm => dm.select(...args);\n\n/**\n * This is functional version of projection operator. {@link link_to_projection | Projection} is a column filtering\n * operation.It expects list of fields name and either include those or exclude those based on {@link FilteringMode} on\n * the  resultant variable.It returns a function which is called with the DataModel instance on which the action needs\n * to be performed.\n *\n * Projection expects array of fields name based on which it creates the selection and rejection set. All the field\n * whose name is present in array goes in selection set and rest of the fields goes in rejection set.\n *\n * {@link FilteringMode} operates on the selection and rejection set to determine which one would reflect in the\n * resulatant datamodel.\n *\n * @warning\n * Selection and rejection set is only a logical idea for concept explanation purpose.\n *\n * @error\n * `FilteringMode.ALL` is not a valid working mode for functional version of `select`. Its only avialable on the\n * chained version.\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<string | Regexp>} projField - An array of column names in string or regular expression.\n * @param {Object} [config] - An optional config to control the creation of new DataModel\n * @param {FilteringMode} [config.mode=FilteringMode.NORMAL] - Mode of the projection\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const project = (...args) => dm => dm.project(...args);\n\n/**\n * This is functional version of binnig operator. Binning happens on a measure field based on a binning configuration.\n * Binning in DataModel does not aggregate the number of rows present in DataModel instance after binning, it just adds\n * a new field with the binned value. Refer binning {@link example_of_binning | example} to have a intuition of what\n * binning is and the use case.\n *\n * Binning can be configured by\n * - providing custom bin configuration with non uniform buckets\n * - providing bin count\n * - providing each bin size\n *\n * When custom buckets are provided as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const buckets = {\n *      start: 30\n *      stops: [80, 100, 110]\n *  };\n *  const config = { buckets, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(dm);\n *\n * @text\n * When `binCount` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binCount: 5, name: 'binnedHP' }\n *  const binFn = bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @text\n * When `binSize` is defined as part of binning configuration\n * @example\n *  // DataModel already prepared and assigned to dm vairable\n *  const config = { binSize: 200, name: 'binnedHorsepower' }\n *  const binnedDm = dataModel.bin('horsepower', config);\n *  const binnedDm = binFn(Dm);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {String} name Name of measure which will be used to create bin\n * @param {Object} config Config required for bin creation\n * @param {Array.<Number>} config.bucketObj.stops Defination of bucket ranges. Two subsequent number from arrays\n *      are picked and a range is created. The first number from range is inclusive and the second number from range\n *      is exclusive.\n * @param {Number} [config.bucketObj.startAt] Force the start of the bin from a particular number.\n *      If not mentioned, the start of the bin or the lower domain of the data if stops is not mentioned, else its\n *      the first value of the stop.\n * @param {Number} config.binSize Bucket size for each bin\n * @param {Number} config.binCount Number of bins which will be created\n * @param {String} config.name Name of the new binned field to be created\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const bin = (...args) => dm => dm.bin(...args);\n\n/**\n * This is functional version of `groupBy` operator.Groups the data using particular dimensions and by reducing\n * measures. It expects a list of dimensions using which it projects the datamodel and perform aggregations to reduce\n * the duplicate tuples. Refer this {@link link_to_one_example_with_group_by | document} to know the intuition behind\n * groupBy.\n *\n * DataModel by default provides definition of few {@link reducer | Reducers}.\n * {@link ReducerStore | User defined reducers} can also be registered.\n *\n * This is the chained implementation of `groupBy`.\n * `groupBy` also supports {@link link_to_compose_groupBy | composability}\n *\n * @example\n * const groupBy = DataModel.Operators.groupBy;\n * const groupedFn = groupBy(['Year'], { horsepower: 'max' } );\n * groupedDM = groupByFn(dm);\n *\n * @public\n *\n * @param {Array.<string>} fieldsArr - Array containing the name of dimensions\n * @param {Object} [reducers={}] - A map whose key is the variable name and value is the name of the reducer. If its\n *      not passed, or any variable is ommitted from the object, default aggregation function is used from the\n *      schema of the variable.\n *\n * @return {PreparatorFunction} Function which expects an instance of DataModel on which the operator needs to be\n *      applied.\n */\nexport const groupBy = (...args) => dm => dm.groupBy(...args);\n\n/**\n * Enables composing operators to run multiple operations and save group of operataion as named opration on a DataModel.\n * The resulting DataModel will be the result of all the operation provided. The operations provided will be executed in\n * a serial manner ie. result of one operation will be the input for the next operations (like pipe operator in unix).\n *\n * Suported operations in compose are\n * - `select`\n * - `project`\n * - `groupBy`\n * - `bin`\n * - `compose`\n *\n * @example\n * const compose = DataModel.Operators.compose;\n * const select = DataModel.Operators.select;\n * const project = DataModel.Operators.project;\n *\n * let composedFn = compose(\n *    select(fields => fields.netprofit.value <= 15),\n *    project(['netprofit', 'netsales']));\n *\n * const dataModel = new DataModel(data1, schema1);\n *\n * let composedDm = composedFn(dataModel);\n *\n * @public\n * @namespace DataModel\n * @module Operators\n *\n * @param {Array.<Operators>} operators: An array of operation that will be applied on the\n * datatable.\n *\n * @returns {DataModel} Instance of resultant DataModel\n */\nexport const compose = (...operations) =>\n    (dm, config = { saveChild: true }) => {\n        let currentDM = dm;\n        let frstChild;\n        const derivations = [];\n        const saveChild = config.saveChild;\n\n        operations.forEach((operation) => {\n            currentDM = operation(currentDM);\n            derivations.push(...currentDM._derivation);\n            if (!frstChild) {\n                frstChild = currentDM;\n            }\n        });\n\n        saveChild && currentDM.addParent(dm, derivations);\n        if (derivations.length > 1) {\n            frstChild.dispose();\n        }\n\n        return currentDM;\n    };\n","/**\n * Wrapper on calculateVariable() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const calculateVariable = (...args) => dm => dm.calculateVariable(...args);\n\n/**\n * Wrapper on sort() method of DataModel to behave\n * the pure-function functionality.\n *\n * @param {Array} args - The argument list.\n * @return {any} Returns the returned value of calling function.\n */\nexport const sort = (...args) => dm => dm.sort(...args);\n","import { crossProduct } from './cross-product';\nimport { naturalJoinFilter } from './natural-join-filter-function';\n\nexport function naturalJoin (dataModel1, dataModel2) {\n    return crossProduct(dataModel1, dataModel2, naturalJoinFilter(dataModel1, dataModel2), true);\n}\n"],"sourceRoot":""}